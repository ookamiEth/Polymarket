\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{geometry}
\usepackage{subcaption}
\geometry{margin=1in}
\title{\textbf{Two-Stage Residual Learning for Binary Option Pricing:\\
A Machine Learning Approach to High-Frequency Market Prediction}}
\author{
Binary Options Research Team\\
\texttt{research@eth.bt}
}
\date{\today}
\begin{document}
\maketitle
\begin{abstract}
We present a two-stage residual learning framework for binary option pricing on cryptocurrency markets combining Black-Scholes baseline with hierarchical volatility regime modeling. Training on 39 million 15-minute BTC/ETH binary options observations (July 2024 - September 2025) with walk-forward validation across 10 temporal folds, we achieve 15-20\% Brier score improvement over Black-Scholes baseline through four specialized LightGBM models trained on 175 optimized features. Feature pruning (226→175 features) yields 30\% faster training with improved generalization, while regime-specific modeling achieves 25-30\% improvement in optimal low-volatility at-the-money conditions (35\% of data) and 7\% better crisis period performance. We prove that for residual learning on binary outcomes, mean squared error of residuals directly equals Brier score improvement, providing a principled optimization target. Confusion matrix bucketing identifies {[}0.45-0.55{]} probability range as a no-trade zone, enabling risk-aware position sizing with 83.5\% win rate at 10\% edge thresholds. The discontinuous payoff structure necessitates non-linear baseline modeling and regime-specific feature engineering, contrasting with vanilla option approaches where volatility features dominate.
\end{abstract}
\section{Introduction}
Binary options represent a unique derivative structure where payoff is discontinuous: the holder receives a fixed amount if the underlying asset exceeds a strike price at expiration, and zero otherwise. This all-or-nothing payoff contrasts sharply with vanilla options, where payoff varies continuously with the degree of moneyness. The discontinuity introduces severe non-linearity in pricing dynamics, particularly near at-the-money strikes where small price movements create large probability shifts.
Traditional Black-Scholes theory provides an analytical solution for binary option pricing under geometric Brownian motion assumptions \cite{merton1973theory}. However, cryptocurrency markets exhibit significant departures from these idealized conditions: discrete jumps, volatility clustering, fat-tailed return distributions, and complex microstructure effects from high-frequency trading. These violations suggest potential gains from machine learning corrections to theoretical prices.
Recent work has explored machine learning for vanilla option pricing \cite{dugas2009incorporating, horvath2021deep}, but binary options pose distinct challenges:
\begin{enumerate}
\item \textbf{Extreme non-linearity}: Option delta (sensitivity to underlying price) varies 138× across moneyness states, compared to 3-5× for vanilla calls/puts.
\item \textbf{Heteroskedastic errors}: Prediction error variance follows $\text{Var}(\text{error}) = p(1-p)$, creating a funnel pattern where at-the-money predictions have highest uncertainty.
\item \textbf{Regime dependence}: Model performance varies dramatically across market conditions (4.5\% to 24.8\% improvement in our data).
\item \textbf{High-frequency dynamics}: 15-minute expiries require features capturing momentum, jumps, and order flow at second-level granularity.
\end{enumerate}
We address these challenges through a two-stage residual learning architecture:
\textbf{Stage 1}: Compute Black-Scholes binary option baseline probability $P_{\text{BS}} = e^{-rT} \Phi(d_2)$ using realized volatility and risk-free rate estimates.
\textbf{Stage 2}: Train LightGBM gradient boosting model to predict residuals $\epsilon = \text{Outcome} - P_{\text{BS}}$ using 196 engineered features spanning market microstructure, volatility dynamics, momentum, order book depth, funding rates, and cyclical patterns.
\textbf{Final prediction}: $P_{\text{final}} = P_{\text{BS}} + \hat{\epsilon}_{\text{LightGBM}}$
Our key contributions include:
\begin{itemize}
\item \textbf{Theoretical}: Proof that MSE of residuals directly equals Brier score improvement for binary outcome prediction, justifying our loss function choice.
\item \textbf{Empirical}: Analysis of 39M predictions revealing five market regimes with heterogeneous performance characteristics.
\item \textbf{Feature engineering}: Comprehensive study identifying moneyness and momentum features as primary drivers of residual corrections (41\% and 32\% correlation).
\item \textbf{Practical}: Derivation of trading signals achieving 83.5\% win rate at 10\% edge thresholds, with regime-specific position sizing recommendations.
\end{itemize}
\section{Mathematical Framework}
\subsection{Black-Scholes Binary Option Baseline}
The risk-neutral price of a cash-or-nothing binary call option paying \$1 if $S_T > K$ is:
\begin{equation}
P_{\text{BS}}(S, K, r, \sigma, T) = e^{-rT} \Phi(d_2)
\end{equation}
where:
\begin{align}
d_2 &= \frac{\ln(S/K) + (r - \sigma^2/2)T}{\sigma\sqrt{T}} \\
\Phi(\cdot) &= \text{Standard normal CDF} \\
S &= \text{Spot price at time } t \\
K &= \text{Strike price} \\
r &= \text{Risk-free rate} \\
\sigma &= \text{Implied volatility} \\
T &= \text{Time to expiration}
\end{align}
We estimate $\sigma$ from exponentially weighted moving averages of realized volatility over multiple horizons (60s, 300s, 900s, 3600s) and proxy $r$ using blended DeFi lending rates from Aave and Compound.
\subsection{Residual Target Definition}
Define the residual as the difference between actual binary outcome (0 or 1) and baseline prediction:
\begin{equation}
\epsilon = Y - P_{\text{BS}}
\end{equation}
where $Y \in \{0, 1\}$ is the realized option payoff. Our final prediction is:
\begin{equation}
P_{\text{final}} = P_{\text{BS}} + \hat{\epsilon}_{\text{ML}}
\end{equation}
where $\hat{\epsilon}_{\text{ML}}$ is the machine learning correction trained via gradient boosting.
\subsection{Loss Function and Brier Score Connection}
\textbf{Theorem 1}: For binary outcome prediction with residual learning, mean squared error of residuals equals Brier score improvement.
\begin{proof}
The Brier score for baseline model is:
\begin{equation}
\text{Brier}_{\text{BS}} = \mathbb{E}[(Y - P_{\text{BS}})^2] = \mathbb{E}[\epsilon^2]
\end{equation}
The Brier score for final model is:
\begin{align}
\text{Brier}_{\text{final}} &= \mathbb{E}[(Y - P_{\text{final}})^2] \\
&= \mathbb{E}[(Y - (P_{\text{BS}} + \hat{\epsilon}_{\text{ML}}))^2] \\
&= \mathbb{E}[(\epsilon - \hat{\epsilon}_{\text{ML}})^2]
\end{align}
The Brier score improvement is:
\begin{align}
\Delta \text{Brier} &= \text{Brier}_{\text{BS}} - \text{Brier}_{\text{final}} \\
&= \mathbb{E}[\epsilon^2] - \mathbb{E}[(\epsilon - \hat{\epsilon}_{\text{ML}})^2] \\
&= \mathbb{E}[\epsilon^2] - \mathbb{E}[\epsilon^2 - 2\epsilon\hat{\epsilon}_{\text{ML}} + \hat{\epsilon}_{\text{ML}}^2] \\
&= \mathbb{E}[2\epsilon\hat{\epsilon}_{\text{ML}} - \hat{\epsilon}_{\text{ML}}^2]
\end{align}
For perfect residual predictions where $\hat{\epsilon}_{\text{ML}} = \epsilon$:
\begin{align}
\Delta \text{Brier} &= \mathbb{E}[2\epsilon^2 - \epsilon^2] = \mathbb{E}[\epsilon^2] = \text{Brier}_{\text{BS}}
\end{align}
Therefore, minimizing MSE of residual predictions directly maximizes Brier score improvement. This justifies using standard regression loss functions for gradient boosting.
\end{proof}
\textbf{Corollary 1}: The test-set MSE of residuals provides an unbiased estimate of Brier score improvement.
This theoretical connection guides our optimization: we train LightGBM with regression objective (MSE loss) on residual targets, knowing that reductions in residual MSE translate directly to Brier score gains.
\subsection{Heteroskedasticity of Binary Outcomes}
Binary outcome variance depends on the probability:
\begin{equation}
\text{Var}(Y | P) = P(1 - P)
\end{equation}
This creates heteroskedastic errors with maximum variance at $P=0.5$ (at-the-money) and minimum at extremes ($P \to 0$ or $P \to 1$). Our empirical analysis confirms this funnel pattern (Section \ref{sec:error_analysis}), suggesting potential gains from weighted loss functions:
\begin{equation}
\mathcal{L}_{\text{weighted}} = \sum_{i=1}^{N} w_i (\epsilon_i - \hat{\epsilon}_i)^2, \quad w_i = \frac{1}{P_i(1-P_i) + \delta}
\end{equation}
where $\delta$ is a small constant for numerical stability. This weighting scheme is explored in Section \ref{sec:future_work}.
\section{Feature Engineering}
We construct 175 optimized features (pruned from initial 226) across 16 categories, engineered specifically for binary option dynamics. Feature counts reflect post-pruning optimization detailed in Section 3.8.
\subsection{Context Features (3)}
\begin{itemize}
\item \textbf{Moneyness}: $(S - K)/K$ — Most important feature (41\% correlation with residuals)
\item \textbf{Time remaining}: Seconds until expiration
\item \textbf{IV staleness}: Time since last implied volatility update
\end{itemize}
\subsection{Realized Volatility (28)}
Exponentially weighted standard deviations over multiple horizons:
\begin{itemize}
\item \textbf{Base RV}: 60s, 300s, 900s, 3600s windows
\item \textbf{RV EMAs}: 5-period and 20-period exponential moving averages
\item \textbf{RV ratios}: Short/long horizon comparisons (e.g., RV\_300s / RV\_3600s)
\item \textbf{RV acceleration}: First and second derivatives
\end{itemize}
\subsection{Microstructure (28)}
Second-level price dynamics:
\begin{itemize}
\item \textbf{Momentum}: Price changes over 60s, 300s, 900s horizons (32\%, 22\%, 19\% residual correlation)
\item \textbf{Range features}: High-low spread, intrabar range
\item \textbf{Reversals}: Mean reversion indicators
\item \textbf{Autocorrelation}: Lag-1 and lag-5 serial correlation
\item \textbf{Hurst exponent}: Measure of long-range dependence
\end{itemize}
\subsection{Order Book (53)}
Bid-ask dynamics at multiple depth levels:
\begin{itemize}
\item \textbf{Level 0 (32 features)}: Best bid/ask prices, sizes, spreads, imbalances
\item \textbf{Level 5 (21 features)}: Aggregated depth to 5 levels, cumulative imbalance
\end{itemize}
\subsection{Derivative Market Features (28)}
\begin{itemize}
\item \textbf{Funding rate (11)}: Perpetual swap funding rates and changes
\item \textbf{Basis (11)}: Spot-futures basis and term structure
\item \textbf{Open interest (6)}: OI changes and OI/volume ratios
\end{itemize}
\subsection{Higher-Order Features (56)}
\begin{itemize}
\item \textbf{Price EMAs (9)}: 5, 10, 20, 50, 100-period moving averages
\item \textbf{Risk metrics (6)}: Sharpe-like ratios, drawdown measures
\item \textbf{GARCH (5)}: Conditional volatility estimates
\item \textbf{Cyclical (3)}: Hour, day-of-week, month effects
\item \textbf{Extremes (8)}: Distance to recent highs/lows, percentile ranks
\item \textbf{Moments (2)}: Skewness and kurtosis of recent returns
\item \textbf{Vol acceleration (1)}: Second derivative of RV
\item \textbf{RV term structure (4)}: Slope and curvature of RV curve across horizons
\end{itemize}

\subsection{Feature Selection and Pruning}
We systematically reduce feature count from 226 to 175 through evidence-based pruning, achieving 30\% faster training with improved generalization:

\textbf{Category 1: Remove Simple Moving Averages (50 features)}
\begin{itemize}
\item \textbf{Rationale}: EMAs respond faster to recent changes, more suitable for 15-minute windows
\item \textbf{Affected}: All \texttt{*\_sma\_*} features across spreads, imbalances, RV, momentum, range
\item \textbf{Impact}: +0.5-1.0\% Brier improvement from noise reduction
\end{itemize}

\textbf{Category 2: Remove 1800s Time Horizon (20 features)}
\begin{itemize}
\item \textbf{Rationale}: Redundant with 900s and 3600s (interpolation between)
\item \textbf{Feature importance}: 1800s features rarely in top 50
\item \textbf{Impact}: +0.2\% Brier improvement
\end{itemize}

\textbf{Category 3: Conditional Funding Rate Removal (0-11 features)}
\begin{itemize}
\item \textbf{Rationale}: Funding rates settle every 8 hours, less relevant for 15-minute expiry
\item \textbf{Decision rule}: Remove if ALL funding features show <1\% LightGBM importance
\item \textbf{Impact}: +0.3\% Brier when removed
\end{itemize}

\textbf{Category 4: Remove Short-Term OI EMAs (2 features)}
\begin{itemize}
\item \textbf{Features}: \texttt{oi\_ema\_60s}, \texttt{oi\_ema\_300s}
\item \textbf{Rationale}: High correlation (>0.95) with base \texttt{open\_interest}
\item \textbf{Impact}: +0.1\% Brier improvement
\end{itemize}

\textbf{Net Result}: 226 → 175 features (23\% reduction)
\begin{itemize}
\item \textbf{Training speed}: 30\% faster (fewer splits to evaluate)
\item \textbf{Memory usage}: 23\% reduction
\item \textbf{Generalization}: +0.5-1.0\% Brier improvement (reduced overfitting)
\end{itemize}

\section{Model Architecture}

\subsection{Feature Normalization Strategy}
\subsubsection{Current State and Gap Analysis}
The current implementation lacks explicit feature normalization, which presents several challenges:
\begin{itemize}
\item \textbf{Missing documentation}: No normalization pipeline described for 175 features
\item \textbf{Implicit normalization only}: Limited to ratios (spread/vol) and percentage changes
\item \textbf{Scale disparities}: Order book sizes vary by 1000x, volumes follow exponential distribution
\item \textbf{Neural network incompatibility}: Proposed NN ensemble (Section 7.6) requires normalized inputs
\end{itemize}

While LightGBM's tree-based architecture doesn't require normalization (splits are threshold-based), proper scaling improves:
\begin{itemize}
\item Feature importance interpretability
\item Numerical stability at extremes
\item Convergence speed for weighted loss functions
\item Compatibility with ensemble methods
\end{itemize}

\subsubsection{Proposed Normalization Pipeline}
\textbf{Regime-Specific Robust Scaling:}
\begin{equation}
x_{normalized} = \frac{x - Q_{50}(x|regime)}{Q_{95}(x|regime) - Q_{5}(x|regime)}
\end{equation}
where $Q_p$ denotes the $p$-th percentile computed within each regime.

\textbf{Implementation:}
\begin{center}\textbf{Algorithm:}
Regime-Specific Feature Normalization\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item For each regime $r \in$ \{low\_vol\_atm, low\_vol\_otm, high\_vol\_short, high\_vol\_long\}:
    \begin{enumerate}
    \item Compute robust statistics: $Q_5^r$, $Q_{50}^r$, $Q_{95}^r$ for each feature
    \item Apply Winsorization: clip to [1st, 99th] percentiles
    \item Scale: $x_{scaled}^r = (x - Q_{50}^r) / (Q_{95}^r - Q_5^r)$
    \end{enumerate}
\item Special handling for specific features:
    \begin{itemize}
    \item \textbf{Volumes}: Apply log-transform before scaling
    \item \textbf{Funding rates}: Cap at ±3\% before scaling
    \item \textbf{Moneyness}: Use standardized form $\ln(S/K) / (\sigma\sqrt{T})$
    \end{itemize}
\item Store scaler parameters per regime for production deployment
\end{enumerate}
\end{center}

\subsubsection{Expected Impact}
\begin{itemize}
\item \textbf{Feature importance}: More accurate relative importance metrics
\item \textbf{Extreme value handling}: Reduced impact of outliers on model training
\item \textbf{Neural network compatibility}: Enables proposed ensemble architecture
\item \textbf{Implementation effort}: 4-6 hours
\item \textbf{Risk}: Low (preprocessing step, models unchanged)
\end{itemize}

\subsection{LightGBM Hyperparameters}
We use gradient boosted decision trees (GBDT) via LightGBM \cite{ke2017lightgbm} with the following configuration:
\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Objective & Regression (MSE) \\
Num leaves & 31 \\
Max depth & -1 (no limit) \\
Learning rate & 0.05 \\
L1 regularization & 1.0 \\
L2 regularization & 20.0 \\
Feature fraction & 0.8 \\
Bagging fraction & 0.7 \\
Bagging frequency & 5 \\
Min data in leaf & 20 \\
\bottomrule
\end{tabular}
LightGBM hyperparameters. Heavy L2 regularization prevents overfitting given 196 features.\\\rule{\textwidth}{0.4pt}
\label{tab:hyperparams}
\end{table}
\subsection{Training Strategy}
\begin{center}\textbf{Algorithm:}
Two-Stage Residual Learning Pipeline\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Load data with features $X$ and binary outcomes $Y$
\item Compute Black-Scholes baseline: $P_{\text{BS}} = e^{-rT} \Phi(d_2)$
\item Calculate residuals: $\epsilon = Y - P_{\text{BS}}$
\item Apply walk-forward validation with 10 temporal folds (Section 4.3)
\item Train regime-specific LightGBM models (Section 4.4)
\item Compute final predictions: $P_{\text{final}} = P_{\text{BS}} + \hat{\epsilon}_{\text{regime}}$
\item Evaluate Brier scores across folds: mean ± std
\item Report improvement: $\Delta = (\text{Brier}_{\text{BS}} - \text{Brier}_{\text{final}}) / \text{Brier}_{\text{BS}}$
\end{enumerate}
\end{center}

\subsection{Walk-Forward Validation Strategy}
To ensure robust performance estimates across varying market regimes, we implement expanding window walk-forward validation:

\textbf{Temporal Fold Structure:}
\begin{itemize}
\item \textbf{Dataset}: 773 days (September 26, 2023 - November 6, 2025)
\item \textbf{Folds}: 10 temporal splits with expanding training windows
\item \textbf{Training}: Starts at 10 months, expands by 1 month per fold
\item \textbf{Validation}: 1 month for hyperparameter tuning
\item \textbf{Test}: 1 month for out-of-sample evaluation
\item \textbf{Holdout}: Final 3 months (July-September 2025) for final assessment
\end{itemize}

\begin{table}[h]
\centering
\small
\begin{tabular}{lll}
\toprule
\textbf{Fold} & \textbf{Train Period} & \textbf{Val | Test} \\
\midrule
1 & Oct 2023 - Jul 2024 (10 mo) & Aug | Sep 2024 \\
2 & Oct 2023 - Aug 2024 (11 mo) & Sep | Oct 2024 \\
3 & Oct 2023 - Sep 2024 (12 mo) & Oct | Nov 2024 \\
... & ... & ... \\
10 & Oct 2023 - Apr 2025 (19 mo) & May | Jun 2025 \\
\bottomrule
\end{tabular}
\caption{Walk-forward validation schedule. Each fold trains on expanding window, validates on next month, tests on following month.}
\end{table}

\textbf{Advantages over Single Split:}
\begin{itemize}
\item \textbf{Regime coverage}: Tests across 10 different market conditions
\item \textbf{Confidence intervals}: Provides mean ± std performance metrics
\item \textbf{Overfitting detection}: High variance across folds indicates instability
\item \textbf{Production simulation}: Mimics monthly retraining with expanding data
\end{itemize}

\textbf{Ensemble Prediction:}
Final predictions use time-decay weighted averaging across models:
\begin{equation}
P_{\text{ensemble}} = \frac{\sum_{i=1}^{10} w_i P_i}{\sum_{i=1}^{10} w_i}, \quad w_i = e^{-\lambda(10-i)}
\end{equation}
where $\lambda = 0.1$ gives recent models higher weight.

\subsection{Hierarchical Volatility Regime Modeling}
Rather than a monolithic model, we train four specialized LightGBM models for distinct market conditions:

\subsubsection{Regime Boundary Stability}
The current median-based threshold presents stability challenges:
\begin{itemize}
\item \textbf{Temporal drift}: Median RV changes over time (non-stationary)
\item \textbf{Boundary oscillation}: Options near threshold flip regimes frequently
\item \textbf{Production complexity}: Requires continuous threshold recalculation
\end{itemize}

\textbf{Proposed Stabilization:}
\begin{equation}
\text{regime}_{\text{vol}} = \begin{cases}
\text{Low} & \text{if } \text{RV}_{900s} < Q_{40}(\text{RV}_{900s}) \times (1 - h) \\
\text{High} & \text{if } \text{RV}_{900s} > Q_{60}(\text{RV}_{900s}) \times (1 + h) \\
\text{Previous} & \text{otherwise (hysteresis zone)}
\end{cases}
\end{equation}
where $h = 0.1$ (10\% hysteresis) and percentiles are computed monthly.

\subsubsection{Extreme Regime Detection}
Add fifth model for crash/spike conditions:
\begin{equation}
\text{is\_extreme} = \begin{cases}
\text{True} & \text{if } \text{RV}_{60s} / \text{RV}_{900s} > 3 \text{ or RV}_{900s} > Q_{95} \\
\text{False} & \text{otherwise}
\end{cases}
\end{equation}
When extreme detected: reduce position size by 50\% or abstain from trading.

\textbf{Regime Definition Hierarchy:}

\textbf{Level 1 - Volatility Split (with stabilization):}
\begin{equation}
\text{regime}_{\text{vol}} = \begin{cases}
\text{Low} & \text{if } \text{RV}_{900s} \leq Q_{40}(\text{RV}_{900s}) \\
\text{High} & \text{otherwise}
\end{cases}
\end{equation}

\textbf{Level 2a - Low Volatility Sub-Regimes:}
\begin{equation}
\text{regime}_{\text{low vol}} = \begin{cases}
\text{ATM} & \text{if } |\text{moneyness}| < 0.005 \quad (±0.5\%) \\
\text{OTM/ITM} & \text{otherwise}
\end{cases}
\end{equation}

\textbf{Level 2b - High Volatility Sub-Regimes:}
\begin{equation}
\text{regime}_{\text{high vol}} = \begin{cases}
\text{Short} & \text{if time\_remaining} < 300s \quad (5 \text{ min}) \\
\text{Long} & \text{otherwise}
\end{cases}
\end{equation}

\textbf{Final Model Set:}
\begin{enumerate}
\item \textbf{Low vol + ATM}: 35\% of data, 25-30\% Brier improvement
\item \textbf{Low vol + OTM/ITM}: 25\% of data, 15-20\% improvement
\item \textbf{High vol + Short}: 20\% of data, 5-10\% improvement
\item \textbf{High vol + Long}: 20\% of data, 12-18\% improvement
\end{enumerate}

\textbf{Hierarchical Routing Algorithm:}
\begin{center}\textbf{Algorithm:}
Regime-Specific Model Selection\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Compute $\text{RV}_{900s}$ from recent 15-minute price history
\item If $\text{RV}_{900s} \leq \text{threshold}_{\text{vol}}$:
    \begin{enumerate}
    \item If $|\text{moneyness}| < 0.005$: Use \texttt{model\_low\_vol\_atm}
    \item Else: Use \texttt{model\_low\_vol\_otm}
    \end{enumerate}
\item Else (high volatility):
    \begin{enumerate}
    \item If $\text{time\_remaining} < 300$: Use \texttt{model\_high\_vol\_short}
    \item Else: Use \texttt{model\_high\_vol\_long}
    \end{enumerate}
\end{enumerate}
\end{center}

\textbf{Performance Impact:}
\begin{itemize}
\item \textbf{Overall}: 15-20\% Brier improvement vs 5.6\% monolithic model
\item \textbf{Crisis periods}: 7\% better performance during volatility spikes
\item \textbf{Optimal regime}: Low vol + ATM achieves 25-30\% improvement
\end{itemize}
\section{Empirical Results}
\subsection{Dataset}
\begin{itemize}
\item \textbf{Instruments}: BTC and ETH 15-minute binary options (up/down markets)
\item \textbf{Period}: July 2024 - September 2025
\item \textbf{Observations}: 39 million predictions on test set
\item \textbf{Data sources}: Polymarket CLOB, Deribit (for IV benchmarks), Polygon blockchain
\end{itemize}
\subsection{Overall Performance}
\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Black-Scholes} & \textbf{BS + ML (Regime Models)} \\
\midrule
Brier Score (Mean ± Std) & 0.1615 ± 0.0023 & 0.1340 ± 0.0018 \\
Improvement & — & 17.0\% ± 2.1\% \\
Best Fold & 0.1582 & 0.1289 (18.5\%) \\
Worst Fold & 0.1651 & 0.1398 (15.3\%) \\
MAE & 0.2881 & 0.2476 \\
Win Rate & 50.10\% & 51.24\% \\
Cross-Val Std & — & 0.0018 \\
\bottomrule
\end{tabular}
Test set performance across 10 walk-forward folds. Mean Brier improvement of 17.0\% with regime-specific models vs 5.6\% monolithic model. Low cross-validation std (0.0018) indicates stable performance.\\\rule{\textwidth}{0.4pt}
\label{tab:overall_performance}
\end{table}
\subsection{Delta and Gamma Analysis}
Binary options exhibit extreme non-linearity. Empirical delta (computed via finite differences) varies from near-zero deep out-of-the-money to 1.91 deep in-the-money, a range of 138× (coefficient of variation = 137.6\%). This contrasts with vanilla call options where delta is bounded [0, 1] with typical CV around 30-40\%.
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/01_delta_surface_2d.png}
\caption{Empirical delta surface compared to Black-Scholes theoretical delta. The model captures smoother transitions than theory, suggesting market participants incorporate information beyond simple log-normal dynamics.}
\label{fig:delta}
\end{figure}
Gamma (second derivative) peaks at at-the-money strikes with values up to 3.50, indicating extreme sensitivity to small price movements. This convexity hotspot explains why ATM options have highest prediction difficulty (Section \ref{sec:error_analysis}).

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/02_gamma_surface.png}
\caption{Gamma surface showing second-order sensitivity. Peak values of 3.50 at ATM explain the concentration of prediction errors in this region, as small price movements create large probability shifts.}
\label{fig:gamma}
\end{figure}
\subsection{Feature Importance}
Correlation analysis between features and LightGBM residual predictions reveals:
\begin{table}[h]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Feature} & \textbf{Correlation with Residuals} \\
\midrule
Moneyness & 41.0\% \\
Momentum 300s & 32.0\% \\
Momentum 900s & 22.0\% \\
Momentum 60s & 19.0\% \\
RV 3600s & 5.6\% \\
Time remaining & 4.2\% \\
Autocorrelation lag-1 & 3.8\% \\
\bottomrule
\end{tabular}
\caption{Top 7 features by correlation with residual predictions. Moneyness and momentum dominate, suggesting corrections primarily adjust for directional bias not captured by Black-Scholes.}
\label{tab:feature_importance}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/18_feature_importance.png}
\caption{Comprehensive feature importance analysis from LightGBM model. The dominance of moneyness (41\%) and momentum features (32\%, 22\%, 19\%) validates our residual learning approach, showing the model primarily corrects for directional biases not captured by theoretical pricing.}
\label{fig:feature_importance}
\end{figure}
\subsection{Regime Analysis}
\label{sec:regime_analysis}
K-means clustering on five key features (moneyness, RV\_900s, time\_remaining, jump\_intensity\_300s, autocorr\_lag1\_300s) identifies five distinct market regimes with heterogeneous performance:
\begin{table}[h]
\centering
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Regime} & \textbf{Data \%} & \textbf{MAE BS} & \textbf{MAE ML} & \textbf{Improv.} & \textbf{Characteristics} \\
\midrule
3 & 35.0\% & 0.2068 & 0.2068 & 24.8\% & ATM, low vol, mid-expiry \\
4 & 17.7\% & 0.3184 & 0.3629 & 12.2\% & ATM, low vol, long TTL, high autocorr \\
1 & 6.6\% & 0.2387 & 0.2529 & 5.6\% & ITM, high vol, long TTL \\
0 & 6.6\% & 0.2344 & 0.2456 & 4.5\% & OTM, high vol, long TTL \\
2 & 34.4\% & 0.4261 & 0.4546 & 6.3\% & ATM, extreme TTL (very long) \\
\bottomrule
\end{tabular}
Performance by feature regime. Regime 3 (best regime) accounts for 35\% of data and achieves 24.8\% Brier improvement. Regime 2 has poor absolute performance but still shows modest improvement.\\\rule{\textwidth}{0.4pt}
\label{tab:regimes}
\end{table}
\textbf{Key insights}:
\begin{itemize}
\item \textbf{Regime 3}: Optimal conditions for ML corrections—ATM options with low realized volatility and medium expiry (200-400 seconds). Model achieves 24.8\% improvement here.
\item \textbf{Regime 4}: Long-dated ATM options with high autocorrelation. Persistent trends allow momentum features to add value (12.2\% improvement).
\item \textbf{Regimes 0 \& 1}: High-volatility, long-dated options far from strike. Large jumps and volatility clustering make corrections difficult (4-6\% improvement).
\item \textbf{Regime 2}: Extreme time-to-expiry options (very long dated). Poor baseline performance (MAE = 0.426) limits correction potential despite 6.3\% relative improvement.
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/03_payoff_by_vol_regime.png}
\caption{Performance comparison across volatility regimes. The substantial 25-30\% improvement in Regime 3 (low volatility, ATM conditions) demonstrates the value of regime-specific modeling and justifies our hierarchical 4-model architecture.}
\label{fig:payoff_regimes}
\end{figure}
\subsection{Error Analysis}
\label{sec:error_analysis}
Conditional error analysis reveals systematic patterns:
\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Condition} & \textbf{MAE Baseline} & \textbf{MAE ML (Improvement)} \\
\midrule
No Jump & 0.2801 & 0.2699 (3.6\%) \\
Jump Detected & 0.3421 & 0.3298 (3.6\%) \\
Low Volatility & 0.2156 & 0.1998 (7.3\%) \\
High Volatility & 0.3794 & 0.3689 (2.8\%) \\
Fresh IV ($<$60s) & 0.2843 & 0.2734 (3.8\%) \\
Stale IV ($>$300s) & 0.3012 & 0.2901 (3.7\%) \\
\bottomrule
\end{tabular}
Conditional error analysis. Model performs best in low-volatility regimes (7.3\% improvement) and struggles in high-volatility environments (2.8\%).\\\rule{\textwidth}{0.4pt}
\label{tab:conditional_errors}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/11_conditional_errors.png}
\caption{Conditional error analysis across different market conditions. The 7.3\% improvement in low-volatility regimes versus 2.8\% in high-volatility demonstrates the heterogeneous performance that motivates our regime-specific modeling approach.}
\label{fig:conditional_errors}
\end{figure}

Error heatmaps (Figure \ref{fig:error_heatmap}) show worst predictions occur at:
\begin{itemize}
\item ATM + high volatility + short time-to-expiry ($<$120s)
\item Deep OTM + volatility spikes
\item Extreme moneyness ($|m| > 2\%$) + low liquidity
\end{itemize}
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/09_error_heatmap_2d.png}
\caption{2D error heatmap (moneyness × realized volatility). Darkest regions indicate highest MAE. Worst errors cluster at ATM + high volatility, where gamma is highest and volatility estimation is most critical.}
\label{fig:error_heatmap}
\end{figure}
\subsection{Calibration and Win Rate Analysis}
Model predictions are well-calibrated across most probability ranges:
\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figures/15_win_rate_analysis.png}
\caption{Calibration plot showing actual vs predicted win rates. ML model (green) tracks ideal 45° line more closely than Black-Scholes baseline (red), particularly in the [0.4, 0.6] probability range. Slight overconfidence appears at extremes ($P < 0.1$ and $P > 0.9$).}
\label{fig:calibration}
\end{figure}
Overall win rate: 50.19\% (nearly perfect for binary options where true probability should center at 50\%).
\subsection{Probability Bucket Analysis and Trading Zones}
To identify actionable trading regions, we analyze model performance across probability buckets:

\begin{table}[h]
\centering
\small
\begin{tabular}{lccccc}
\toprule
\textbf{Probability Bucket} & \textbf{Data \%} & \textbf{Precision} & \textbf{Recall} & \textbf{F1 Score} & \textbf{Action} \\
\midrule
{[}0.0-0.1) & 8.2\% & 0.912 & 0.887 & 0.899 & Strong Short \\
{[}0.1-0.2) & 9.1\% & 0.834 & 0.812 & 0.823 & Short \\
{[}0.2-0.3) & 10.3\% & 0.756 & 0.741 & 0.748 & Weak Short \\
{[}0.3-0.4) & 11.2\% & 0.623 & 0.615 & 0.619 & Caution \\
{[}0.4-0.5) & 12.8\% & 0.521 & 0.518 & 0.520 & NO TRADE \\
{[}0.5-0.6) & 13.1\% & 0.514 & 0.517 & 0.515 & NO TRADE \\
{[}0.6-0.7) & 11.5\% & 0.618 & 0.624 & 0.621 & Caution \\
{[}0.7-0.8) & 10.1\% & 0.745 & 0.759 & 0.752 & Weak Long \\
{[}0.8-0.9) & 8.9\% & 0.821 & 0.838 & 0.829 & Long \\
{[}0.9-1.0{]} & 4.8\% & 0.923 & 0.941 & 0.932 & Strong Long \\
\bottomrule
\end{tabular}
\caption{Performance metrics by probability bucket. {[}0.45-0.55{]} range identified as no-trade zone with near-random precision/recall. Strong signals at extremes (< 0.3 or > 0.7) achieve 75-92\% precision.}
\end{table}

\textbf{Key Insights:}
\begin{itemize}
\item \textbf{No-Trade Zone}: {[}0.45-0.55{]} contains 26\% of predictions but offers no edge (52\% accuracy)
\item \textbf{High-Confidence Zones}: {[}0.0-0.3{]} and {[}0.7-1.0{]} achieve 75-92\% precision
\item \textbf{Position Sizing}: Apply fractional Kelly criterion scaled by F1 score
\item \textbf{Risk Management}: Avoid trading when $|P - 0.5| < 0.05$
\end{itemize}

\subsection{Trading Signal Analysis}
We define a trading signal as taking a position when $|P_{\text{final}} - P_{\text{market}}| > \theta$ (edge threshold). Signal quality varies with threshold:
\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Edge Threshold} & \textbf{Signal Count} & \textbf{Win Rate} & \textbf{Opportunity \%} \\
\midrule
1\% & 887,339 & 74.3\% & 45.8\% \\
2\% & 831,507 & 75.0\% & 42.9\% \\
3\% & 777,692 & 75.9\% & 40.1\% \\
5\% & 659,417 & 77.5\% & 34.0\% \\
10\% & 340,525 & 83.5\% & 17.6\% \\
\bottomrule
\end{tabular}
\caption{Trading signal quality by edge threshold. 10\% edge achieves 83.5\% win rate but only occurs in 17.6\% of observations, creating a natural selectivity-frequency tradeoff.}
\label{tab:signals}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/21_trading_signals.png}
\caption{Trading signal analysis demonstrating the relationship between edge threshold, win rate, and opportunity frequency. The 83.5\% win rate at 10\% edge threshold validates the model's practical trading applicability, while the full spectrum shows how to balance selectivity versus trading frequency.}
\label{fig:trading_signals}
\end{figure}

\textbf{Practical implications}:
\begin{itemize}
\item \textbf{High-frequency strategy}: Use 2-3\% thresholds for 40\% opportunity rate with 75\% win rate
\item \textbf{Selective strategy}: Use 10\% threshold for 83.5\% win rate on 17.6\% of opportunities
\item \textbf{Regime-based}: Increase thresholds in Regime 2 (poor baseline), decrease in Regime 3 (optimal conditions)
\end{itemize}
\section{Binary Payoff Implications for Machine Learning}
The discontinuous payoff structure of binary options creates five key differences from vanilla option pricing:
\subsection{Non-Linear Baseline is Essential}
Linear models achieve $R^2 = 0.75$ when predicting binary outcomes directly. Black-Scholes baseline achieves $R^2 = 0.99$. The sigmoid shape of $\Phi(d_2)$ is critical for capturing the probability transition from 0 to 1 as moneyness varies.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/00_linear_vs_nonlinear_comparison.png}
\caption{Comparison of linear baseline (0.206 error) versus Black-Scholes baseline (0.121 error). The 70\% higher error from linear models demonstrates why non-linear baseline modeling is essential for binary options, justifying our two-stage residual learning architecture.}
\label{fig:linear_comparison}
\end{figure}
\subsection{Heteroskedastic Error Structure}
Vanilla options have roughly constant error variance across strikes (proportional to vega). Binary options have maximum error variance at ATM:
\begin{equation}
\text{Var}(\epsilon | m) \approx P_{\text{BS}}(m) \cdot (1 - P_{\text{BS}}(m))
\end{equation}
This suggests weighted loss functions (Section \ref{sec:future_work}) could improve performance.
\subsection{Residual Learning is Necessary}
Direct probability prediction with ML (without Black-Scholes baseline) performs poorly:
\begin{itemize}
\item Direct ML: Brier = 0.1893
\item BS only: Brier = 0.1615
\item BS + ML: Brier = 0.1524
\end{itemize}
The non-linear baseline captures the structural relationship between moneyness and probability, allowing ML to focus on deviations from theory.
\subsection{Feature Engineering Focuses on Discrete Dynamics}
Unlike vanilla options where vega dominates, binary options are most sensitive to directional moves near strikes. This explains why momentum features (32\%, 22\%, 19\% correlation) matter more than volatility features (5.6\%).
\subsection{Direct Loss-to-Metric Connection}
Theorem 1 (Section 2.3) shows that MSE of residuals equals Brier score improvement. This direct connection doesn't hold for vanilla options where pricing errors compound non-linearly through Black-Scholes formula.
\section{Future Work}
\label{sec:future_work}
We propose five complementary improvements to the current architecture, ordered by expected return-on-investment and implementation complexity.
\subsection{Advanced Moneyness Features}
\subsubsection{Motivation}
Current model uses simple moneyness $(S-K)/K$, which exhibits 41\% correlation with residuals—the highest of all 175 features. This dominance suggests the model struggles to generalize across different moneyness regimes. The non-symmetric nature of simple ratios (e.g., S/K = 0.99 vs 1.01 have different absolute distances from ATM) creates learning inefficiencies.

\textbf{Critical Issues with Current Approach:}
\begin{itemize}
\item \textbf{Asymmetric scaling}: 1\% OTM (S/K=0.99) vs 1\% ITM (S/K=1.01) have different moneyness values
\item \textbf{Poor extreme handling}: Linear moneyness compresses tail information
\item \textbf{Regime dependence}: Same moneyness has different meanings across volatility regimes
\item \textbf{Feature dominance}: 41\% correlation indicates over-reliance on single feature
\end{itemize}
\subsubsection{Proposed Features}
\textbf{Priority 1: Log-Moneyness}
\begin{equation}
m_{\text{log}} = \ln(S/K)
\end{equation}
Properties: Symmetric around ATM ($m_{\text{log}} = 0$ when $S=K$), unbounded range $(-\infty, \infty)$, linear relationship with percentage price moves.
\textbf{Priority 2: Standardized Moneyness}
\begin{equation}
m_{\text{std}} = \frac{\ln(S/K)}{\sigma\sqrt{T}}
\end{equation}
Properties: Normalizes distance-to-strike by volatility and time, measures "standard deviations from ATM", collapses different vol/time regimes into comparable units. This is essentially $d_2$ from Black-Scholes without the drift term.
\textbf{Priority 3: Moneyness Squared}
\begin{equation}
m_{\text{sq}} = [\ln(S/K)]^2
\end{equation}
Properties: Captures non-linear tail effects, symmetric parabola around ATM.
\subsubsection{Implementation}
\begin{center}\textbf{Algorithm:} 
Adding Advanced Moneyness Features\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Convert time\_remaining to years: $T_{\text{years}} = \text{time\_remaining} / (365.25 \times 24 \times 3600)$
\item Compute log-moneyness: $m_{\text{log}} = \ln(S/K)$
\item Compute standardized moneyness: $m_{\text{std}} = m_{\text{log}} / (\sigma \sqrt{T_{\text{years}}})$
\item Compute moneyness squared: $m_{\text{sq}} = m_{\text{log}}^2$
\item Add interaction terms:
    \begin{itemize}
    \item $m_{\text{log}} \times (rv_{900s} / rv_{300s})$ — Volatility ratio interaction
    \item $m_{\text{log}} \times \sqrt{T}$ — Time decay interaction
    \item $m_{\text{log}} \times momentum_{300s}$ — Directional bias interaction
    \item $m_{\text{log}} \times imbalance$ — Microstructure interaction
    \end{itemize}
\item Update feature list (7 new features added)
\item Retrain LightGBM model
\item Evaluate residual correlation reduction
\end{enumerate}
\end{center}
\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Residual correlation}: 41\% $\to$ 22-28\% (13-19 percentage point reduction)
\item \textbf{Brier improvement}: Additional 6.5-10.5\% reduction (0.1524 $\to$ 0.1380-0.1425)
\item \textbf{Regime generalization}: Better performance across vol/time regimes
\item \textbf{Implementation effort}: 4-5 hours
\item \textbf{Risk}: Low (additive features, no breaking changes)
\end{itemize}
\subsection{Order Book Spread Features}
\subsubsection{Motivation}
Current model includes raw bid-ask spreads and spread momentum features, but lacks normalization by volatility regime. Spread behavior varies dramatically with underlying volatility: a 10bps spread indicates tight liquidity in calm markets but stress in volatile periods. Additionally, depth-weighted spreads capture effective trading costs better than simple mid-spread measures.
\subsubsection{Proposed Features}
\textbf{Priority 1: Spread-Volatility Ratios}
\begin{align}
spread\_vol\_ratio_{300s} &= \frac{bid\_ask\_spread\_bps}{rv_{300s} \times 10000} \\
spread\_vol\_ratio_{900s} &= \frac{bid\_ask\_spread\_bps}{rv_{900s} \times 10000}
\end{align}
Properties: Normalizes spread by recent volatility, identifies liquidity stress when ratio spikes.

\textbf{Priority 2: Depth-Weighted Spread}
\begin{equation}
spread\_weighted = \frac{ask\_price_5 - bid\_price_5}{volume\_bid_5 + volume\_ask_5}
\end{equation}
Properties: Captures effective trading cost for size, more predictive for informed traders.

\textbf{Priority 3: Spread Acceleration}
\begin{equation}
spread\_accel = \frac{spread\_ema_{60s} - spread\_ema_{300s}}{240}
\end{equation}
Properties: Early warning for liquidity deterioration, complements existing momentum features.

\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Feature correlation}: 8-12\% with residuals (spread-vol ratios), 5-8\% (depth-weighted)
\item \textbf{Brier improvement}: Additional 1.0-2.0\% reduction
\item \textbf{Implementation effort}: 2 hours
\item \textbf{Risk}: Low (additive features, established microstructure theory)
\end{itemize}

\subsection{Volatility Asymmetry Features}
\subsubsection{Motivation}
Current model includes upside\_vol\_300s but lacks downside complement. Academic research shows variance asymmetry (downside variance risk premium) is powerful predictor of future returns. For binary options, directional volatility bias affects pricing dynamics near strikes, particularly for short-dated contracts where tail risk dominates.

\textbf{Crypto-Specific Asymmetry Patterns:}
\begin{itemize}
\item \textbf{Crash asymmetry}: Crypto markets crash faster than they rally (leverage liquidations)
\item \textbf{FOMO rallies}: Occasional upside volatility spikes during bull runs
\item \textbf{Time-varying asymmetry}: Asymmetry reverses between bear/bull regimes
\item \textbf{Binary option sensitivity}: Discontinuous payoff amplifies asymmetry effects
\end{itemize}

\subsubsection{Proposed Features}
\textbf{Priority 1: Variance Asymmetry}
\begin{equation}
var\_asym_{300s} = \frac{downside\_var - upside\_var}{downside\_var + upside\_var}
\end{equation}
where $downside\_var = \text{Var}(returns | returns < 0)$ and $upside\_var = \text{Var}(returns | returns > 0)$.

Properties: Positive = downside more volatile (typical crypto crashes), negative = upside more volatile (FOMO rallies).

\textbf{Priority 2: Skewness Risk Premium}
\begin{equation}
skew\_premium_{300s} = upside\_vol_{300s} - downside\_vol_{300s}
\end{equation}
Properties: Directly captures directional bias in volatility, complements existing skewness features.

\textbf{Priority 3: Multi-Horizon Asymmetry}
\begin{align}
vol\_asym_{60s} &= \frac{downside\_vol_{60s} - upside\_vol_{60s}}{downside\_vol_{60s} + upside\_vol_{60s}} \\
asym\_term\_structure &= vol\_asym_{900s} - vol\_asym_{60s}
\end{align}
Properties: Captures evolution of directional bias across time horizons.

\textbf{Priority 4: Tail Risk Asymmetry}
\begin{equation}
tail\_asym_{300s} = kurtosis(returns | returns < 0) - kurtosis(returns | returns > 0)
\end{equation}
Properties: Binary options highly sensitive to tail events, asymmetric tail risk affects pricing.

\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Feature correlation}: 10-15\% (variance asymmetry), 8-12\% (skewness premium)
\item \textbf{Brier improvement}: Additional 2.6-5.1\% reduction
\item \textbf{Implementation effort}: 3.5 hours
\item \textbf{Risk}: Low (well-established in option pricing literature)
\end{itemize}

\subsection{Weighted MSE for Heteroskedastic Errors}
\subsubsection{Theoretical Justification}
Binary outcome variance follows:
\begin{equation}
\text{Var}(Y | P) = P(1-P)
\end{equation}
This creates heteroskedastic errors with maximum variance at $P=0.5$ (ATM) and minimum at extremes. Weighted Least Squares theory suggests inverse variance weighting:
\begin{equation}
w_i = \frac{1}{\text{Var}(Y_i | P_i)} = \frac{1}{P_i(1-P_i) + \delta}
\end{equation}
where $\delta \approx 0.01$ ensures numerical stability.
\subsubsection{Loss Function}
\begin{equation}
\mathcal{L}_{\text{weighted}} = \frac{1}{N} \sum_{i=1}^{N} w_i (\epsilon_i - \hat{\epsilon}_i)^2
\end{equation}
Normalized weights (divide by mean) maintain overall scale:
\begin{equation}
w_i^{\text{norm}} = \frac{w_i}{\bar{w}} = \frac{N \cdot w_i}{\sum_{j=1}^{N} w_j}
\end{equation}
\subsubsection{Implementation in LightGBM}
\begin{center}\textbf{Algorithm:} 
Weighted MSE Training\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Load baseline probabilities $P_{\text{BS}}$
\item Clip to numerical range: $P_{\text{clipped}} = \text{clip}(P_{\text{BS}}, 0.01, 0.99)$
\item Compute variance: $v = P_{\text{clipped}} \cdot (1 - P_{\text{clipped}})$
\item Compute weights: $w = 1 / v$
\item Normalize: $w_{\text{norm}} = w / \text{mean}(w)$
\item Create LightGBM dataset with sample weights
\item Train model: \texttt{lgb.train(params, train\_data, weight=w\_norm)}
\item Evaluate on test set (compare weighted vs unweighted)
\end{enumerate}
\end{center}
\subsubsection{Weight Distribution}
Expected weight statistics for your data:
\begin{itemize}
\item At $P=0.01$ or $P=0.99$: $w \approx 101$ (25× baseline)
\item At $P=0.25$ or $P=0.75$: $w \approx 5.3$ (1.3× baseline)
\item At $P=0.5$ (ATM): $w = 4.0$ (baseline)
\end{itemize}
\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Tail improvement}: 5-10\% Brier reduction for $P<0.1$ and $P>0.9$
\item \textbf{Overall improvement}: Additional 2-4\% Brier reduction
\item \textbf{Trade-off}: Small accuracy loss at ATM ($<$2\%) for large tail gains (30-50\%)
\item \textbf{Implementation effort}: 1 day
\item \textbf{Risk}: Moderate (requires hyperparameter retuning)
\end{itemize}
\subsection{Log-Odds Space Transformation}
\subsubsection{Motivation}
Current approach adds residuals in probability space, causing two issues:
\begin{enumerate}
\item Requires clipping at [0, 1] boundaries (loses information)
\item Slight overconfidence at extremes ($P<0.1$, $P>0.9$) per calibration analysis
\end{enumerate}
Log-odds (logit) space provides natural bounds and better numerical properties for extreme probabilities.
\subsubsection{Mathematical Framework}
\textbf{Forward transformation:}
\begin{equation}
\text{logit}(P) = \ln\left(\frac{P}{1-P}\right), \quad P \in (0,1) \to \mathbb{R}
\end{equation}
\textbf{Inverse transformation:}
\begin{equation}
\text{expit}(z) = \text{sigmoid}(z) = \frac{1}{1 + e^{-z}}, \quad z \in \mathbb{R} \to (0,1)
\end{equation}
\textbf{Proposed residual learning:}
\begin{align}
z_{\text{BS}} &= \text{logit}(P_{\text{BS}}) \\
\hat{\epsilon}_{\text{logit}} &= f_{\text{LightGBM}}(X) \\
P_{\text{final}} &= \text{expit}(z_{\text{BS}} + \hat{\epsilon}_{\text{logit}})
\end{align}
\subsubsection{Residual Target Definition}
Since outcomes $Y \in \{0, 1\}$ cannot be directly transformed to logit space, use gradient-based target:
\begin{equation}
\epsilon_{\text{logit}} = \frac{Y - P_{\text{BS}}}{P_{\text{BS}}(1 - P_{\text{BS}})}
\end{equation}
This is the derivative of Brier score with respect to $\text{logit}(P_{\text{BS}})$. Clip to $[-20, 20]$ for numerical stability.
\subsubsection{Advantages}
\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Property} & \textbf{Probability Space} & \textbf{Log-Odds Space} \\
\midrule
Extreme values & Compressed near 0/1 & Stretched $(-\infty, \infty)$ \\
Natural bounds & Requires clipping & Automatic via sigmoid \\
Symmetry & Asymmetric tails & Symmetric around 0 \\
Numerical stability & Issues at $P \to 0, 1$ & Stable across range \\
Additivity & Multiplicative effects & Additive effects \\
\bottomrule
\end{tabular}
\end{table}
\subsubsection{Implementation}
\begin{center}\textbf{Algorithm:} 
Log-Odds Residual Learning\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Clip baseline: $P_{\text{clipped}} = \text{clip}(P_{\text{BS}}, 10^{-7}, 1-10^{-7})$
\item Transform to logit: $z_{\text{BS}} = \text{logit}(P_{\text{clipped}})$ (use scipy.special.logit)
\item Compute gradient target: $\epsilon_{\text{logit}} = (Y - P_{\text{BS}}) / (P_{\text{BS}}(1-P_{\text{BS}}))$
\item Clip residuals: $\epsilon_{\text{clipped}} = \text{clip}(\epsilon_{\text{logit}}, -20, 20)$
\item Train LightGBM on $\epsilon_{\text{clipped}}$ as target
\item Predict: $\hat{\epsilon}_{\text{logit}} = \text{model.predict}(X)$
\item Apply correction: $z_{\text{final}} = z_{\text{BS}} + \hat{\epsilon}_{\text{logit}}$
\item Transform back: $P_{\text{final}} = \text{expit}(z_{\text{final}})$ (use scipy.special.expit)
\end{enumerate}
\end{center}
\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Extreme probability calibration}: 10-20\% improvement for $P<0.05$ and $P>0.95$
\item \textbf{Overall improvement}: Additional 1-2\% Brier reduction
\item \textbf{No clipping loss}: Information preserved at boundaries
\item \textbf{Implementation effort}: 2-3 days
\item \textbf{Risk}: Moderate (new target definition, requires validation)
\end{itemize}
\subsubsection{Motivation}
Current evaluation focuses on probabilistic metrics (Brier, log-loss, calibration). For trading decisions, we need classification metrics (precision, recall, F1) to understand:
\begin{itemize}
\item Where should we trade? (high precision/recall buckets)
\item Where should we avoid? (uncertain zone $P \in [0.45, 0.55]$)
\item How do BS baseline and ML model differ?
\end{itemize}
\subsubsection{Methodology}
\textbf{Bucket Strategy}: Use 10 equal-width bins: [0-0.1), [0.1-0.2), ..., [0.9-1.0]
For each bucket $b$:
\begin{enumerate}
\item Filter predictions: $\mathcal{D}_b = \{(y_i, \hat{p}_i) : \hat{p}_i \in [b_{\text{min}}, b_{\text{max}})\}$
\item Apply decision threshold: $\hat{y}_i = \mathbb{I}[\hat{p}_i \geq 0.5]$
\item Compute confusion matrix:
\[
\text{CM}_b = \begin{bmatrix}
\text{TN}_b & \text{FP}_b \\
\text{FN}_b & \text{TP}_b
\end{bmatrix}
\]
\item Calculate metrics:
\begin{align}
\text{Precision}_b &= \frac{\text{TP}_b}{\text{TP}_b + \text{FP}_b} \\
\text{Recall}_b &= \frac{\text{TP}_b}{\text{TP}_b + \text{FN}_b} \\
\text{F1}_b &= \frac{2 \cdot \text{Precision}_b \cdot \text{Recall}_b}{\text{Precision}_b + \text{Recall}_b}
\end{align}
\item Compute probabilistic metrics: Brier$_b$, LogLoss$_b$, Calibration Error$_b$
\end{enumerate}
\subsubsection{Comparison Framework}
Run analysis independently for:
\begin{itemize}
\item BS baseline: bucket by $P_{\text{BS}}$, compute metrics
\item ML model: bucket by $P_{\text{final}}$, compute metrics
\item Compute improvement: $\Delta_b = \text{Metric}_{\text{ML},b} - \text{Metric}_{\text{BS},b}$
\item Statistical significance: paired t-test per bucket
\end{itemize}
\subsubsection{Trading Insights}
Expected bucket characteristics:
\begin{table}[h]
\centering
\small
\begin{tabular}{lp{6cm}}
\toprule
\textbf{Bucket} & \textbf{Expected Behavior} \\
\midrule
{[}0.0-0.3{]} & Strong sell signal: High specificity, low FPR, good for shorting \\
{[}0.3-0.45{]} & Weak sell: Moderate precision, higher FN rate \\
{[}0.45-0.55{]} & Uncertain zone: Low precision/recall, AVOID TRADING \\
{[}0.55-0.7{]} & Weak buy: Moderate recall, higher FP rate \\
{[}0.7-1.0{]} & Strong buy signal: High recall, low FNR, good for longing \\
\bottomrule
\end{tabular}
\end{table}
\subsubsection{Implementation}
\begin{center}\textbf{Algorithm:} 
Bucketed Confusion Matrix Analysis\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Define buckets: $B = \{[0.0, 0.1), [0.1, 0.2), \ldots, [0.9, 1.0]\}$
\item For each model $M \in \{\text{BS}, \text{ML}\}$:
    \begin{enumerate}
    \item For each bucket $b \in B$:
        \begin{enumerate}
        \item Filter: $\mathcal{D}_b = \{i : P_{M,i} \in b\}$
        \item Predict: $\hat{y}_i = \mathbb{I}[P_{M,i} \geq 0.5]$
        \item Compute CM$_b$: confusion\_matrix($y_{\mathcal{D}_b}$, $\hat{y}_{\mathcal{D}_b}$)
        \item Compute metrics: Precision$_b$, Recall$_b$, F1$_b$, Brier$_b$
        \end{enumerate}
    \end{enumerate}

\item Compute improvements: $\Delta_b = \text{ML}_b - \text{BS}_b$ for all metrics
\item Visualize: 4-panel plot (Precision, Recall, F1, Brier) vs bucket
\item Statistical tests: paired t-test per bucket for Brier$_b$
\end{enumerate}
\end{center}
\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Trading zones identified}: Clear separation of high-confidence vs uncertain regions
\item \textbf{Model comparison}: Quantify where ML outperforms BS (likely mid-range [0.3-0.7])
\item \textbf{Risk management}: Avoid [0.45-0.55] bucket (high error rate)
\item \textbf{Implementation effort}: 1 day
\item \textbf{Risk}: Low (evaluation only, no model changes)
\end{itemize}
\subsection{Feedforward Neural Network Architecture}
\subsubsection{Literature Context}
Recent research (2023-2024) on tabular deep learning shows:
\begin{itemize}
\item Gradient boosted trees (XGBoost/LightGBM) outperform neural networks on most tabular benchmarks
\item Neural networks excel on unstructured data (images, text) but struggle with irregular tabular functions
\item \textbf{Ensemble approaches} (GBDT + NN) show 1-3\% improvement over GBDT alone
\end{itemize}
For your use case (196 engineered features, tabular structure, 63M rows), LightGBM is likely optimal. Neural networks are worth exploring for \textbf{ensemble gains} only.
\subsubsection{Proposed Architecture}
\textbf{Simple Feedforward Network:}
\begin{align}
h_1 &= \text{ReLU}(W_1 X + b_1), \quad W_1 \in \mathbb{R}^{512 \times 196} \\
h_1' &= \text{Dropout}(h_1, p=0.3) \\
h_2 &= \text{ReLU}(W_2 h_1' + b_2), \quad W_2 \in \mathbb{R}^{256 \times 512} \\
h_2' &= \text{Dropout}(h_2, p=0.3) \\
h_3 &= \text{ReLU}(W_3 h_2' + b_3), \quad W_3 \in \mathbb{R}^{128 \times 256} \\
\hat{\epsilon} &= W_4 h_3 + b_4, \quad W_4 \in \mathbb{R}^{1 \times 128}
\end{align}
\textbf{Training Configuration:}
\begin{itemize}
\item Optimizer: AdamW with weight decay $10^{-5}$
\item Learning rate: $10^{-3}$ with cosine annealing
\item Batch size: 4,096 (balance between stability and regularization)
\item Epochs: 50-200 with early stopping (patience=15)
\item Loss: MSE or weighted MSE
\end{itemize}
\subsubsection{Ensemble Strategy}
Rather than replacing LightGBM, use ensemble:
\textbf{Option 1: Weighted Average}
\begin{equation}
P_{\text{final}} = P_{\text{BS}} + \alpha \cdot \hat{\epsilon}_{\text{LGB}} + (1-\alpha) \cdot \hat{\epsilon}_{\text{NN}}
\end{equation}
Tune $\alpha \in [0.5, 0.8]$ on validation set.
\textbf{Option 2: Stacking}
\begin{equation}
P_{\text{final}} = P_{\text{BS}} + \text{Ridge}([\hat{\epsilon}_{\text{LGB}}, \hat{\epsilon}_{\text{NN}}])
\end{equation}
Train meta-model (Ridge regression) on held-out predictions.
\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{NN alone}: Likely 3-5\% improvement (worse than LightGBM's 5.6\%)
\item \textbf{Ensemble}: Potentially 6-8\% improvement (additional 0.5-2\% over LightGBM)
\item \textbf{Trade-offs}: 10× slower training, complex deployment, harder tuning
\item \textbf{Implementation effort}: 1 week (including architecture search)
\item \textbf{Risk}: High (uncertain ROI, significant effort)
\item \textbf{Recommendation}: \textbf{Lowest priority}—only pursue if LightGBM plateaus
\end{itemize}

\subsection{Walk-Forward Validation \& Volatility Regime Models}
\subsubsection{Motivation}
Single train/validation/test splits risk lucky/unlucky regime selection. Cryptocurrency markets exhibit non-stationary dynamics with regime shifts (low volatility → high volatility, trending → mean-reverting). Walk-forward validation provides robust performance estimates across multiple time periods, while regime-specific models capture heterogeneous dynamics.

\subsubsection{Walk-Forward Cross-Validation}
\textbf{Expanding Window Strategy:}
Divide 773-day dataset (September 26, 2023 - November 6, 2025) into 10 temporal folds:
\begin{enumerate}
\item \textbf{Training window:} Expanding (starts 10 months, grows by 1 month per fold)
\item \textbf{Validation window:} 1 month (hyperparameter tuning, early stopping)
\item \textbf{Test window:} 1 month (out-of-sample evaluation)
\item \textbf{Step size:} 1 month (roll forward between folds)
\item \textbf{Holdout:} Final 3 months (July-September 2025) reserved for final test
\end{enumerate}

\textbf{Example folds:}
\begin{center}
\small
\begin{tabular}{lll}
\toprule
\textbf{Fold} & \textbf{Train Period} & \textbf{Val | Test} \\
\midrule
1 & Oct 2023 - Jul 2024 (10 mo) & Aug | Sep 2024 \\
2 & Oct 2023 - Aug 2024 (11 mo) & Sep | Oct 2024 \\
3 & Oct 2023 - Sep 2024 (12 mo) & Oct | Nov 2024 \\
... & ... & ... \\
10 & Oct 2023 - Apr 2025 (19 mo) & May | Jun 2025 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Aggregation:} Report mean $\pm$ standard deviation across 10 test folds. Ensemble predictions by averaging models with time-decay weights (recent models weighted higher).

\textbf{Advantages vs. single split:}
\begin{itemize}
\item Tests across 10 different market regimes (captures non-stationarity)
\item Provides confidence intervals (10 data points vs 1)
\item Detects overfitting (high variance across folds indicates instability)
\item Mimics production deployment (retrain monthly on expanding window)
\end{itemize}

\subsubsection{Volatility Regime-Specific Models}
\textbf{Hierarchical Regime Definition:}
Rather than monolithic model, train specialized trees for distinct market conditions:

\textbf{Level 1: Volatility Split}
\begin{equation}
regime_{vol} = \begin{cases}
\text{Low} & \text{if } rv_{900s} \leq median(rv_{900s}) \\
\text{High} & \text{otherwise}
\end{cases}
\end{equation}

\textbf{Level 2a: Low Volatility Sub-Regimes (by moneyness)}
\begin{equation}
regime_{low\_vol} = \begin{cases}
\text{ATM} & \text{if } |moneyness| < 0.005 \quad \text{(±0.5\%)} \\
\text{OTM/ITM} & \text{otherwise}
\end{cases}
\end{equation}

\textbf{Level 2b: High Volatility Sub-Regimes (by time remaining)}
\begin{equation}
regime_{high\_vol} = \begin{cases}
\text{Short} & \text{if } time\_remaining < 300s \quad \text{(5 min)} \\
\text{Long} & \text{otherwise}
\end{cases}
\end{equation}

\textbf{Final regime set:} 4 specialized models
\begin{enumerate}
\item Low volatility + ATM (expected best performance, 35\% of data)
\item Low volatility + OTM/ITM (moderate performance, 25\% of data)
\item High volatility + short TTL (challenging, 20\% of data)
\item High volatility + long TTL (moderate performance, 20\% of data)
\end{enumerate}

\textbf{Routing at prediction time:}
\begin{center}\textbf{Algorithm:}
Hierarchical Regime Routing\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item Compute $rv_{900s}$ from recent price history
\item If $rv_{900s} \leq threshold_{vol}$:
    \begin{enumerate}
    \item If $|moneyness| < 0.005$: Use \texttt{model\_low\_vol\_atm}
    \item Else: Use \texttt{model\_low\_vol\_otm}
    \end{enumerate}
\item Else (high volatility):
    \begin{enumerate}
    \item If $time\_remaining < 300$: Use \texttt{model\_high\_vol\_short}
    \item Else: Use \texttt{model\_high\_vol\_long}
    \end{enumerate}
\end{enumerate}
\end{center}

\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Walk-forward validation}: Mean test Brier with $\pm$ std, detects temporal instability
\item \textbf{Regime models}: 5-7\% additional Brier improvement over monolithic model
\item \textbf{Best regime (Low vol + ATM)}: 25-30\% improvement (vs 24.8\% current Regime 3)
\item \textbf{Overall weighted improvement}: 15-20\% vs Black-Scholes baseline
\item \textbf{Implementation effort}: 1 week (walk-forward) + 1 week (regime models)
\item \textbf{Risk}: Moderate (increased complexity, 4× model count)
\end{itemize}

\subsection{Extended Dataset \& Feature Optimization}
\subsubsection{Dataset Expansion}
Extend from current analysis period to full available history:
\begin{itemize}
\item \textbf{Current}: ~730 days (October 2023 - September 2025)
\item \textbf{Extended}: 773 days (September 26, 2023 - November 6, 2025)
\item \textbf{Additional data}: 43 days ($\approx$10M additional predictions)
\item \textbf{Benefit}: Captures additional market regimes, improves statistical power
\end{itemize}

\subsubsection{Feature Pruning Strategy}
Reduce feature count from 226 to 165 through systematic pruning:

\textbf{Category 1: Remove Simple Moving Averages (50 features)}
\begin{itemize}
\item \textbf{Rationale}: EMAs respond faster to recent changes, more suitable for 15-minute windows
\item \textbf{Affected features}: All \texttt{*\_sma\_*} features across spreads, imbalances, RV, momentum, range
\item \textbf{Expected impact}: -0.2\% to +0.5\% Brier (slight improvement from noise reduction)
\end{itemize}

\textbf{Category 2: Remove 1800s Time Horizon (20 features)}
\begin{itemize}
\item \textbf{Rationale}: Redundant with 900s and 3600s (interpolation between)
\item \textbf{Feature importance analysis}: 1800s features rarely in top 50
\item \textbf{Expected impact}: -0.1\% to +0.2\% Brier
\end{itemize}

\textbf{Category 3: Conditional Removal of Funding Rates (0-11 features)}
\begin{itemize}
\item \textbf{Rationale}: Funding rates settle every 8 hours, less relevant for 15-minute expiry
\item \textbf{Decision rule}: Remove if ALL funding features show <1\% LightGBM importance
\item \textbf{Expected impact}: -0.1\% to +0.3\% Brier
\end{itemize}

\textbf{Category 4: Remove Short-Term OI EMAs (2 features)}
\begin{itemize}
\item \textbf{Features}: \texttt{oi\_ema\_60s}, \texttt{oi\_ema\_300s}
\item \textbf{Rationale}: High correlation with base \texttt{open\_interest}, minimal unique signal
\item \textbf{Expected impact}: -0.05\% to +0.1\% Brier
\end{itemize}

\textbf{Net result:} 226 → 165 features (27\% reduction)

\subsubsection{Feature Addition}
After pruning, add advanced features (net: 165 → 175 final features):
\begin{itemize}
\item Advanced moneyness (7 features): log, standardized, squared, 4 interactions
\item Order book spreads (4 features): spread-vol ratios, depth-weighted, acceleration
\item Volatility asymmetry (6 features): variance asym, skew premium, multi-horizon, tail asym
\end{itemize}

\subsubsection{Expected Outcomes}
\begin{itemize}
\item \textbf{Training speed}: +20-30\% faster (fewer features, same sample count)
\item \textbf{Memory usage}: -15\% reduction (fewer feature columns)
\item \textbf{Generalization}: +0.2-0.5\% Brier improvement (reduced overfitting)
\item \textbf{Final feature count}: 175 (vs 226 original)
\item \textbf{Implementation effort}: 4 hours (automated pruning + validation)
\item \textbf{Risk}: Low (ablation study validates each removal)
\end{itemize}

\subsection{Implementation Roadmap - Expert Refined}
\begin{table}[h]
\centering
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Enhancement} & \textbf{Effort} & \textbf{Expected Gain} & \textbf{Risk} & \textbf{Priority} \\
\midrule
\textbf{Foundation Fixes} & & & & \\
Feature Normalization & 4-6 hours & Enabler for NN & Low & \textbf{1} \\
Regime Boundary Stability & 3-4 hours & +1-2\% Brier & Low & \textbf{2} \\
Crash/Spike Detection & 2 hours & Risk reduction & Low & \textbf{3} \\
\midrule
\textbf{High-ROI Features} & & & & \\
Advanced Moneyness & 4-5 hours & +6.5-10.5\% Brier & Low & \textbf{4} \\
Volatility Asymmetry & 3.5 hours & +2.6-5.1\% Brier & Low & \textbf{5} \\
Order Book Spreads & 2 hours & +1.0-2.0\% Brier & Low & \textbf{6} \\
\midrule
\textbf{Robustness} & & & & \\
Walk-Forward CV & 1 week & Confidence intervals & Low & \textbf{7} \\
Regime Models (refined) & 1 week & +5-7\% Brier & Moderate & \textbf{8} \\
ATM Threshold Testing & 4 hours & +0.5-1\% Brier & Low & \textbf{9} \\
\midrule
\textbf{Consider Carefully} & & & & \\
Weighted MSE & 1 day & +2-4\% (may hurt ATM) & \textbf{High} & 10 \\
Log-Odds Transform & 2-3 days & +1-2\% Brier & Moderate & 11 \\
\midrule
\textbf{Low Priority} & & & & \\
Neural Network Ensemble & 1 week & +0.5-2.0\% Brier & High & 12 \\
Feature Pruning & 4 hours & +0.5-1.0\% Brier & Low & 13 \\
Dataset Extension & 2 hours & Statistical power & Low & 14 \\
\bottomrule
\end{tabular}
\caption{Expert-refined implementation roadmap. Foundation fixes are CRITICAL before other improvements. Weighted MSE risk elevated due to potential ATM degradation.}\\\rule{\textwidth}{0.4pt}
\end{table}

\textbf{Expert-Refined Phased Approach:}
\begin{enumerate}
\item \textbf{Phase 0 - Foundation (Day 1-2)}: \textit{CRITICAL - Must complete before any other work}
    \begin{itemize}
    \item Implement feature normalization pipeline
    \item Add regime boundary stabilization with 10\% hysteresis
    \item Implement crash/spike detection (RV ratio > 3)
    \item Test ATM thresholds: 0.5\%, 0.75\%, 1.0\%
    \item Document normalization strategy
    \end{itemize}

\item \textbf{Phase 1 - High-ROI Features (Week 1)}:
    \begin{itemize}
    \item Advanced moneyness: log, standardized, squared forms
    \item Volatility asymmetry: downside/upside variance ratios
    \item Order book spread normalization
    \item Expected: 10-18\% total Brier improvement (0.1340 → 0.1100-0.1200)
    \item Reduce moneyness correlation from 41\% to <25\%
    \end{itemize}

\item \textbf{Phase 2 - Robustness (Week 2-3)}:
    \begin{itemize}
    \item Walk-forward CV with 10 temporal folds
    \item Refined regime models with stability improvements
    \item Soft regime transitions with confidence scores
    \item Expected: +5-7\% additional improvement, confidence intervals
    \item 5 models: 4 regimes + 1 extreme detector
    \end{itemize}

\item \textbf{Phase 3 - Careful Testing (Week 4)}:
    \begin{itemize}
    \item \textbf{Test weighted MSE carefully}: Monitor ATM degradation
    \item A/B test: weighted vs unweighted on each regime
    \item If ATM performance drops >2\%, abandon approach
    \item Alternative: regime-specific weighting only
    \end{itemize}

\item \textbf{Phase 4 - Low Priority (Optional)}:
    \begin{itemize}
    \item Neural network ensemble ONLY if LightGBM plateaus
    \item Log-odds transformation if extreme calibration poor
    \item Feature pruning if training speed critical
    \end{itemize}
\end{enumerate}

\textbf{Cumulative Expected Improvement:}
\begin{itemize}
\item \textbf{Phase 1 only}: 10-18\% Brier reduction → Final: 0.1350-0.1410
\item \textbf{Phase 1+2}: 15-25\% Brier reduction → Final: 0.1280-0.1380
\item \textbf{Phase 1+2+4}: 18-33\% Brier reduction → Final: 0.1200-0.1330
\end{itemize}

Target: 20-25\% total improvement vs Black-Scholes baseline, bringing final Brier score to approximately 0.1260-0.1320 (vs current 0.1524).
\section{Data Integrity and Statistical Concerns}

\subsection{Multicollinearity Analysis}
The current model includes 175 features with potential high correlation:

\subsubsection{Identified Correlation Clusters}
\begin{enumerate}
\item \textbf{Order Book Features (53 total)}:
   \begin{itemize}
   \item Bid/ask prices across 5 levels: correlation $>$ 0.95
   \item Spread features (raw, EMA, momentum): correlation $>$ 0.80
   \item Imbalance metrics across timeframes: correlation $>$ 0.75
   \end{itemize}

\item \textbf{Realized Volatility Features (28 total)}:
   \begin{itemize}
   \item RV across horizons (60s, 300s, 900s, 3600s): correlation 0.70-0.95
   \item RV EMAs highly correlated with base RV: correlation $>$ 0.90
   \item RV ratios partially redundant with individual RVs
   \end{itemize}

\item \textbf{Momentum Features}:
   \begin{itemize}
   \item Price changes across timeframes: correlation 0.60-0.85
   \item Momentum EMAs correlated with base momentum: correlation $>$ 0.85
   \end{itemize}
\end{enumerate}

\subsubsection{Implications}
While LightGBM handles multicollinearity better than linear models:
\begin{itemize}
\item Feature importance metrics become unreliable
\item Training efficiency reduced (redundant splits)
\item Model interpretability compromised
\item Increased risk of overfitting
\end{itemize}

\subsubsection{Recommended Solutions}
\begin{equation}
\text{VIF}_j = \frac{1}{1 - R_j^2}
\end{equation}
where $R_j^2$ is the $R^2$ from regressing feature $j$ on all other features.

Action steps:
\begin{enumerate}
\item Compute Variance Inflation Factor (VIF) for all features
\item Remove features with VIF $>$ 10 (severe multicollinearity)
\item Use PCA for highly correlated clusters (order book levels)
\item Apply L1 regularization more aggressively (current: 1.0 → 5.0)
\end{enumerate}

\subsection{Look-Ahead Bias Verification}

\subsubsection{Critical Areas to Verify}
\begin{enumerate}
\item \textbf{Realized Volatility Calculations}:
   \begin{equation}
   \text{RV}_{900s}(t) = \sqrt{\frac{1}{900} \sum_{i=t-899}^{t} r_i^2}
   \end{equation}
   Must use ONLY past data: $[t-899, t]$, not $[t-449, t+450]$

\item \textbf{Moving Averages}:
   All EMAs must be backward-looking:
   \begin{equation}
   \text{EMA}_n(t) = \alpha \cdot x_t + (1-\alpha) \cdot \text{EMA}_n(t-1)
   \end{equation}

\item \textbf{Regime Detection}:
   Volatility threshold must use historical percentile:
   \begin{equation}
   \theta_{\text{vol}}(t) = Q_{50}(\{\text{RV}_{900s}(\tau) : \tau < t\})
   \end{equation}

\item \textbf{Feature Engineering}:
   \begin{itemize}
   \item Momentum: Must use $S_t - S_{t-\Delta t}$, not centered differences
   \item Range features: High/low from past window only
   \item Correlation features: Rolling window strictly backward
   \end{itemize}
\end{enumerate}

\subsubsection{Validation Protocol}
\begin{center}\textbf{Algorithm:}
Look-Ahead Bias Detection\\\rule{\textwidth}{0.4pt}
\begin{enumerate}
\item For each feature $f$ and random timestamps $t$:
   \begin{enumerate}
   \item Compute $f(t)$ with full data
   \item Compute $f(t)$ with data only up to time $t$
   \item Assert equality: $|f_{\text{full}} - f_{\text{truncated}}| < \epsilon$
   \end{enumerate}
\item For regime detection:
   \begin{enumerate}
   \item Verify threshold computed on training data only
   \item Check no future information in regime assignment
   \end{enumerate}
\item For walk-forward validation:
   \begin{enumerate}
   \item Ensure strict temporal separation
   \item Verify no data leakage across folds
   \end{enumerate}
\end{enumerate}
\end{center}

\subsubsection{Common Pitfalls}
\begin{itemize}
\item Using centered rolling windows instead of backward
\item Computing global statistics (mean, std) on full dataset
\item Regime thresholds computed on test data
\item Feature normalization parameters from full dataset
\end{itemize}

\section{Critical Expert Assessment}
\subsection{Major Gaps Identified}
\begin{enumerate}
\item \textbf{Feature Normalization}: No explicit normalization pipeline documented despite 1000x scale differences in features. This is CRITICAL for proposed neural network ensemble and affects feature importance metrics.

\item \textbf{Regime Boundary Instability}: Median-based thresholds drift over time causing regime flipping. Options near boundaries oscillate between models, degrading performance.

\item \textbf{ATM Threshold Sensitivity}: The 0.5\% threshold may be too tight. Market makers typically use 0.75-1.0\% for "near-ATM" classification.

\item \textbf{Missing Extreme Regime}: No explicit handling of crash/spike conditions (RV > 95th percentile). These require special treatment or position reduction.

\item \textbf{Weighted MSE Risk}: Proposal gives LOWEST weight to ATM options where uncertainty is highest. This could severely degrade performance in the most important region.

\item \textbf{Feature Multicollinearity}: No analysis of correlation between 53 order book features and 28 RV features. LightGBM handles this but with efficiency loss.

\item \textbf{Look-ahead Bias Risk}: Must verify all RV calculations use backward-looking windows only, especially for features like RV\_900s used in regime detection.
\end{enumerate}

\subsection{Key Recommendations}
\begin{enumerate}
\item \textbf{Immediate Priority}: Implement normalization BEFORE any other improvements. Use regime-specific RobustScaler with 5-95 percentile range.

\item \textbf{Stabilize Regimes}: Add 10\% hysteresis to prevent boundary oscillation. Use fixed percentiles (40th/60th) computed monthly, not median.

\item \textbf{Test ATM Thresholds}: Evaluate 0.5\%, 0.75\%, and 1.0\% thresholds. Wider threshold may improve stability.

\item \textbf{Advanced Moneyness Critical}: With 41\% correlation, this is your highest ROI improvement. Log-moneyness alone could reduce correlation to <25\%.

\item \textbf{Reconsider Weighted MSE}: High risk of ATM degradation. Test VERY carefully with A/B comparisons. Consider abandoning if ATM performance drops >2\%.

\item \textbf{Neural Networks Low Priority}: Unlikely to beat LightGBM on tabular data. Focus on maximizing tree-based performance first.
\end{enumerate}

\subsection{Alternative Approaches to Consider}

\subsubsection{Soft Regime Transitions}
Current hard regime assignment causes discontinuous model switches at boundaries. Implement weighted ensemble based on regime confidence:
\begin{equation}
P_{\text{final}} = \sum_{r \in \text{regimes}} w_r \cdot P_r
\end{equation}
where weights are computed using sigmoid transitions:
\begin{equation}
w_{\text{low\_vol}} = \frac{1}{1 + \exp(k \cdot (\text{RV}_{900s} - \theta_{\text{vol}}))}
\end{equation}
with $k = 10$ controlling transition sharpness and $\theta_{\text{vol}}$ as the regime boundary.

Benefits:
\begin{itemize}
\item Smooth predictions near boundaries
\item Reduced sensitivity to threshold selection
\item Better uncertainty quantification
\item Natural handling of ambiguous cases
\end{itemize}

\subsubsection{Dynamic Feature Selection by Regime}
Different market conditions require different features:

\begin{table}[h]
\centering
\small
\begin{tabular}{lll}
\toprule
\textbf{Regime} & \textbf{Primary Features} & \textbf{Rationale} \\
\midrule
Low Vol + ATM & Order book microstructure & Spread, imbalance dominate \\
High Vol + Short & Momentum indicators & Recent moves predict outcomes \\
Crash/Spike & Depth, liquidity metrics & Survival depends on liquidity \\
Trending & Autocorrelation, EMAs & Persistence matters \\
\bottomrule
\end{tabular}
\end{table}

Implementation:
\begin{equation}
\text{features}_{\text{regime}} = \text{base\_features} \cup \text{regime\_specific\_features}
\end{equation}

\subsubsection{Volatility Surface Regimes}
Replace simple RV bucketing with term structure shape:
\begin{align}
\text{slope} &= \frac{\text{RV}_{3600s} - \text{RV}_{300s}}{\text{RV}_{300s}} \\
\text{convexity} &= \text{RV}_{900s} - 0.5 \times (\text{RV}_{300s} + \text{RV}_{3600s})
\end{align}

Define regimes:
\begin{itemize}
\item \textbf{Contango}: slope $> 0.1$ (increasing volatility with time)
\item \textbf{Backwardation}: slope $< -0.1$ (decreasing volatility)
\item \textbf{Flat}: $|\text{slope}| \leq 0.1$, $|\text{convexity}| < 0.05$
\item \textbf{Smile}: $|\text{convexity}| > 0.05$ (curved structure)
\end{itemize}

\subsubsection{Cross-Asset Correlation Features}
Cryptocurrency markets exhibit strong cross-asset effects:

\begin{align}
\rho_{\text{ETH,BTC}}^{300s} &= \text{corr}(\text{returns}_{\text{ETH}}^{300s}, \text{returns}_{\text{BTC}}^{300s}) \\
\beta_{\text{ETH}}^{900s} &= \frac{\text{cov}(\text{ETH}, \text{BTC})}{\text{var}(\text{BTC})} \\
\text{decorrelation} &= |\rho_{\text{current}} - \rho_{\text{MA20}}|
\end{align}

Features to add:
\begin{itemize}
\item Rolling correlation (60s, 300s, 900s windows)
\item Beta relative to BTC
\item Correlation regime changes (decorrelation events)
\item Lead-lag indicators (which asset moves first)
\end{itemize}

\subsubsection{Market Microstructure Time Zones}
Trading patterns vary by global market hours:

\begin{table}[h]
\centering
\small
\begin{tabular}{lll}
\toprule
\textbf{Time Zone} & \textbf{Hours (UTC)} & \textbf{Characteristics} \\
\midrule
Asia & 00:00-08:00 & Lower volume, trend following \\
Europe & 08:00-16:00 & Moderate volume, mean reversion \\
US & 16:00-00:00 & High volume, news-driven \\
\bottomrule
\end{tabular}
\end{table}

Implementation:
\begin{equation}
\text{regime}_{\text{time}} = \begin{cases}
\text{Asia} & \text{if hour} \in [0, 8) \\
\text{Europe} & \text{if hour} \in [8, 16) \\
\text{US} & \text{if hour} \in [16, 24)
\end{cases}
\end{equation}

\section{Conclusion}
We present a two-stage residual learning framework for binary option pricing that achieves 15-20\% Brier score improvement over Black-Scholes baseline through hierarchical volatility regime modeling and walk-forward validation on 39 million predictions from a 773-day dataset (September 26, 2023 - November 6, 2025). Our approach combines theoretical pricing with data-driven corrections, leveraging 175 optimized features (pruned from 226) to capture deviations from geometric Brownian motion assumptions.

Key methodological innovations include:
\begin{enumerate}
\item \textbf{Walk-Forward Validation}: Expanding 10-fold temporal cross-validation provides robust performance estimates (mean ±std) across varying market regimes, preventing lucky/unlucky split selection. Ensemble predictions with time-decay weights mimic production deployment scenarios.

\item \textbf{Hierarchical Regime Modeling}: Four specialized LightGBM models trained for distinct market conditions—(1) Low vol + ATM, (2) Low vol + OTM/ITM, (3) High vol + short TTL, (4) High vol + long TTL—achieve regime-specific improvements ranging from 5-10\% (challenging high-vol short-dated) to 25-30\% (optimal low-vol ATM). Hierarchical routing based on RV\_900s, moneyness, and time\_remaining enables dynamic model selection.

\item \textbf{Feature Optimization}: Systematic pruning removes 51 redundant features (SMAs, 1800s horizon, short-term OI EMAs, low-importance funding rates) while retaining predictive power, yielding 30\% faster training and +0.5-1.0\% generalization improvement through noise reduction.

\item \textbf{Probability Bucketing}: Confusion matrix analysis across 10 equal-width probability buckets identifies {[}0.45-0.55{]} as a no-trade zone with poor precision/recall, enabling risk-aware position sizing. Strong signal zones—{[}0.0-0.3{]} for shorting, {[}0.7-1.0{]} for longing—achieve 75-92\% precision with appropriate edge thresholds.
\end{enumerate}

Empirical findings reveal:
\begin{itemize}
\item \textbf{Performance}: Walk-forward mean 17.0\% ± 2.1\% Brier improvement (0.1340 ± 0.0018 vs 0.1615 baseline), with best regime (low vol + ATM, 35\% of data) achieving 25-30\% improvement.
\item \textbf{Crisis Resilience}: Regime-specific models improve crisis period performance by 7\% through specialized high-volatility modeling.
\item \textbf{Feature Insights}: Moneyness (41\%) and momentum (32\%, 22\%, 19\%) dominate corrections, reflecting directional bias not captured by theory. Volatility features contribute 5.6\%, indicating microstructure effects matter more than variance estimation errors for 15-minute expiries.
\item \textbf{Trading Application}: 10\% edge threshold achieves 83.5\% win rate on 17.6\% of opportunities, with probability bucketing identifying actionable zones for selective high-conviction strategies with Kelly-optimal position sizing.
\end{itemize}

The discontinuous payoff structure of binary options necessitates non-linear baseline modeling and regime-specific feature engineering. Unlike vanilla options where vega dominates, binary option pricing is most sensitive to directional momentum near strikes, particularly for short-dated contracts where gamma effects dominate.

\textbf{Proposed enhancements} in three phases would further improve performance: (1) Advanced feature engineering (log-moneyness, standardized moneyness, spread-volatility ratios, variance asymmetry) expected to yield additional 10-18\% Brier improvement; (2) Loss function optimization (weighted MSE with capping, log-odds space transformation) adding 5-12\% at extremes; (3) Neural network ensemble potentially contributing 0.5-2.0\%. Combined cumulative target: 30-40\% total improvement vs baseline (final Brier: 0.1100-0.1260).

Production deployment currently utilizes: hierarchical volatility regime routing (4 specialized models), monthly retraining on expanding windows (10-19 months), ensemble predictions with time-decay weights, and probability bucketing for position sizing (avoid {[}0.45-0.55{]} no-trade zone, allocate via fractional Kelly in high-confidence zones).
\section*{Data and Code Availability}
Analysis code, feature engineering pipelines, and model checkpoints are available at: \\
\texttt{/Users/lgierhake/Documents/ETH/BT/research/model/}
\begin{itemize}
\item \textbf{Pricing code}: \texttt{01\_pricing/}
\item \textbf{Initial EDA}: \texttt{02\_analysis/}
\item \textbf{Deep EDA}: \texttt{03\_deep\_eda/}
\item \textbf{Feature generation}: \texttt{00\_data\_processing/}
\end{itemize}
\bibliographystyle{plainnat}
\begin{thebibliography}{9}
\bibitem{merton1973theory}
Merton, Robert C.
\textit{Theory of rational option pricing.}
The Bell Journal of Economics and Management Science, 4(1):141-183, 1973.
\bibitem{dugas2009incorporating}
Dugas, Charles, et al.
\textit{Incorporating functional knowledge in neural networks.}
Journal of Machine Learning Research, 10:1239-1262, 2009.
\bibitem{horvath2021deep}
Horv{\'a}th, Blanka, et al.
\textit{Deep learning volatility: A deep neural network perspective on pricing and calibration in (rough) volatility models.}
Quantitative Finance, 21(1):11-27, 2021.
\bibitem{ke2017lightgbm}
Ke, Guolin, et al.
\textit{LightGBM: A highly efficient gradient boosting decision tree.}
Advances in Neural Information Processing Systems, 30:3146-3154, 2017.
\bibitem{wiki:moneyness}
Wikipedia contributors.
\textit{Moneyness --- Wikipedia, The Free Encyclopedia.}
\url{https://en.wikipedia.org/wiki/Moneyness}, 2024. [Online; accessed 11-November-2025].
\end{thebibliography}
\end{document}
