# Gitbook Documentation Export
Source: https://docs.tardis.dev
Platform: Gitbook (confidence: 0.8)
Exported: 2025-10-08 14:42:45
Total Pages: 53
Failed Pages: 3

================================================================================

## Table of Contents

1. [Welcome](https://docs.tardis.dev/)
2. [Frequently Asked Questions](https://docs.tardis.dev/faq)
3. [General](https://docs.tardis.dev/faq/general)
4. [Data](https://docs.tardis.dev/faq/data)
5. [Billing and Subscriptions](https://docs.tardis.dev/faq/billing-and-subscriptions)
6. [Downloadable CSV files](https://docs.tardis.dev/downloadable-csv-files)
7. [Historical Data Details](https://docs.tardis.dev/historical-data-details)
8. [BitMEX](https://docs.tardis.dev/historical-data-details/bitmex)
9. [Deribit](https://docs.tardis.dev/historical-data-details/deribit)
10. [Binance USDT Futures](https://docs.tardis.dev/historical-data-details/binance-futures)
11. [Binance COIN Futures](https://docs.tardis.dev/historical-data-details/binance-delivery)
12. [Binance Spot](https://docs.tardis.dev/historical-data-details/binance)
13. [FTX](https://docs.tardis.dev/historical-data-details/ftx)
14. [OKX Futures](https://docs.tardis.dev/historical-data-details/okex-futures)
15. [OKX Swap](https://docs.tardis.dev/historical-data-details/okex-swap)
16. [OKX Options](https://docs.tardis.dev/historical-data-details/okex-options)
17. [OKX Spot](https://docs.tardis.dev/historical-data-details/okex)
18. [Huobi Futures](https://docs.tardis.dev/historical-data-details/huobi-dm)
19. [Huobi COIN Swaps](https://docs.tardis.dev/historical-data-details/huobi-dm-swap)
20. [Huobi USDT Swaps](https://docs.tardis.dev/historical-data-details/huobi-dm-linear-swap)
21. [Huobi Global](https://docs.tardis.dev/historical-data-details/huobi)
22. [Bitfinex Derivatives](https://docs.tardis.dev/historical-data-details/bitfinex-derivatives)
23. [Bitfinex](https://docs.tardis.dev/historical-data-details/bitfinex)
24. [Coinbase Pro](https://docs.tardis.dev/historical-data-details/coinbase)
25. [Kraken Futures](https://docs.tardis.dev/historical-data-details/cryptofacilities)
26. [Kraken](https://docs.tardis.dev/historical-data-details/kraken)
27. [Bitstamp](https://docs.tardis.dev/historical-data-details/bitstamp)
28. [Gemini](https://docs.tardis.dev/historical-data-details/gemini)
29. [Bybit Derivatives](https://docs.tardis.dev/historical-data-details/bybit)
30. [Bybit Spot](https://docs.tardis.dev/historical-data-details/bybit-spot)
31. [dYdX](https://docs.tardis.dev/historical-data-details/dydx)
32. [WOO X](https://docs.tardis.dev/historical-data-details/woo-x)
33. [Kucoin Spot](https://docs.tardis.dev/historical-data-details/kucoin)
34. [Blockchain.com](https://docs.tardis.dev/historical-data-details/blockchain-com)
35. [Upbit](https://docs.tardis.dev/historical-data-details/upbit)
36. [Phemex](https://docs.tardis.dev/historical-data-details/phemex)
37. [Delta](https://docs.tardis.dev/historical-data-details/delta)
38. [AscendEX (BitMax)](https://docs.tardis.dev/historical-data-details/ascendex)
39. [FTX US](https://docs.tardis.dev/historical-data-details/ftx-us)
40. [Binance US](https://docs.tardis.dev/historical-data-details/binance-us)
41. [Gate.io Futures](https://docs.tardis.dev/historical-data-details/gate-io-futures)
42. [Gate.io](https://docs.tardis.dev/historical-data-details/gate-io)
43. [Bitnomial](https://docs.tardis.dev/historical-data-details/bitnomial)
44. [Crypto.com](https://docs.tardis.dev/historical-data-details/crypto-com)
45. [OKCoin](https://docs.tardis.dev/historical-data-details/okcoin)
46. [bitFlyer](https://docs.tardis.dev/historical-data-details/bitflyer)
47. [HitBTC (high caps)](https://docs.tardis.dev/historical-data-details/hitbtc)
48. [CoinFLEX (2.0)](https://docs.tardis.dev/historical-data-details/coinflex)
49. [Binance Jersey](https://docs.tardis.dev/historical-data-details/binance-jersey)
50. [Binance DEX](https://docs.tardis.dev/historical-data-details/binance-dex)
51. [Poloniex](https://docs.tardis.dev/historical-data-details/poloniex)
52. [Privacy Policy](https://docs.tardis.dev/legal/privacy-policy)
53. [Terms of Service](https://docs.tardis.dev/legal/terms-of-service)

================================================================================

# Welcome

Source: https://docs.tardis.dev/
Extraction Method: playwright

Copy
# Welcome
Welcome to Tardis.dev documentation pages

$
## Downloadable CSV files
If you prefer accessing historical datasets in CSV format, please see downloadable CSV files docs.

[Downloadable CSV files](/downloadable-csv-files)
## Market data replay API
Follow our API getting started guide to learn more how to access historical data via our HTTP API and client libs that offer tick-level market data replay support data both in exchange-native and normalized formats.

[Getting Started](/api/getting-started)
## Real-time market data streaming
Consolidated real-time market data streaming API is available via our open source libraries that connect directly to exchanges' WebSocket APIs. We do not provide hosted real-time API, see why.

## Available historical market data details
See historical data details to learn exactly what, how and since we collect for each supported exchange and what data is available via our market data API and downloadable CSV files.

[Historical Data Details](/historical-data-details)
## Questions?
Refer to our FAQ or contact us via email. We're always here to help you with any questions you have.

[Frequently Asked Questions](/faq)/$[NextFrequently Asked Questions](/faq)Last updated 3 years ago

================================================================================

# Frequently Asked Questions

Source: https://docs.tardis.dev/faq
Extraction Method: playwright

Copy
# Frequently Asked Questions
Got questions? We're happy to help!

$
## General

• What is Tardis.dev and what is your unique value proposition?
• Which exchanges, instruments and currency pairs are supported?
• Do you provide discounts?
• Do you offer free trials?
• What does professional support mean?
• What would I use your services if I can collect data by myself?
• How can I download the data?
• How far back the historical data is available?
• Do you provide historical market data in CSV flat files?
• What programming languages are supported?
• What API protocols can be used to access market data?
• How time-machine market replay works?
• Do you support consolidated real-time market data streaming?
• Are there any rate-limits for the API?
• How do I obtain my API key?
• What if my API key was compromised?
• What is your infrastructure setup?
• Do you provide SLA?

## Data

• What data types do you support?
• What does high frequency historical data mean?
• How historical raw market data is being sourced?
• Why data source matters and why we use from real-time WebSocket feeds as data source vs periodically calling REST endpoints?
• What L2 order book data can be used for?
• What L3 order book data can be used for?
• What is the maximum order book depth available for each supported exchange?
• Which exchanges support liquidations data type?
• Do you provide historical options data?
• Do you provide historical futures data?
• What is the difference between futures and perpetual swaps contracts?
• Do you provide time based aggregated data as well?
• Can you record market data for exchange that's not currently supported?
• Do you provide market data in normalized format?
• Do you provide normalized contract amounts for derivatives exchanges in your historical data feeds?
• What is a difference between exchange-native and normalized data format?
• What is the channel field used in the HTTP API and client libs replay functions?
• What time zone is used in the data?
• Is provided raw market data complete?
• How frequently exchanges drop WebSocket connections?
• Can historical order books reconstructed from L2 updates be crossed (bid/ask overlap) occasionally?
• Can exchange publish data with non monotonically increasing timestamps for single data channel?
• Are exchanges publishing duplicated trades data messages?
• How order book data snapshots are provided?
• Do you collect order books as snapshots or in streaming mode?
• How incremental_book_l2 CSV dataset is built from real-time data?
• How can I reconstruct full order book state from  incremental_book_L2 CSV dataset?
• How CSV datasets are split into the files?
• How market data messages are being timestamped?
• What is the new historical market data delay in relation to real-time?

## Billing and Subscriptions

• What is the order process?
• Do you provide discounts?
• How one-off purchase based access works?
• How subscription based access works?
• What are the differences between subscriptions types?
• Do subscriptions include access to historical data as well?
• What is included in "Individual" data plan?
• What is included in "Perpetuals" data plan?
• What is included in "Derivatives" data plan?
• What is included in "All Exchanges" data plan?
• How can I change my subscription plan?
• Can I pay through invoicing?
• Can I get quotation document before making an order?
• How can I get an invoice and VAT refund?
• What are your VAT details?
• I’ve lost my invoice. How do I get a new one?
• What is the refund policy?
• How can I cancel my subscription?
• Do you accept payments in cryptocurrency?
• How I can update my credit card information?

## Got other Questions? We're happy to help!
Simply contact us via email.

/$[PreviousWelcome](/)[NextGeneral](/faq/general)Last updated 1 year ago

================================================================================

# General

Source: https://docs.tardis.dev/faq/general
Extraction Method: playwright

Copy
1. Frequently Asked Questions

# General
$
## What is Tardis.dev and what is your unique value proposition?
Tardis.dev provides the most comprehensive and granular cryptocurrency market data products in the industry and offers:

• access to high frequency historical data including the most granular tick level order book updates and trades for both derivatives and top spot cryptocurrency exchanges
• non standard data types: historical funding, open interest, indexes, liquidations and more
• fast and convenient data access both via API and downloadable CSV files
• data sourced from real-time WS market data feeds with complete control and transparency how the data is being recorded
• exchange-native and normalized data format support
• time-machine market replay allowing reconstruction of state of the limit order book at any given moment in time across all supported cryptocurrency markets
• always available market data backup
• fair, transparent pricing with discounts for solo trades,  small prop shops and academic researchers
• consolidated real-time market data streaming support via Tardis.dev open source libraries that connect directly to exchanges' public WebSocket APIs (no API key required)
• professional support

Data use cases

• market microstructure and order book dynamics research
• trading execution optimization
• tick-level granularity market simulation
• liquidity and lead-lag analysis
• backtesting and optimization of trading strategies
• full historical order book reconstruction at any given point in time
• training machine learning models
• alpha generation
• designing quantitative models
• academics research
• data visualizations

## Which exchanges, instruments and currency pairs are supported?
In total over 40 000 distinct instruments & currency pairs across leading derivatives and spot cryptocurrency exchanges is supported. We collect and provide data for all instruments & currency pairs available on given exchange with some exceptions for spot exchanges where we collect high caps currency pairs only (due to exchanges API limitations).

See historical data details for each supported exchange.

• BitMEX
• Deribit
• BinanceUSDT FuturesCOIN FuturesSpot
• FTX
• OKXFuturesSwapOptionsSpot
• HuobiFuturesCOIN SwapsUSDT SwapsGlobal (Spot)
• BitfinexDerivativesSpot
• Coinbase Pro
• Kraken Futures (Crypto Facilities)
• Kraken
• Bitstamp
• Gemini
• Poloniex
• Bybit
• Bybit Spot
• dYdX
• WOO X
• KucoinSpot
• Blockchain.com
• Upbit
• Phemex
• Delta
• Ascendex (BitMax)
• FTX US
• Binance US
• Gate.io Futures
• Gate.io (high caps)
• Bitnomial
• Crypto.com
• OKCoin
• bitFlyer
• HitBTC
• CoinFLEX
• Binance Jersey
• Binance DEX

## Do you provide discounts?
We do provide discounts in a transparent form via different subscriptions types.

## Do you offer free trials?
Yes, if you'd like to test the service (data quality, coverage, API performance etc.) we offer generous free trials. Simply reach out to us and we'll set up trial account for you.

## What does professional support mean?
Our support team has in-depth knowledge of market data and exchanges' APIs peculiarities, programming and data analysis expertise. You get the answers straight from people whose day to day job is overseeing and maintaining market data collection process and infrastructure.

For business subscriptions we provide dedicated communication channel (via Telegram Messenger, email or Zoom calls) for your company where our team is on standby every business day (7AM - 3PM UTC) to answer any questions you may have.

For pro subscriptions and one-off purchases we do provide email based support with 24-48 business hours initial response time.

For academic and solo subscriptions there is no dedicated support provided, only self-service.

## What would I use your services if I can collect data by myself?
Since cryptocurrency exchanges' market data APIs are public anyone can use those to collect the data, but it's a time consuming and resource intensive undertaking (exchanges we support publish ~1000GB of new data every day), that requires investment in proper infrastructure, constant monitoring and oversight (exchanges API changes, rate-limiting monitoring, new exchanges integrations, unexpected connection issues, latency monitoring etc.), not to mention implementation costs of data collection, storage and distribution services.

All in all we think our offering is comprehensive, transparent and fair, provides good value and saves you time and money in comparison to in-house solution allowing you to focus on your core objective not on data management intricacies.

## How can I download the data?
You can access historical market data via API which provides raw data in exchange native format or download CSV datasets with trades, incremental order book L2 updates, order book snapshots, options chains, quotes, derivative tickers (open interest, funding, mark price, index price) and liquidations.

Our client libs provide data in normalized format as well, which can be more flexible than CSV datasets for some use cases but also slower to download due to on-demand, client-side data normalization overhead in comparison to ready to download CSV files.

## How far back the historical data is available?
Data is available since 2019-03-30 for majority of the supported exchanges (that existed at that time).

exchange

available since

BitMEX

2019-03-30

Deribit

2019-03-30

Binance USDT Futures

2019-11-17

Binance COIN Futures

2020-06-16

Binance Spot

2019-03-30

FTX (delisted)

2019-08-01

OKX Futures

2019-03-30

OKX Swap

2019-03-30

OKX Options

2020-02-01

OKX Spot

2019-03-30

Huobi Futures

2019-11-19

Huobi COIN SwapsHuobi COIN Swaps

2020-03-28

Huobi USDT Swaps

2020-10-30

Huobi Global

2019-11-19

Bitfinex Derivatives

2019-09-14

Bitfinex

2019-05-23

Coinbase Pro

2019-03-30

Kraken Futures

2019-03-30

Kraken

2019-06-04

Bitstamp

2019-03-30

Gemini

2019-08-30

Poloniex

2020-07-01

Bybit

2019-11-07

Bybit Spot

2021-12-04

dYdX

2021-04-06

WOO X

2023-01-20

Kucoin Spot

2022-08-16

Blockchain.com

2023-02-23

Upbit

2021-03-03

Phemex

2020-03-17

Delta

2020-03-30

Ascendex

2021-03-28

FTX US (delisted)

2020-05-22

Binance US

2019-09-25

Gate.io Futures

2020-07-01

Gate.io

2020-07-01

Bitnomial

2023-01-13

Crypto.com

2022-06-01

OKCoin

2019-11-19

bitFlyer

2019-08-30

HitBTC

2019-11-19

CoinFLEX (2.0)

2020-07-14

Binance DEX (delisted)

2019-06-04

## Do you provide historical market data in CSV flat files?
Yes, see downloadable CSV files documentation for more details.

## What programming languages are supported?
Any programming language that can communicate using HTTPS can communicate with our HTTP API.

We do provide official Python and Node.js clients that offer fast and convenient access to tick-level historical market data.

Finally, our open source, locally runnable tardis-machine server with built-in local data caching, provides market data normalization, custom order book snapshots capabilities and real-time market data streaming support that connects directly to exchanges' WebSocket APIs. It provides both streaming HTTP and WebSocket endpoints returning market data for whole time periods (in contrast to Tardis.dev HTTP API where single call returns data for single minute time period) and is available via npm and as a Docker Image.

## What API protocols can be used to access market data?
Historical market data provided by HTTP API can be accessed via HTTPS.

Locally runnable tardis-machine server provides both HTTP and WebSocket based APIs for accessing both historical and real-time market data.

## How time-machine market replay works?
Exchanges' market data WebSocket APIs are designed to publish real-time feeds and not historical ones. Locally runnable tardis-machine server's WebSocket API bridges that gap and allows "replaying" historical market data from any given past point in time with the same data format and 'subscribe' logic as real-time exchanges' APIs. In many cases existing exchanges' WebSocket clients can be used to connect to this endpoint just by changing URL, and receive market data in exchange-native format for date ranges specified in URL query string params.

## Do you support consolidated real-time market data streaming?
We do not provide hosted real-time market data API as we think that given everyone can access exchanges' APIs directly for free without restrictions, relaying on 3rd party for such crucial piece of infrastructure does not make sense (additional latency and another SPOF). 

Instead we developed locally runnable (self hosted) server and open source libraries that offer consolidated real-time normalized market data streaming capabilities, connect directly to exchanges' WebSocket APIs and are completely free to use.

## Are there any rate-limits for the API?
There are no API rate limits for downloadable CSV files API.

Raw data replay API for professional level subscriptions is limited to 30 millions requests per day and up to 60 concurrent requests. API key can be used only from single IP adress at the same time.

For business level subscriptions there are no rate limits for raw data replay API as long as your behavior does not negatively impact other customers API usage experience.
If that's the case, we'll contact your via email and do our best to help how to sort it out - in most cases it's download client bug that over and over downloads the same data in a loop.

## How do I obtain my API key?
API key can be obtained on Tardis.dev website via order form. You'll receive it via email after successful order.

## What if my API key was compromised?
Contact us immediately and we will generate new API key for you.

## What is your infrastructure setup?

#### Market data collection
Highly available Google Cloud Platform Kubernetes Clusters located in in London, UK (europe-west2 region) and Tokyo, Japan (asia-northeast1 region)

#### Market data storage
Two independent, geo-redundant, highly durable storage services

#### Market data distribution
High performance API servers deployed across network of data centers around the globe

## Do you provide SLA?
We do not have a formal SLA in place yet, but all infrastructure is set up to provide highest availability possible on both data collection and distribution side with geo-redundant setup. Both data collection services and public APIs are constantly monitored from multiple locations and our team is immediately notified in case of any issue. We don't practice maintenance that would affect API availability, but in very rare circumstance if that would happen we'll communicate that in advance. If a formal SLA is something that your business require contact us.

/$[PreviousFrequently Asked Questions](/faq)[NextData](/faq/data)Last updated 2 months ago

================================================================================

# Data

Source: https://docs.tardis.dev/faq/data
Extraction Method: playwright
Components: code_block(5)

Copy
1. Frequently Asked Questions

# Data
$
## What data types do you support?
We provide the most comprehensive and granular market data on the market sourced from real-time WebSocket APIs with complete control and transparency how the data is being recorded.

Via downloadable CSV data files following normalized tick-level data types are available:

• trades
• incremental order book L2 updates
• order book snapshots (top 25 and top 5 levels)
• options_chain
• quotes
• derivative tick info (open interest, funding rate, mark price, index price)
• liquidations

Raw data API that is available for pro and business subscriptions provides data in exchange-native data format. See historical data details to learn about real-time channels captured for each exchange. Each captured channel can be considered a different exchange specific data type (for example Binance bookTicker channel, or BitMEX liquidation channel).

We also provide following normalized data types via our client libs (normalization is done client-side, using raw data API as a data source):

• trades
• order book L2 updates
• order book snapshots (tick-by-tick, 10ms, 100ms, 1s, 10s etc)
• quotes
• derivative tick info (open interest, funding rate, mark price, index price)
• liquidations
• options summary
• OHLCV
• volume/tick based trade bars

## What does high frequency historical data mean?
We always collect and provide data with the most granularity that exchange can offer via it's real-time WS feeds. High frequency can mean different things for different exchanges due to exchanges APIs limitations. For example for Coinbase Pro it can mean L3 order book data (market-by-order), for Binance Futures all order book L2 real-time updates and for Binance Spot it means order book updates aggregated in 100ms intervals.

## How historical raw market data is being sourced?
Raw market data is sourced from exchanges real-time WebSocket APIs. 
For cases where exchange lacks WebSocket API for particular data type we fallback to pooling REST API periodically, e.g.,  Binance Futures open interest data.

See market data collection overview for more details and why data source matters.

## Why data source matters and why we use real-time WebSocket feeds as data source vs periodically calling REST endpoints?
Recording exchanges real-time WebSocket feeds allows us preserving and providing the most granular data that exchanges APIs can offer including data that is simply not available via their REST APIs like tick level order book updates.

Historical data sourced from WebSocket real-time feeds adheres to what you'll see when trading live and can be used to exactly replicate live conditions even if it means some occasional connection drops causing small data gaps, real-time data publishing delays especially during larger market moves, duplicated trades or crossed books in some edge cases. We find that trade-off acceptable and even if data isn't as clean and corrected as sourced from REST APIs, it allows for more insight into market microstructure and various unusual exchanges behaviors that simply can't be captured otherwise.

Simple example would be latency spikes for many exchanges during increased volatility periods where exchange publish trade/order book/quote WebSocket messages with larger than usual latency or simply skip some of the the updates and then return those in one batch. Querying the REST API would result in nice, clean trade history, but such data wouldn't fully reflect real actionable market behavior and would result in unrealistic backtesting results, breaking  in the real-time scenarios.

See market data collection overview for more details.

## What L2 order book data can be used for?
L2 data (market-by-price) includes bids and asks orders aggregated by price level and can be used to analyze among other things:

• order book imbalance
• average execution cost
• average liquidity away from midpoint
• average spread
• hidden interest (i.e., iceberg orders)

We do provide L2 data both in CSV format as incremental order book L2 updates, tick level order book snapshots (top 25 and top 5 levels) as well as in exchange-native format via API and client libraries that can perform full order book reconstruction client-side.

## What L3 order book data can be used for?
L3 data (market-by-order) includes every order book order addition, update, cancellation and match and can be used to analyze among other things:

• order resting time
• order fill probability
• order queue dynamics

Historical L3 data is currently available via API for Bitfinex, Coinbase Pro and Bitstamp - remaining supported exchanges provide L2 data only.

## What is the maximum order book depth available for each supported exchange?
We always collect full depth order book data as long as exchange's WebSocket API supports it. Table below shows current state of affairs for each supported exchange.

exchange

order book depth

order book updates frequency

BitMEX

full order book depth snapshot and updates

real-time

Deribit

full order book depth snapshot and updates

real-time

Binance USDT Futures

top 1000 levels initial order book snapshot, full depth incremental order book updates

real-time, dynamically adjusted

Binance COIN Futures

top 1000 levels initial order book snapshot, full depth incremental order book updates

real-time, dynamically adjusted

Binance Spot

top 1000 levels initial order book snapshot, full depth incremental order book updates

100ms

FTX

top 100 levels initial order book snapshot and updates

real-time

OKX Futures

top 400 levels initial order book snapshot and updates

real-time

OKX Swap

top 400 levels initial order book snapshot and updates

real-time

OKX Options

top 400 levels initial order book snapshot and updates

real-time

OKX Spot

top 400 levels initial order book snapshot and updates

real-time

Huobi Futures

top 150 levels initial order book snapshot and updates

30ms

Huobi COIN Swaps

top 150 levels initial order book snapshot and updates

30ms

Huobi USDT Swaps

top 150 levels initial order book snapshot and updates

30ms

Huobi Global

top 150 levels initial order book snapshot and updates

100ms

Bitfinex Derivatives

top 100 levels initial order book snapshot and updates

real-time

Bitfinex

top 100 levels initial order book snapshot and updates

real-time

Coinbase Pro

full order book depth snapshot and updates

real-time

Kraken Futures

full order book depth snapshot and updates

real-time

Kraken

top 1000 levels initial order book snapshot and updates

real-time

Bitstamp

full order book depth snapshot and updates

real-time

Gemini

full order book depth snapshot and updates

real-time

Poloniex

full order book depth snapshot and updates

real-time

Bybit

top 25 levels initial order book snapshot and updates

real-time

dYdX

full order book depth snapshot and updates

real-time

Upbit

top 15 levels snapshots

real-time

Phemex

top 30 levels initial order book snapshot and updates

20ms

FTX US

top 100 levels initial order book snapshot and updates

real-time

Binance US

top 1000 levels initial order book snapshot, full depth incremental order book updates

100ms

Gate.io Futures

top 20 levels order book snapshots

unknown

Gate.io

top 30 levels order book snapshots

unknown

OKCoin

top 400 levels initial order book snapshot and updates

real-time

bitFlyer

full order book depth snapshot and updates

real-time

HitBTC

full order book depth snapshot and updates

real-time

Binance DEX

top 1000 levels initial order book snapshot, full depth incremental order book updates

100ms

## Which exchanges support liquidations data type?
Liquidations data is sourced from exchanges WebSocket APIs when supported with fallback to pooling REST APIs when WebSockets APIs do not support that data type and can be accessed via raw data APIs (replaying relevant channel) or as normalized data type via CSV downloads.

exchange

available since

notes

BitMEX

2019-03-30

collected from WS liquidation channel

Deribit

2019-03-30

collected from WS trade channel (trades with liquidation flag)

Binance USDT Futures

2019-11-17

collected from WS forceOrder stream, since 2021-04-27 liquidation orders streams do not push realtime order data anymore, instead, they push snapshot order data at a maximum frequency of 1 order push per second

Binance COIN Futures

2020-06-16

collected from WS forceOrder stream, since 2021-04-27 liquidation orders streams do not push realtime order data anymore, instead, they push snapshot order data at a maximum frequency of 1 order push per second

FTX

2019-08-01

collected from WS trades channel (trades with liquidation flag)

OKX Futures

2020-12-18

collected by pooling OKEx REST APIs since liquidations aren't available via WS feeds

OKX Swap

2020-12-18

collected by pooling OKEx REST APIs since liquidations aren't available via WS feeds

Huobi Futures

2020-06-24

collected from WS liquidation_orders channel

Huobi Swap

2020-06-24

collected from WS liquidation_orders channel

Bitfinex Derivatives

2019-09-14

collected from WS liquidations channel

Kraken Futures

2019-03-30

collected from WS trade channel (trades with liquidation type)

Bybit

2020-12-18

up until 2021-09-20 collected by pooling Bybit REST APIs since liquidations weren't available via WS feeds, starting from 2021-09-20 collected from WS liquidation channel

## Do you provide historical options data?
Yes, we do provide historical options data for Deribit and OKEx Options - see options chain CSV data type and Deribit and OKEx Options  exchange details pages.

## Do you provide historical futures data?
We cover all leading derivatives exchanges such as BitMEX, Deribit, Binance USDT Futures, Binance COIN Futures, FTX, OKEx, Huobi Futures, Huobi Swap, Bitfinex Derivatives, Bybit and many more.

## What is the difference between futures and perpetual swaps contracts?
Futures contract is a contract that has expiry date (for example quarter ahead for quarterly futures). Futures contract price converges to spot price as the contract approaches expiration/settlement date.
After futures contract expires, exchange settles it and replaces with a new contract for the next period (next quarter for our previous example).

Perpetual swap contract also commonly called "perp", "swap", "perpetual" or "perpetual future" in crypto exchanges nomenclature is very similar to futures contract, but does not have expiry date (hence perpetual). In order to ensure that the perpetual swap contract price stays near the spot price exchanges employ mechanism called funding rate. When the funding rate is positive, Longs pay Shorts. When the funding rate is negative, Shorts pay Longs. This mechanism can be quite nuanced and vary between exchanges, so it's best to study each contract specification to learn all the details (funding periods, mark price mechanisms etc.).

See CSV grouped symbols section if you'd like to download data for all futures or perpetual swaps as a single file for given exchange instead one by one for each individual instrument.

## Do you provide time based aggregated data as well?
We are focusing on providing the best possible tick-level historical data for cryptocurrency exchanges and as of now our APIs (both HTTP and CSV datasets) do offer access to tick-level data only and do not offer support for time based aggregated data.

If you're interested in time based aggregated data (OHLC, interval based order book snapshots) see our client libs that provide such capabilities, but with the caveat that data aggregation is performed client-side from tick-level data sourced from the API, meaning it can be relatively slow process in contrast to ready to download aggregated data.

## Can you record market data for exchange that's not currently supported?
Yes, we're always open to support new promising exchanges. Contact us and we'll get back to you to discuss the details.

## Do you provide market data in normalized format?
Normalized market data (unified data format for every exchange) is available via our official libraries and downloadable CSV files. Our HTTP API provides data only in exchange-native format.

## Do you provide normalized contract amounts for derivatives exchanges in your historical data feeds?
Data we provide has contract amounts exactly as provided by exchanges APIs, meaning in some cases it can be tricky to compare across exchanges due to different contract multipliers (like for example OKEx where each contract has $100 value) or different contract types (linear or inverse).

We'll keep it this way, but we also provide instrument metadata API that returns contract multipliers, tick sizes and more for each instrument in uniform way, allowing easily normalize the contract amounts client-side without having to go through all kinds of documentation on various exchange to find this information.

See instrument metadata API docs.

## What is a difference between exchange-native and normalized data format?
Cryptocurrency markets are very fragmented and every exchange provides data in it's own bespoke data format which we call exchange-native data format. 

Our HTTP API and client libs can provide market data in this format, meaning data you receive is exactly the same as the live data you would have received from exchanges ("as-is").

See how we collect data in exchange-native format and why it's important.

For example BitMEX trade message looks like this:

$Copy
```
{
  "table": "trade",
  "action": "insert",
  "data": [
    {
      "timestamp": "2019-06-01T00:03:11.589Z",
      "symbol": "ETHUSD",
      "side": "Sell",
      "size": 10,
      "price": 268.7,
      "tickDirection": "ZeroMinusTick",
      "trdMatchID": "ebc230d9-0b6e-2d5d-f99a-f90109a2b113",
      "grossValue": 268700,
      "homeNotional": 0.08555051758063137,
      "foreignNotional": 22.987424073915648
    }
  ]
}
```

/$and this is Deribit trade message:

$Copy
```
{
  "jsonrpc": "2.0",
  "method": "subscription",
  "params": {
    "channel": "trades.ETH-26JUN20.raw",
    "data": [
      {
        "trade_seq": 18052,
        "trade_id": "ETH-10813935",
        "timestamp": 1577836825724,
        "tick_direction": 0,
        "price": 132.65,
        "instrument_name": "ETH-26JUN20",
        "index_price": 128.6,
        "direction": "buy",
        "amount": 1.0
      }
    ]
  }
}
```

/$In contrast, normalized data format means the same, unified format across multiple exchanges. We provide normalized data via our client libs (data normalization is performed client-side) as well as via downloadable CSV files.

In the process of data normalization we map the data we collected from real-time WebSocket APIs (exchange-native format) to normalized/unified format across exchanges that is easier to deal with (one data format across multiple exchanges).

We've open sourced all the data mappings from exchange-native to normalized format to make the whole process as transparent as possible.

Sample normalized trade message:

$Copy
```
{
  "type": "trade",
  "symbol": "XBTUSD",
  "exchange": "bitmex",
  "id": "282a0445-0e3a-abeb-f403-11003204ea1b",
  "price": 7996,
  "amount": 50,
  "side": "sell",
  "timestamp": "2019-10-23T10:32:49.669Z",
  "localTimestamp": "2019-10-23T10:32:49.740Z"
}
```

/$We support following normalized data types via our client libs:

• tick-by-tick trades
• order book L2 updates
• order book snapshots (tick-by-tick, 10ms, 100ms, 1s, 10s etc)
• quotes
• derivative tick info (open interest, funding rate, mark price, index price)
• liquidations
• OHLCV
• volume/tick based trade bars

and downloadable CSV data files:

• tick-by-tick trades
• incremental order book L2 updates
• tick level order book snapshots (top 25 and top 5 levels)
• options_chain
• quotes
• derivative tick info (open interest, funding rate, mark price, index price)
• liquidations

## What is the channel field used in the HTTP API and client libs replay functions?
Exchanges when publishing real-time data messages, always publish those for subscription topics clients have subscribed to. Those subscriptions topics are also very often called "channels" or "streams" in exchanges documentations pages and describe data type given message belongs to - for example BitMEX publishes it's trades data via trade channel and order book L2 updates data via orderBookL2.

Since we collect the data for all the channels described in exchanges' details page (Captured real-time market data channels section) our HTTP API and client libs offer filtering capability by those channels names, so for example to get historical trades for BitMEX, channel trade needs to be provided alongside requested instruments symbols (via HTTP API or client lib replay function args).

## What time zone is used in the data?
UTC, always.

## Is provided raw market data complete?
We're doing our best to provide the most complete and reliable historical raw data API on the market. To do so amongst many other things,  we utilize highly available Kubernetes clusters on Google Cloud Platform that offer best in the class availability, networking and monitoring. However due to exchanges' APIs downtimes (maintenance, deployments, connection drops etc.) we can experience data gaps and cannot guarantee 100% data completeness, but 99.9% (99.99% on most days) which should be more than enough for most of the use cases that tick level data is useful for.

In rare circumstances, when exchange's API changes without any notice or we hit new unexpected rate limits we also may fail to record data during such period, it happens very rarely and is very specific for each exchange. Use /exchanges/:exchange API endpoint and check for incidentReports field in order to get most detailed and up to date information on that subject.

## How frequently exchanges drop WebSocket connections?
As long as exchange WebSocket API is not 'hidden' behind Cloudflare proxy (causing relatively frequent "CloudFlare WebSocket proxy restarting, Connection reset by peer" errors) connections are stable for majority of supported exchanges and there are almost no connection drops during the day. In cases when there is more volatility in the market some exchanges tend to drop connections more frequently or have larger latency spikes. Overall it's a nuanced matter that changes over time, if you'd have any questions regarding particular exchange, please do not hesitate to contact us.

## Can historical order books reconstructed from L2 updates be crossed (bid/ask overlap) occasionally?
Although is should never happen in theory, in practice due to various crypto exchanges bugs and peculiarities it can happen (very occasionally), see some posts from users reporting those issues:

• https://www.reddit.com/r/BitMEX/comments/8lbj9e/bidask_ledger_weirdness/
• https://www.reddit.com/r/KrakenSupport/comments/emu7xc/websocket_bid_sometimes_not_being_deletedupdated/
• https://www.reddit.com/r/KrakenSupport/comments/d1a4nx/websocket_orderbook_receiving_wrong_bid_price_for/
• https://twitter.com/coinarb/status/931260529993170944

We do track sequence numbers of WebSocket L2 order book messages when collecting the data and restart connection when sequence gap is detected for exchanges that do provide those numbers.
We observe that even in scenario when sequence numbers are in check, bid/ask overlap can occur. 

When such scenario occurs, exchanges tend to 'forget' to publish  delete messages for the opposite side of the book when publishing new level for given side - we validated that hypothesis by comparing reconstructed order book snapshots that had crossed order book (bid/ask overlap) for which we removed order book levels for the opposite side manually (as exchange didn't publish that 'delete'), with quote/ticker feeds if best bid/ask matches (for exchanges that provide those) - see sample code that implements that manual level removal logic.

## Can exchange publish data with non monotonically increasing timestamps for single data channel?
That shouldn't happen in theory, but we've detected that for some exchanges when new connection is established sometimes first message for given channel & symbol has newer timestamp than subsequent message, e.g., order book snapshot has newer timestamp than first order book update. This is why we provide data via API and CSV downloads for given data ranges based on local timestamps (timestamp of message arrival) which are always monotonically increasing.

## Are exchanges publishing duplicated trades data messages?
Some exchanges are occasionally publishing duplicated trades (trades with the same ids). Since we collect real-time data we also collect and provide duplicate trades via API if those were published by real-time WebSocket feeds of exchanges. Our client libraries have functionality that when working with normalized data can deduplicate such trades, similarly for downloadable CSV files we deduplicate tick-by-tick trades data.

## How order book data snapshots are provided?
Historical market data available via HTTP API provides order book snapshots at the beginning of each day (00:00 UTC) - see details.

We also provide custom order book snapshots with customizable time intervals from tick-by-tick, milliseconds to minutes or hours via client libs in which case custom snapshots are computed client side from raw data provided via HTTP API as well as via downloadable CSV files - book_snapshot_25 and book_snapshot_5 .

## Do you collect order books as snapshots or in streaming mode?
Order books are collected in streaming mode - snapshot at the beginning of each day and then incremental updates. See details.

We also provide custom order book snapshots with customizable time intervals from tick-by-tick, milliseconds to minutes or hours via client libs in which case custom snapshots are computed client side from raw data provided via HTTP API as well as via downloadable CSV files - book_snapshot_25 and book_snapshot_5 .

## How incremental_book_l2 CSV dataset is built from real-time data?
Cryptocurrency exchanges real-time APIs vary a lot, but for L2 order book data they all tend to follow similar flow, first when WS connection is established and subscription is confirmed, exchanges send initial order book snapshot (all existing price levels or top 'x' levels depending on exchange) and then start streaming 'book update' messages (called frequently deltas as well). Those updates when applied to initial snapshot, result in up to data order book state at given time.

We do provide initial L2 snapshots in incremental_book_L2 dataset at the beginning of each day (00:00 UTC, more details), but also anytime exchange closes it's real-time WebSocket connection, see details.

Let's take FTX as an example and start with it's snapshot orderbook message (that is frequently called 'partial' in exchanges API docs as well).

Remaining bids and asks levels were removed from this sample message for the sake of clarity.

$Copy
```
{
  "channel": "orderbook",
  "market": "ETH/USD",
  "type": "partial",
  "data": {
    "time": 1601510401.2166328,
    "checksum": 204980439,
    "bids": [
      [
        359.72,
        121.259
      ]
    ],
    "asks": [
      [
        359.8,
        8.101
      ]
    ],
    "action": "partial"
  }
}
```

/$Such snapshot message maps to the following rows in CSV file:

exchange

symbol

timestamp

local_timestamp

is_snapshot

side

price

amount

ftx

ETH/USD

1601510401216632

1601510401316432

true

ask

359.8

8.101

ftx

ETH/USD

1601510401216632

1601510401316432

true

bid

359.72

121.259

... and here's a sample FTX orderbook update message.

$Copy
```
{
  "channel": "orderbook",
  "market": "ETH/USD",
  "type": "update",
  "data": {
    "time": 1601510427.1840546,
    "checksum": 1377242400,
    "bids": [],
    "asks": [
      [
        360.24,
        4.962
      ],
      [
        361.02,
        0
      ]
    ],
    "action": "update"
  }
}
```

/$Let's see how it maps to CSV format.

exchange

symbol

timestamp

local_timestamp

is_snapshot

side

price

amount

ftx

ETH/USD

1601510427184054

1601510427204046

false

ask

360.24

4.962

ftx

ETH/USD

1601510427184054

1601510427204036

false

ask

361.02

0

See this answer if you have doubts how to reconstruct order book state based on data provided in incremental_book_L2 dataset.

## How can I reconstruct full order book state from  incremental_book_L2 CSV dataset?
See also how incremental_book_l2 CSV dataset is built from real-time data.

In order to reconstruct full order book state correctly from incremental_book_L2 data:

• For each row in the CSV file (iterate in the same order as provided in file):
only if local timestamp of current row is larger than previous row local timestamp(local_timestamp column value) it means you can read your local order book state as it's consistent, why? CSV format is flat where each row represents single price level update, but most exchanges real-time feeds publish multiple order book levels updates via single WebSocket message that need to be processed together before reading locally maintained order book state. We use local timestamp value here to detect all price level updates belonging to single 'update' message.if current row is a part of the snapshot (is_snapshot column value set to true) and previous one was not, reset your local order book state object that tracks price levels for each order book side as it means that there was a connection restart and exchange provided full order book snapshot or it was a start of a new day (each incremental_book_L2 file starts with the snapshot)
if current row amount is set to zero (amount column value set to 0) remove such price level (row's price column) from your local order book state as such price level does not exist anymore
if current row amount is not set to zero update your local order book state price level with new value or add new price level if not exist yet in your local order book state - maintain separately bids and asks order book sides (side column value)

Alternatively we do also provide top 25 and top 5 levels order book snapshots CSV datasets ready to download.

## How CSV datasets are split into the files?
CSV datasets are available in daily intervals split by exchange, data type and symbol. In addition to standard currency pairs/instrument symbols, each exchange also has special 'grouped' symbols available depending if it supports given market type: SPOT, FUTURES, OPTIONS and PERPETUALS. That feature is useful if someone is interested in for examples all Deribit's options instruments' trades or quotes data without a need to request data for each symbol separately one by one.

## How market data messages are being timestamped?
Each message received via WebSocket connection is timestamped with 100ns precision using synchronized clock at arrival time (before any message processing) and stored in ISO 8601 format.

## What is the new historical market data delay in relation to real-time?
For API access it's 15 minutes (T - 15min), downloadable CSV files for given day are available on the next day around 06:00 UTC.

/$[PreviousGeneral](/faq/general)[NextBilling and Subscriptions](/faq/billing-and-subscriptions)Last updated 1 year ago

================================================================================

# Billing and Subscriptions

Source: https://docs.tardis.dev/faq/billing-and-subscriptions
Extraction Method: playwright

Copy
1. Frequently Asked Questions

# Billing and Subscriptions

## What is the order process?

1. Select data plan and access type that you're interested in via order form on Tardis.dev website.
available data plansIndividualPerpetualsDerivativesAll Exchangesavailable access typesOne-off PurchaseSubscriptionSoloAcademicProBusiness
2. Proceed to checkout where you provide email address and payment details.
accepted payment methodsCredit Cards (Mastercard Visa Maestro American Express Discover Diners Club JCB UnionPay)PayPalApple Pay  (one-off purchases only)Wire Transfers (for one-off purchases only)
3. Successfully complete your payment and receive the API key via email that allows you to download CSV datasets and access historical data via API. API key is valid as long as subscription is active or 6 months for one-off purchases.

For larger orders we do also accept pay through invoicing.

## Do you provide discounts?
We do provide discounts in a transparent form via different subscriptions types.

## How one-off purchase based access works?
One-off purchase provides access to specific time periods of historical market data.
API key is valid for a year since purchase and allows access to all available data types (trades, order books etc.) for ordered date ranges both via API and downloadable CSV files.

## How subscription based access works?
Subscriptions based access model relies on recurring payments at regular intervals (monthly, quarterly, yearly) and offers access to newly collected market data as it becomes available as well as existing historical market data which range depends on chosen billing period.

There are three 'dimensions' you can customize your subscription by:

• Subscription type - Academic, Solo, Pro or Business
• Data plan (which exchanges data you get access to) - Individual, Perpetuals, Derivatives or 
All Exchanges
• Billing interval (how much of historical data you get access to) - monthly, quarterly or yearly

For example "All Exchanges" Business Subscription with yearly billing period allows accessing all available existing historical data via API and CSV files and one year of new data as it becomes available (for initial payment).

API key is valid as long as subscription is active and allows access to all available data types (trades, orders book data, quotes, funding, liquidations etc.) via downloadable CSV files and via raw market data API (for Pro and Business subscriptions types only).

## What are the differences between subscriptions types?
Academic

Solo

Professional

Business

Downloadable CSV files

✓

✓

✓

✓

Raw data replay API
(HTTP API /data-feeds)

—

—

✓

✓

Tardis Machine replay APis

—

—

✓

✓

Tardis Machine real-time APIs

✓

✓

✓

✓

Instrument metadata API

—

—

✓

✓

Additional API keys

—

—

—

✓

Professional support level

none

none

email (priority)

dedicated

Integration assistance

—

—

—

✓

Vendor onboarding

—

—

—

✓

Api keys count

1

1

1

10

Unlimited data raplay API

—

—

✓ (30 millions requests per day, up to 60 concurrent requests)

✓

Business subscriptions include up to 10 additional API keys that can be used to get access to historical data by many team members at the same time including across different geo-locations and provide dedicated communication channel (via Telegram Messenger, email or Zoom Calls) for your company where our team is on standby to answer any questions you may have.

Business subscriptions also provide vendor onboarding support on our side including filling W9, ACH and other company specific forms as well as integration assistance - we do provide dedicated code snippets to help out with seamless integration.

Academic subscriptions require confirmation of eligibility, for example using university (@edu) email address.

Pro, academic and solo subscriptions plans include single API key that can be used to get access to historical data. Such API key can't be used by different team members (IP addresses) at the same time.
Real-time market data streaming feature does not have this limitation (does not require API key at all).

## Do subscriptions include access to historical data as well?
Yes,  depending on chosen billing period, subscriptions include access to existing historical market data as well:

• all available historical data if subscription is billed yearly - historical market data is available since 2019-03-30 for majority of the supported exchanges (see exchange details page for exact date for particular exchange)
• 12 months of historical data if subscription is billed quarterly, e.g., subscription that has started at 2020-04-01, includes access to historical data since 2019-04-01 - it's not a rolling time window, but fixed starting date since when historical data is available for your subscription
• 4 months of historical data if subscription is billed monthly, e.g., subscription that has started at 2020-04-01, includes access to historical data since 2019-12-01 -  it's not a rolling time window, but fixed starting date since when historical data is available for your subscription

All subscriptions provide access to all available data types (trades, orders book data, quotes, funding  etc.) via downloadable CSV files and raw data replay API (for pro and business subscriptions types).

## What is included in "Individual" data plan?
"Individual" data plan provides per-exchange access to market data that includes full feed (all instruments) and data types of selected exchange(s), for example full Coinbase exchange data feed.

See Historical Data Details to learn more what data is available for each supported exchange.

"Individual" data plan allows access to all available data types (trades, orders book data, quotes, funding etc.) via downloadable CSV files and raw data replay API (for pro and business subscriptions types).

Range of historical data access for "Individual" data plan depends on chosen billing period (for example: access to all existing historical data we collected if subscription is billed yearly).

"Individual" data plan is available both for subscriptions and one-off purchases.

## What is included in "Perpetuals" data plan?
"Perpetuals" data plan provides access to the following perpetual swaps instruments' market data (over 500 perpetual swaps instruments across 13 exchanges):

• BitMEX: all perpetual swaps instruments
• Deribit: all perpetual swaps instruments
• Binance USDT Futures: all perpetual swaps instruments
• Binance COIN Futures: all perpetual swaps instruments
• FTX: all perpetual swaps instruments
• OKX Swap: all perpetual swaps instruments
• Huobi COIN Swaps: all perpetual swaps instruments
• Huobi USDT Swaps: all perpetual swaps instruments
• bitFlyer: FX_BTC_JPY
• Bitfinex Derivatives: all perpetual swaps instruments
• Bybit: all perpetual swaps instruments
• dYdX: all perpetual swaps instruments
• Phemex: all perpetual swaps instruments
• Delta: all perpetual swaps instruments
• Gate.io Futures: all perpetual swaps instruments
• CoinFLEX: all perpetual swaps instruments
• dYdX: all perpetual swaps instruments
• WOO X: all perpetual swaps instruments
• Ascendex: all perpetual swaps instruments
• Crypto.com: all perpetual swaps instruments

"Perpetuals" data plan allows access to all available data types (trades, orders book data, funding etc.) via downloadable CSV files and raw data replay API (for pro and business subscriptions types).

Range of historical data access for "Perpetuals" data plan depends on chosen billing period (for example: access to all existing historical data we collected if subscription is billed yearly).

"Perpetuals" data plan is available both for subscriptions and one-off purchases.

## What is included in "Derivatives" data plan?
"Derivatives" data plan provides access to the following derivatives exchanges' market data:

• BitMEX: all exchange's instruments
• Deribit: all exchange's instruments
• Binance USDT Futures: all exchange's instruments
• Binance COIN Futures: all exchange's instruments
• FTX: all exchange's instruments
• OKX Futures: all exchange's instruments
• OKX Swap: all exchange's instruments
• OKX Options: all exchange's instruments
• Huobi Futures: all exchange's instruments
• Huobi COIN Swap: all exchange's instruments
• Huobi USDT Swaps: all exchange's instruments
• Bitfinex Derivatives: all exchange's instruments
• Bybit: all exchange's instruments
• DYdX: all exchange's instruments
• Phemex: all exchange's instruments
• CoinFLEX: : all exchange's instruments
• Delta: all exchange's instruments
• bitFlyer: all exchange's instruments
• Gate.io Futures: all exchange's instruments
• dYdX: all perpetual swaps instruments
• WOO X: all exchange's instruments
• Crypto.com: all exchange's instruments
• Ascendex: all exchange's instruments

"Derivatives" data plan allows access to all available data types (trades, orders book data, quotes, funding  etc.) via downloadable CSV files and raw data replay API (for pro and business subscriptions types).

Range of historical data access for "Derivatives" data plan depends on chosen billing period (for example: access to all existing historical data we collected if subscription is billed yearly).

"Derivatives" data plan is available both for subscriptions and one-off purchases.

## What is included in "All Exchanges" data plan?
"All Exchanges" data plan provides access to market data of all supported exchanges (30+ leading spot and derivatives exchanges, see full list).

"All Exchanges" data plan allows access to all available data types (trades, orders book data, quotes, funding, liquidations  etc.) for all supported exchanges and theirs instruments/currency pairs via downloadable CSV files and raw data replay API (for pro and business subscriptions types).

Range of historical data access for "All Exchanges" data plan depends on chosen billing period (for example: access to all existing historical data we collected if subscription is billed yearly).

"All Exchanges" data plan is available both for subscriptions and one-off purchases.

## How can I change my subscription plan?
Contact us describing which plan you'd like to change to and we'll handle the rest.

## Can I pay through invoicing?
We offer invoicing for customers paying over $6000 for data access. Simply use our order form and "PAY THROUGH INVOICING" button.

Alternatively contact us with orders details you're interested in (data plan, billing period) and we'll send you back invoice that if paid will give you the access to the data.

Pay through invoicing order form previewSample invoice document preview
## Can I get quotation document before making an order?
Yes, please use our order form and "REQUEST QUOTATION" button.

Alternatively contact us with orders details you're interested in (data plan, billing period) and we'll send you back quotation document in no time.

request quotation document order form previewSample quotation document preview
## How can I get an invoice and VAT refund?
After successful order you'll receive Receipt email from Paddle which is our online reseller & payment processor. Click on the button titled "View Receipt" there.

Receipt email previewYou will be redirected to the receipt page where you will be able to enter your address details by clicking on "Add address & VAT Number“ link.

Receipt page previewIf you  would like to enter a VAT number select "This is a business purchase" checkbox to enter the VAT ID if forgot to enter it during the checkout. The tax amount will be refunded in max. 12 hours after it is confirmed by Paddle.

"Edit receipt information" preview
#### Save invoice as PDF

• Right click on the screen and click 'Print...' in context menu
• Change destination to 'Save as PDF'
• Click 'Save' button to save invoice as PDF file

## What are your VAT details?
Click on the link titled "Click here to get a full invoice with address & custom information" provided with the order confirmation email sent by Paddle to get the address and VAT ID of Paddle who process our payments. Paddle acts as a reseller and Merchant of Record so they handle VAT on our behalf.

## I’ve lost my invoice. How do I get a new one?
You need to contact us or help@paddle.com to request a new invoice. Please provide the email address you bought the subscription with and any extra details that might help.

## What is the refund policy?
We do not offer refunds for initial subscription payments and one-off purchases.

If you are on yearly billing and forget to cancel your subscription before the renewal date, reach out to us within seven days after the renewal date to discuss a refund.

If you’re on a monthly or quarterly billing, please be sure to cancel your subscription before the end date of your current plan as there are no refunds for recurring payments on monthly and quarterly billing plans.

If you'd like to test the service, we offer generous free trials. Simply reach out to us and we'll set up test account for you in no time.

## How can I cancel my subscription?
In order to cancel you active subscription use the 'Cancel subscription' link we've sent you in email together with your API key or contact us and we'll provide cancellation link for you. 

Alternatively you can email Paddle (help@paddle.com) which acts as our reseller and Merchant of Record including a note of the email address you used to purchase your subscription and your order number.

## Do you accept payments in cryptocurrency?
We accept BTC, ETH and USDT for one-off purchases. Contact us and we'll get back to you with details.

## How I can update my credit card information?
In order to update your credit card information use the 'Update payment method' link we've sent you in email together with your API key or contact us and we'll provide that link for you.

[PreviousData](/faq/data)[NextDownloadable CSV files](/downloadable-csv-files)Last updated 2 months ago

================================================================================

# Downloadable CSV files

Source: https://docs.tardis.dev/downloadable-csv-files
Extraction Method: playwright
Components: code_block(6)

Copy
# Downloadable CSV files
$
## Quick start
CSV datasets are available via dedicated datasets API that allows downloading tick level incremental order book L2 updates, order book snapshots, trades, options chains, quotes, derivative tickers and liquidations data.

For ongoing data, CSV datasets for a given day are available on the next day around 06:00 UTC.

CSV datasets are exported from exchanges' real-time WebSocket feeds data we collected (and also provide via our API as historical data in exchange-native format).

Historical datasets for the first day of each month are available to download without API key. 

Our Node.js and Python clients have built-in functions to efficiently download whole date range of data.

PythonNode.jscURLCopy
```
# pip install tardis-dev
# requires Python >=3.6
from tardis_dev import datasets

datasets.download(
    exchange="deribit",
    data_types=[
        "incremental_book_L2",
        "trades",
        "quotes",
        "derivative_ticker",
        "book_snapshot_25",
        "liquidations"
    ],
    from_date="2019-11-01",
    to_date="2019-11-02",
    symbols=["BTC-PERPETUAL", "ETH-PERPETUAL"],
    api_key="YOUR API KEY (optionally)",
)
```

See full example that shows all available download options (download path customization, filenames conventions and more).

Copy
```
// npm install tardis-dev@10.0.20
// requires node version >=12
const { downloadDatasets } = require('tardis-dev')

;(async () => {
  await downloadDatasets({
    exchange: 'deribit',
    dataTypes: [
      'incremental_book_L2',
      'trades',
      'quotes',
      'derivative_ticker',
      'book_snapshot_25',
      'liquidations'
    ],
    from: '2019-11-01',
    to: '2019-11-02',
    symbols: ['BTC-PERPETUAL', 'ETH-PERPETUAL'],
    apiKey: 'YOUR API KEY (optionally)'
  })
})()
```

See full example that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
curl -o deribit_trades_2019-11-01_BTC-PERPETUAL.csv.gz https://datasets.tardis.dev/v1/deribit/trades/2019/11/01/BTC-PERPETUAL.csv.gz
```

/$See datasets API reference.

## CSV format details

• columns delimiter: , (comma)
• new line marker: \n (LF)
• decimal mark: . (dot)
• date time format: microseconds since epoch (https://www.epochconverter.com/)
• date time timezone: UTC

## Data types

### • incremental_book_L2
Incremental order book L2 updates collected from exchanges' real-time WebSocket order book L2 data feeds - data as deep and granular as underlying real-time data source, please see FAQ: What is the maximum order book depth available for each supported exchange? for more details.

Learn in more detail how incremental_book_l2 CSV dataset is built from real-time data.

As exchanges real-time feeds usually publish multiple order book levels updates via single message you can recognize that by grouping rows by local_timestamp field if needed.

If you have any doubts how to correctly reconstruct full order book state from incremental_book_L2 CSV dataset, please see this answer or contact us.

In case you only need order book data for top 25 or top 5 levels, we do provide datasets with already reconstructed snapshots for every update for those. See book_snapshot_25 and book_snapshot_5.

CSV incremental_book_L2  schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

is_snapshot

possible values:

• true - if update was a part of initial order book snapshot
• false - if update was not a part of initial order book snapshot

If last update was not a snapshot and current one is, then existing order book state must be discarded (all existing levels removed)

side

determines to which side of the order book update belongs to:

• bid - bid side of the book, buy orders
• ask - ask side of the book, sell orders

price

price identifying book level being updated

amount

updated price level amount as provided by exchange, not a delta - an amount of 0 indicates that the price level can be removed

exchange

symbol

timestamp

local_timestamp

is_snapshot

side

price

amount

deribit

BTC-PERPETUAL

1585699209920000

1585699209934201

false

ask

6443.5

38640

deribit

BTC-PERPETUAL

1585699209947000

1585699209957629

false

bid

6311.5

0

deribit

BTC-PERPETUAL

1585699209950000

1585699209963464

false

ask

6428

13210

deribit

BTC-PERPETUAL

1585699209967000

1585699209979152

false

bid

6311.5

750

deribit

BTC-PERPETUAL

1585699209970000

1585699209983585

false

bid

6327

16010

deribit

BTC-PERPETUAL

1585699209970000

1585699209983585

false

bid

6325

210530

deribit

BTC-PERPETUAL

1585699209972000

1585699209983691

false

bid

6351

810

deribit

BTC-PERPETUAL

1585699209972000

1585699209983691

false

bid

6352.5

18830

deribit

BTC-PERPETUAL

1585699209974000

1585699209983703

false

ask

6492

100

[https://datasets.tardis.dev/v1/deribit/incremental_book_L2/2020/04/01/BTC-PERPETUAL.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/incremental_book_L2/2020/04/01/BTC-PERPETUAL.csv.gz)Deribit BTC-PERPETUAL incremental order book L2 updates for 2020-04-01[https://datasets.tardis.dev/v1/deribit/incremental_book_L2/2020/09/01/FUTURES.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/incremental_book_L2/2020/09/01/FUTURES.csv.gz)Deribit FUTURES instruments incremental order book L2 updates for 2020-09-01
### • book_snapshot_25
Tick-level order book snapshots reconstructed from exchanges' real-time WebSocket order book L2 data feeds. Each row represents top 25 levels from each side of the limit order book book and was recorded every time any of the tracked bids/asks top 25 levels have changed.

CSV book_snapshot_25 schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

asks[0..24].price

top 25 asks prices in ascending order, empty if there aren't enough price levels available in the order book or provided by the exchange

asks[0..24].amount

top 25 asks amounts in ascending order, empty if there aren't enough price levels available in the order book or provided by the exchange

bids[0..24].price

top 25 bids prices in descending order, empty if there aren't enough price levels available in the order book or provided by the exchange

bids[0..24].amount

top 25 bids amounts in descending order, empty if there aren't enough price levels available in the order book or provided by the exchange

exchange

symbol

timestamp

local_timestamp

asks[0].price

asks[0].amount

bids[0].price

bids[0].amount

asks[1].price

asks[1].amount

bids[1].price

bids[1].amount

asks[2].price

asks[2].amount

bids[2].price

bids[2].amount

asks[3].price

asks[3].amount

bids[3].price

bids[3].amount

asks[4].price

asks[4].amount

bids[4].price

bids[4].amount

asks[5].price

asks[5].amount

bids[5].price

bids[5].amount

asks[6].price

asks[6].amount

bids[6].price

bids[6].amount

asks[7].price

asks[7].amount

bids[7].price

bids[7].amount

asks[8].price

asks[8].amount

bids[8].price

bids[8].amount

asks[9].price

asks[9].amount

bids[9].price

bids[9].amount

asks[10].price

asks[10].amount

bids[10].price

bids[10].amount

asks[11].price

asks[11].amount

bids[11].price

bids[11].amount

asks[12].price

asks[12].amount

bids[12].price

bids[12].amount

asks[13].price

asks[13].amount

bids[13].price

bids[13].amount

asks[14].price

asks[14].amount

bids[14].price

bids[14].amount

asks[15].price

asks[15].amount

bids[15].price

bids[15].amount

asks[16].price

asks[16].amount

bids[16].price

bids[16].amount

asks[17].price

asks[17].amount

bids[17].price

bids[17].amount

asks[18].price

asks[18].amount

bids[18].price

bids[18].amount

asks[19].price

asks[19].amount

bids[19].price

bids[19].amount

asks[20].price

asks[20].amount

bids[20].price

bids[20].amount

asks[21].price

asks[21].amount

bids[21].price

bids[21].amount

asks[22].price

asks[22].amount

bids[22].price

bids[22].amount

asks[23].price

asks[23].amount

bids[23].price

bids[23].amount

asks[24].price

asks[24].amount

bids[24].price

bids[24].amount

deribit

BTC-PERPETUAL

1599868800206000

1599868800253274

10396

48050

10395.5

18220

10396.5

22220

10395

16570

10397

100

10394.5

22630

10397.5

8360

10394

16670

10398

1500

10393.5

16570

10398.5

13210

10393

5600

10399.5

60070

10392.5

20500

10400

5100

10392

30

10400.5

5140

10391.5

75780

10401

13040

10391

12110

10401.5

2250

10390.5

280

10402

9150

10390

52680

10402.5

119390

10389.5

18240

10403

23070

10389

73010

10403.5

53930

10388.5

67500

10404

43590

10388

313140

10404.5

271050

10387.5

280

10405

73710

10387

9840

10405.5

32480

10386.5

104570

10406

41220

10386

269050

10406.5

20400

10385.5

21840

10407

45460

10385

79000

10407.5

69630

10384.5

220

10408

22230

10384

71440

10408.5

30840

10383.5

44740

deribit

BTC-PERPETUAL

1599868800280000

1599868800310441

10396

48050

10395.5

18220

10396.5

22220

10395

16570

10397

100

10394.5

22630

10397.5

8360

10394

16670

10398

1500

10393.5

16570

10398.5

13210

10393

5600

10399.5

60070

10392.5

20500

10400

5100

10392

30

10400.5

5140

10391.5

75780

10401

13040

10391

12110

10401.5

2250

10390.5

280

10402

9150

10390

52680

10402.5

119390

10389.5

18240

10403

23070

10389

73010

10403.5

53930

10388.5

67500

10404

43590

10388

313140

10404.5

271050

10387.5

280

10405

73710

10387

9850

10405.5

32480

10386.5

104570

10406

41220

10386

269050

10406.5

20400

10385.5

21840

10407

45460

10385

79000

10407.5

69630

10384.5

220

10408

22230

10384

71440

10408.5

30840

10383.5

44740

deribit

BTC-PERPETUAL

1599868814801000

1599868814817631

10398.5

20

10398

7400

10399

4890

10397.5

17680

10399.5

520

10396.5

17680

10400

1700

10396

30280

10400.5

3010

10395.5

44110

10401

40

10395

20080

10401.5

2570

10394.5

91410

10402

400

10394

97570

10402.5

50530

10393.5

27510

10403

9960

10393

3330

10403.5

54250

10392.5

200

10404

40

10392

20400

10404.5

10

10391.5

75650

10405

93470

10391

9580

10405.5

32540

10390.5

260040

10406

26130

10390

310

10406.5

9670

10389.5

21210

10407

1180

10389

87320

10407.5

89030

10388.5

61140

10408

54860

10388

283120

10408.5

42430

10387.5

10680

10409

260680

10387

11400

10409.5

19220

10386.5

92470

10410

94970

10386

49640

10410.5

50

10385.5

6420

deribit

BTC-PERPETUAL

1599868814809000

1599868814817632

10398.5

20

10398

7400

10399

4890

10397.5

17680

10399.5

520

10396.5

17680

10400

1700

10396

30280

10400.5

3010

10395.5

44110

10401

40

10395

20080

10401.5

2570

10394.5

91410

10402

400

10394

97570

10402.5

50530

10393.5

27510

10403

9960

10393

3330

10403.5

54900

10392.5

200

10404

40

10392

20400

10404.5

10

10391.5

75650

10405

93470

10391

9580

10405.5

32540

10390.5

260040

10406

26130

10390

310

10406.5

9670

10389.5

21210

10407

1180

10389

87320

10407.5

89030

10388.5

61140

10408

54860

10388

283120

10408.5

42430

10387.5

10680

10409

260680

10387

11400

10409.5

19220

10386.5

92470

10410

94970

10386

49640

10410.5

50

10385.5

6420

deribit

BTC-PERPETUAL

1599868815411000

1599868815414125

10399

4910

10398

25080

10399.5

20

10397.5

17680

10400

2200

10396.5

17680

10400.5

2910

10396

31780

10401

40

10395.5

44110

10401.5

570

10395

20050

10402

500

10394.5

91440

10402.5

52990

10394

98510

10403

3500

10393.5

26570

10403.5

45100

10393

3330

10404

9190

10392.5

470

10404.5

10

10392

18300

10405

70030

10391.5

85130

10405.5

60800

10391

8640

10406

26130

10390.5

260040

10406.5

9270

10390

22530

10407

240

10389.5

14030

10407.5

89970

10389

65120

10408

23640

10388.5

72380

10408.5

62090

10388

283120

10409

260680

10387.5

10280

10409.5

18150

10387

11400

10410

94970

10386.5

123630

10410.5

50

10386

8470

10411

28210

10385.5

6420

deribit

BTC-PERPETUAL

1599868815411000

1599868815419035

10399

4910

10398

25080

10399.5

20

10397.5

17680

10400

2200

10396.5

17680

10400.5

2910

10396

31780

10401

40

10395.5

44110

10401.5

570

10395

20050

10402

500

10394.5

91440

10402.5

52990

10394

98510

10403

3500

10393.5

26570

10403.5

45100

10393

3330

10404

9190

10392.5

470

10404.5

10

10392

18300

10405

70030

10391.5

85130

10405.5

60800

10391

8640

10406

26130

10390.5

260040

10406.5

17270

10390

22530

10407

240

10389.5

14030

10407.5

89970

10389

65120

10408

23640

10388.5

72380

10408.5

62090

10388

283120

10409

260680

10387.5

10280

10409.5

18150

10387

11400

10410

94970

10386.5

123630

10410.5

50

10386

8470

10411

28210

10385.5

6420

deribit

BTC-PERPETUAL

1599868907943000

1599868907946933

10398

4600

10397.5

73090

10399.5

10

10397

24630

10400

3300

10396.5

22770

10400.5

10270

10396

3130

10401

25390

10395.5

5000

10401.5

119790

10395

9060

10402

8510

10394.5

17910

10402.5

8180

10394

138990

10403

10000

10393.5

33080

10404

7960

10393

3020

10404.5

15130

10392.5

8130

10405

128930

10392

100920

10405.5

109560

10391.5

83330

10406

8610

10391

32220

10406.5

34890

10390.5

278270

10407

44440

10390

47980

10407.5

102620

10389.5

292240

10408

20660

10389

65100

10408.5

175160

10388.5

790

10409

7660

10388

55720

10409.5

308550

10387.5

31440

10410

138130

10387

3830

10410.5

15940

10386.5

109470

10411

2610

10386

31560

10411.5

3780

10385.5

3450

deribit

BTC-PERPETUAL

1599868907944000

1599868907953129

10398

4600

10397.5

73090

10399.5

10

10397

24630

10400

3300

10396.5

22770

10400.5

10270

10396

3130

10401

25390

10395.5

5000

10401.5

119790

10395

1060

10402

8510

10394.5

17910

10402.5

8180

10394

146990

10403

10000

10393.5

33080

10404

7960

10393

3020

10404.5

15130

10392.5

8130

10405

128930

10392

100920

10405.5

109560

10391.5

83330

10406

8610

10391

32220

10406.5

34890

10390.5

278270

10407

44440

10390

47980

10407.5

102620

10389.5

292240

10408

20660

10389

65100

10408.5

175160

10388.5

790

10409

7660

10388

55720

10409.5

308550

10387.5

31440

10410

138130

10387

3830

10410.5

15940

10386.5

109470

10411

2610

10386

31560

10411.5

3780

10385.5

3450

deribit

BTC-PERPETUAL

1599868907993000

1599868907997022

10398

4600

10397.5

73090

10399.5

2010

10397

24630

10400

3300

10396.5

22770

10400.5

8270

10396

3130

10401

25390

10395.5

5000

10401.5

119790

10395

1060

10402

8510

10394.5

17910

10402.5

8180

10394

146990

10403

10000

10393.5

33080

10404

7960

10393

3020

10404.5

15130

10392.5

8130

10405

128930

10392

100920

10405.5

109560

10391.5

83330

10406

8610

10391

32220

10406.5

34890

10390.5

278270

10407

44440

10390

47980

10407.5

102620

10389.5

292240

10408

20660

10389

65100

10408.5

175160

10388.5

790

10409

7660

10388

55720

10409.5

308550

10387.5

31440

10410

138130

10387

3830

10410.5

15940

10386.5

109470

10411

2610

10386

31560

10411.5

3780

10385.5

3450

[https://datasets.tardis.dev/v1/bitmex/book_snapshot_25/2020/09/01/XBTUSD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/bitmex/book_snapshot_25/2020/09/01/XBTUSD.csv.gz)BitMEX XBTUSD top 25 levels order book snapshots for 2020-09-01[https://datasets.tardis.dev/v1/binance-futures/book_snapshot_25/2020/09/01/BTCUSDT.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/binance-futures/book_snapshot_25/2020/09/01/BTCUSDT.csv.gz)Binance USDT Futures BTCUSDT top 25 levels order book snapshots for 2020-09-01
### • book_snapshot_5
Tick-level order book snapshots reconstructed from exchanges' real-time WebSocket order book L2 data feeds. Each row represents top 5 levels from each side of the limit order book book and was recorded every time any of the tracked bids/asks top 5 levels have changed.

CSV book_snapshot_5 schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

asks[0..4].price

top 5 asks prices in ascending order, empty if there aren't enough price levels available in the order book or provided by the exchange

asks[0..4].amount

top 5 asks amounts in ascending order, empty if there aren't enough price levels available in the order book or provided by the exchange

bids[0..4].price

top 5 bids prices in descending order, empty if there aren't enough price levels available in the order book or provided by the exchange

bids[0..4].amount

top 5 bids amounts in descending order, empty if there aren't enough price levels available in the order book or provided by the exchange

exchange

symbol

timestamp

local_timestamp

asks[0].price

asks[0].amount

bids[0].price

bids[0].amount

asks[1].price

asks[1].amount

bids[1].price

bids[1].amount

asks[2].price

asks[2].amount

bids[2].price

bids[2].amount

asks[3].price

asks[3].amount

bids[3].price

bids[3].amount

asks[4].price

asks[4].amount

bitmex

XBTUSD

1598918402683390

1598918402683390

11658

1399982

11657.5

2293327

11658.5

82328

11657

37555

11659

3001

11656.5

110647

11659.5

10843

11656

10063

11660

2522

bitmex

XBTUSD

1598918403229829

1598918403229829

11658

1399982

11657.5

2293327

11658.5

82328

11657

37555

11659

3001

11656.5

110647

11659.5

10835

11656

10063

11660

2522

bitmex

XBTUSD

1598918403232925

1598918403232925

11658

1399982

11657.5

2295327

11658.5

82328

11657

37555

11659

3001

11656.5

110647

11659.5

10835

11656

10063

11660

2522

bitmex

XBTUSD

1598918403253585

1598918403253585

11658

1399982

11657.5

2295256

11658.5

82328

11657

37555

11659

3001

11656.5

110647

11659.5

10835

11656

10063

11660

2522

bitmex

XBTUSD

1598918403256460

1598918403256460

11658

1399982

11657.5

2294159

11658.5

82328

11657

37555

11659

3001

11656.5

110647

11659.5

10835

11656

10063

11660

2522

bitmex

XBTUSD

1598947264502293

1598947264502293

11950

730542

11949.5

1100309

11950.5

30454

11949

454098

11951

72967

11948.5

2519605

11951.5

48967

11948

97449

11952

55623

bitmex

XBTUSD

1598947264505452

1598947264505452

11950

730542

11949.5

1100309

11950.5

30454

11949

454098

11951

72967

11948.5

2509605

11951.5

48967

11948

97449

11952

55623

bitmex

XBTUSD

1598947264510015

1598947264510015

11950

730542

11949.5

1100975

11950.5

30454

11949

454098

11951

72967

11948.5

2509605

11951.5

48967

11948

97449

11952

55623

bitmex

XBTUSD

1598947264510024

1598947264510024

11950

730542

11949.5

1250975

11950.5

30454

11949

454098

11951

72967

11948.5

2509605

11951.5

48967

11948

97449

11952

55623

[https://datasets.tardis.dev/v1/bitmex/book_snapshot_5/2020/09/01/XBTUSD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/bitmex/book_snapshot_5/2020/09/01/XBTUSD.csv.gz)BitMEX XBTUSD top 5 levels order book snapshots for 2020-09-01[https://datasets.tardis.dev/v1/binance-futures/book_snapshot_5/2020/09/01/BTCUSDT.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/binance-futures/book_snapshot_5/2020/09/01/BTCUSDT.csv.gz)Binance USDT Futures BTCUSDT top 5 levels order book snapshots for 2020-09-01
### • trades
Individual trades data collected from exchanges' real-time WebSocket trades data feeds.

CSV trades schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

id

trade id as provided by exchange, empty if exchange does not provide one - different exchanges provide id's as numeric values, GUID's or other strings, and some do not provide that information at all

side

liquidity taker side (aggressor), possible values:

• buy - liquidity taker was buying
• sell - liquidity taker was selling
• unknown - exchange did not provide that information

price

trade price as provided by exchange

amount

trade amount as provided by exchange

exchange

symbol

timestamp

local_timestamp

id

side

price

amount

bitmex

XBTUSD

1585699202957000

1585699203089980

d20...

buy

6425.5

12

bitmex

XBTUSD

1585699202980000

1585699203095276

619...

sell

6425

150

bitmex

XBTUSD

1585699203002000

1585699203099299

751...

sell

6425

25

bitmex

XBTUSD

1585699203092000

1585699203122233

3c1...

buy

6425.5

1

bitmex

XBTUSD

1585699203092000

1585699203122233

b9b...

buy

6425.5

1

bitmex

XBTUSD

1585699203092000

1585699203122233

433...

buy

6425.5

1

bitmex

XBTUSD

1585699203092000

1585699203122233

d16...

buy

6425.5

1

bitmex

XBTUSD

1585699203092000

1585699203122233

402...

buy

6425.5

1

bitmex

XBTUSD

1585699203092000

1585699203122233

2f8...

buy

6425.5

1

[https://datasets.tardis.dev/v1/bitmex/trades/2020/03/01/XBTUSD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/bitmex/trades/2020/03/01/XBTUSD.csv.gz)Bitmex XBTUSD trades for 2020-03-01 dataset sample[https://datasets.tardis.dev/v1/okex-futures/trades/2020/03/01/FUTURES.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/okex-futures/trades/2020/03/01/FUTURES.csv.gz)OKEx Futures FUTURES instruments trades for 2020-03-01 dataset sample
### • options_chain
Tick-level options summary info (strike prices, expiration dates, open interest, implied volatility, greeks etc.) for all active options instruments collected from exchanges' real-time WebSocket options tickers data feeds. Options chain data is available for Deribit (sourced from ticker channel) and OKEx Options (sourced from option/summary and index/ticker channels).

For options_chain data type only 'OPTIONS' symbol is available (one file per day for all options instruments).

CSV options_chain schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

ticker timestamp provided by exchange in microseconds since epoch

local_timestamp

ticker message arrival timestamp in microseconds since epoch

type

option type, possible values:

• put
• call

strike_price

option strike price

expiration

option expiration date in microseconds since epoch

open_interest

current open interest, empty is exchange does not provide one

last_price

price of the last trade, empty if there weren't any trades yet

bid_price

current best bid price, empty if there aren't any bids

bid_amount

current best bid amount, empty if there aren't any bids

bid_iv

implied volatility for best bid, empty if there aren't any bids

ask_price

current best ask price, empty if there aren't any asks

ask_amount

current best ask amount, empty if there aren't any asks

ask_iv

implied volatility for best ask, empty if there aren't any asks

mark_price

mark price, empty is exchange does not provide one

mark_iv

implied volatility for mark price, empty is exchange does not provide one

underlying_index

underlying index name that option contract is based upon

underlying_price

underlying price, empty is exchange does not provide one

delta

delta value for the option, empty is exchange does not provide one

gamma

gamma value for the option, empty is exchange does not provide one

vega

vega value for the option, empty is exchange does not provide one

theta

theta value for the option, empty is exchange does not provide one

rho

rho value for the option, empty is exchange does not provide one

exchange

symbol

timestamp

local_timestamp

type

strike_price

expiration

open_interest

last_price

bid_price

bid_amount

bid_iv

ask_price

ask_amount

ask_iv

mark_price

mark_iv

underlying_index

underlying_price

delta

gamma

vega

theta

rho

deribit

BTC-9JUN20-9875-P

1591574399413000

1591574400196008

put

9875

1591689600000000

0.1

0.0295

0.0205

15.0

55.91

0.0235

15.0

68.94

0.02210436

62.89

SYN.BTC-9JUN20

9756.36

-0.61752

0.00103

2.24964

-53.05655

-0.22796

deribit

BTC-9JUN20-9875-P

1591574404454000

1591574404473112

put

9875

1591689600000000

0.1

0.0295

0.0205

15.0

55.91

0.0235

15.0

68.94

0.02209480

62.86

SYN.BTC-9JUN20

9756.37

-0.61757

0.00103

2.24954

-53.02754

-0.22798

deribit

BTC-9JUN20-9875-C

1591574397505000

1591574400196010

call

9875

1591689600000000

44.3

0.0080

0.0095

0.5

61.00

0.0105

20.0

65.33

0.00992836

62.87

SYN.BTC-9JUN20

9756.25

0.38232

0.00103

2.24933

-53.03038

0.13272

deribit

BTC-9JUN20-9750-C

1591574399414000

1591574400196011

call

9750

1591689600000000

30.5

0.0145

0.0145

0.3

58.80

0.0160

20.0

65.02

0.01527998

62.05

SYN.BTC-9JUN20

9756.36

0.51442

0.00109

2.35092

-54.69903

0.17789

deribit

BTC-9JUN20-9750-P

1591574397562000

1591574400196012

put

9750

1591689600000000

0.8

0.0185

0.0140

0.3

59.40

0.0155

0.3

65.63

0.01464260

62.06

SYN.BTC-9JUN20

9756.25

-0.48570

0.00109

2.35092

-54.70775

-0.17832

deribit

BTC-9JUN20-9625-P

1591574397824000

1591574400197202

put

9625

1591689600000000

9.5

0.0130

0.0090

0.4

61.64

0.0105

0.4

68.29

0.00975848

65.01

SYN.BTC-9JUN20

9756.25

-0.35780

0.00097

2.20136

-53.66975

-0.13100

deribit

BTC-9JUN20-9625-C

1591574397359000

1591574400197208

call

9625

1591689600000000

18.0

0.0220

0.0215

15.0

57.39

0.0235

20.0

66.31

0.02320750

65.02

SYN.BTC-9JUN20

9756.18

0.64212

0.00097

2.20150

-53.67532

0.22058

deribit

BTC-9JUN20-9500-P

1591574397940000

1591574400197209

put

9500

1591689600000000

51.5

0.0065

0.0060

0.5

66.31

0.0065

17.1

68.91

0.00625625

67.64

SYN.BTC-9JUN20

9756.30

-0.25091

0.00080

1.87744

-47.62196

-0.09165

deribit

BTC-9JUN20-9500-C

1591574399413000

1591574400197211

call

9500

1591689600000000

43.8

0.0165

0.0315

20.0

62.19

0.0350

0.4

80.06

0.03252520

67.64

SYN.BTC-9JUN20

9756.36

0.74914

0.00080

1.87725

-47.61618

0.25540

[https://datasets.tardis.dev/v1/deribit/options_chain/2020/03/01/OPTIONS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/options_chain/2020/03/01/OPTIONS.csv.gz)Deribit options chain for 2020-03-01[https://datasets.tardis.dev/v1/okex-options/options_chain/2020/03/01/OPTIONS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/okex-options/options_chain/2020/03/01/OPTIONS.csv.gz)OKEx options chain for 2020-03-01
### • quotes
Top of the book (best bid/ask) data reconstructed from exchanges' real-time WebSocket order book L2 data feeds. - best  bid/ask recorded every time top of the book has changed.

We on purpose choose this solution over native exchanges real-time quotes feeds as those vary a lot between exchanges, can be throttled, some are absent at all, often are delayed and published in batches in comparison to more granular L2 updates which are the basis for our quotes dataset.

CSV quotes schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

ask_amount

best ask amount as provided by exchange, empty if there aren't any asks

ask_price

best ask price as provided by exchange, empty if there aren't any asks

bid_price

best bid price as provided by exchange, empty if there aren't any bids

bid_amount

best bid amount as provided by exchange, empty if there aren't any bids

exchange

symbol

timestamp

local_timestamp

ask_amount

ask_price

bid_price

bid_amount

huobi-dm-swap

BTC-USD

1585699201147000

1585699201270777

86

6423

6422.9

112

huobi-dm-swap

BTC-USD

1585699201175000

1585699201292111

86

6423

6422.9

114

huobi-dm-swap

BTC-USD

1585699201257000

1585699201373479

84

6423

6422.9

219

huobi-dm-swap

BTC-USD

1585699201279000

1585699201495667

64

6423

6422.9

219

huobi-dm-swap

BTC-USD

1585699201295000

1585699201495715

64

6423

6422.9

229

huobi-dm-swap

BTC-USD

1585699201447000

1585699201564788

2

6423

6422.9

229

huobi-dm-swap

BTC-USD

1585699201556000

1585699201677770

64

6423

6422.9

229

huobi-dm-swap

BTC-USD

1585699201668000

1585699201784213

64

6423

6422.9

235

huobi-dm-swap

BTC-USD

1585699201747000

1585699201865051

2

6423

6422.9

235

[https://datasets.tardis.dev/v1/huobi-dm-swap/quotes/2020/05/01/BTC-USD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/huobi-dm-swap/quotes/2020/05/01/BTC-USD.csv.gz)Huobi DM Swap BTC-USD quotes for 2020-05-01[https://datasets.tardis.dev/v1/options/quotes/2020/05/01/OPTIONS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/options/quotes/2020/05/01/OPTIONS.csv.gz)Deribit OPTIONS instruments quotes for 2020-05-01book_ticker

### • derivative_ticker
Derivative instrument ticker info (open interest, funding, mark price, index price) collected from exchanges' real-time WebSocket instruments & tickers data feeds. 

Anytime  any of the tracked values has changed data was added to final dataset.

CSV derivative_ticker schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

funding_timestamp

timestamp of the next funding event in microseconds since epoch, empty if exchange does not provide one

funding_rate

funding rate that will take effect on the next funding event at funding timestamp, for some exchanges it's fixed, for other it fluctuates, empty if exchange does not provide one

predicted_funding_rate

estimated predicted funding rate for the next after closest funding event, empty if exchange does not provide one

open_interest

current open interest, empty if exchange does not provide one

last_price

last instrument price, empty if exchange does not provide one

index_price

index price of the instrument, empty if exchange does not provide one

mark_price

mark price of the instrument, empty if exchange does not provide one

1

exchange

symbol

timestamp

local_timestamp

funding_timestamp

funding_rate

predicted_funding_rate

open_interest

last_price

index_price

mark_price

2

bitmex

ETHUSD

1585699199651000

1585699202577291

1585713600000000

0.0001

0.001654

45921455

133.25

133.14

133.15

3

bitmex

ETHUSD

1585699200000000

1585699204834359

1585713600000000

0.0001

0.001654

45921455

133.25

133.12

133.13

4

bitmex

ETHUSD

1585699202925000

1585699205076090

1585713600000000

0.0001

0.001654

45921455

133.3

133.12

133.13

5

bitmex

ETHUSD

1585699202925000

1585699205090339

1585713600000000

0.0001

0.001654

45883853

133.3

133.12

133.13

6

bitmex

ETHUSD

1585699203465000

1585699205274555

1585713600000000

0.0001

0.001654

45883853

133.25

133.12

133.13

7

bitmex

ETHUSD

1585699204439000

1585699205951209

1585713600000000

0.0001

0.001654

45883853

133.15

133.12

133.13

8

bitmex

ETHUSD

1585699205000000

1585699206389317

1585713600000000

0.0001

0.001654

45883853

133.15

133.09

133.1

9

bitmex

ETHUSD

1585699207279000

1585699207490211

1585713600000000

0.0001

0.001654

45883853

133.2

133.09

133.1

10

bitmex

ETHUSD

1585699207279000

1585699208084951

1585713600000000

0.0001

0.001654

45867677

133.2

133.09

133.1

[https://datasets.tardis.dev/v1/bitmex/derivative_ticker/2019/04/01/ETHUSD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/bitmex/derivative_ticker/2019/04/01/ETHUSD.csv.gz)BitMEX ETHUSD derivative ticker for 2019-04-01[https://datasets.tardis.dev/v1/ftx/derivative_ticker/2019/04/01/PERPETUALS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/ftx/derivative_ticker/2019/04/01/PERPETUALS.csv.gz)FTX PERPETUALS instruments derivative ticker for 2019-04-01
### • liquidations
Liquidations data collected from exchanges' real-time WebSocket data feeds were available.

See details which exchanges support it and since when.

CSV liquidations schemadataset previewcolumn name

description

exchange

exchange id, one of https://api.tardis.dev/v1/exchanges ([].id field)

symbol

instrument symbol as provided by exchange (always uppercase)

timestamp

timestamp provided by exchange in microseconds since epoch - if exchange does not provide one local_timestamp value is used as a fallback

local_timestamp

message arrival timestamp in microseconds since epoch

id

liquidation id as provided by exchange, empty if exchange does not provide one - different exchanges provide id's as numeric values, GUID's or other strings, and some do not provide that information at all

side

liquidation side:

• buy - short position was liquidated
• sell - long position was liquidated

price

liquidation price as provided by exchange

amount

liquidation amount as provided by exchange

exchange

symbol

timestamp

local_timestamp

id

side

price

amount

binance-futures

BTCUSDT

1632009737493000

1632009737505152

sell

48283.81

0.01

binance-futures

BTCUSDT

1632009802385000

1632009802398690

buy

48339.11

0.132

binance-futures

BTCUSDT

1632009870475000

1632009870485139

buy

48337.02

0.004

binance-futures

BTCUSDT

1632009889760000

1632009889784144

buy

48346.54

0.002

binance-futures

BTCUSDT

1632009891282000

1632009891296156

buy

48350.34

0.032

binance-futures

BTCUSDT

1632009892636000

1632009892646433

buy

48355.68

0.001

binance-futures

BTCUSDT

1632009970533000

1632009970544039

buy

48290.57

0.042

binance-futures

BTCUSDT

1632010836285000

1632010836297995

sell

48186.15

0.036

binance-futures

BTCUSDT

1632010899415000

1632010899428203

sell

48150.64

0.265

[https://datasets.tardis.dev/v1/ftx/liquidations/2021/09/01/PERPETUALS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/ftx/liquidations/2021/09/01/PERPETUALS.csv.gz)FTX perpetual futures liquidations for 2021-09-01[https://datasets.tardis.dev/v1/bitmex/liquidations/2021/09/01/XBTUSD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/bitmex/liquidations/2021/09/01/XBTUSD.csv.gz)BitMEX XBTUSD liquidations for 2021-09-91
## Grouped symbols
In addition to standard currency pairs & instrument symbols that can be requested when via CSV datasets API, each exchange has additional special grouped symbols available depending if it supports given market type: SPOT, FUTURES, OPTIONS and PERPETUALS. When such symbol is requested then downloaded file for it has all the data for all instruments belonging for given market type. 
This is especially useful for options instruments that as specifying each option symbol one by one can be mundane process, using 'OPTIONS' as a symbol gives data for all options available at given time.

See what is the difference between futures and perpetual swaps contracts.

• incremental_book_L2 - available for FUTURESExamples:https://datasets.tardis.dev/v1/ftx/incremental_book_L2/2020/09/01/FUTURES.csv.gz
• trades  - available for SPOT, FUTURES, OPTIONS, PERPETUALSExamples:https://datasets.tardis.dev/v1/binance/trades/2020/09/01/SPOT.csv.gzhttps://datasets.tardis.dev/v1/deribit/trades/2020/09/01/FUTURES.csv.gzhttps://datasets.tardis.dev/v1/okex-options/trades/2020/09/01/OPTIONS.csv.gzhttps://datasets.tardis.dev/v1/ftx/trades/2020/09/01/PERPETUALS.csv.gz
• derivative_ticker - available for FUTURES, PERPETUALSExamples:https://datasets.tardis.dev/v1/ftx/derivative_ticker/2020/09/01/FUTURES.csv.gzhttps://datasets.tardis.dev/v1/bitmex/derivative_ticker/2020/09/01/PERPETUALS.csv.gz
• options_chain - available for OPTIONSExamples:https://datasets.tardis.dev/v1/deribit/options_chain/2020/09/01/OPTIONS.csv.gzhttps://datasets.tardis.dev/v1/okex-options/options_chain/2020/09/01/OPTIONS.csv.gz
• quotes - available for OPTIONSExamples:https://datasets.tardis.dev/v1/deribit/quotes/2020/09/01/OPTIONS.csv.gzhttps://datasets.tardis.dev/v1/okex-options/quotes/2020/09/01/OPTIONS.csv.gz
• liquidations - available for FUTURES, PERPETUALS, OPTIONSExamples:https://datasets.tardis.dev/v1/deribit/liquidations/2021/09/01/PERPETUALS.csv.gzhttps://datasets.tardis.dev/v1/ftx/liquidations/2021/09/01/FUTURES.csv.gzhttps://datasets.tardis.dev/v1/deribit/liquidations/2021/09/01/OPTIONS.csv.gz

those special symbols are also listed in response to /exchanges/:exchange API call

## Datasets API details

• all downloadable datasets are gzip compressed
• historical market data is available in daily intervals (separate file for each day) based on local timestamp (timestamp of message arrival) split by exchange, data type and symbol
• data for a given day is available on the next day around 6h after 00:00 UTC - exact date until when data is available can be requested via /exchanges/:exchange API call (datasets.exportedUntil), e.g., https://api.tardis.dev/v1/exchanges/ftx
• datasets are ordered and split into separate daily files by local_timestamp (timestamp of message arrival time)
• empty gzip compressed file is being returned in case of no data available for a given day, symbol and data type, e.g., exchange downtime, very low volume currency pairs etc.
• iftimestamp equals to local_timestamp it means that exchange didn't provide timestamp for message, e.g., BitMEX order book updates
• cell in CSV file is empty if there's no value for it, e.g., no trade id if a given exchange doesn't provide one
• datasets are sourced from Tardis.dev HTTP API, which in turn provides the the data sourced from exchanges real-time WebSocket market data feeds (in contrast to REST API endpoints)
• See "Data FAQ" regarding potential order book overlaps issues, non monotonically increasing exchanges timestamps, duplicated trade data and more

## Download via client libraries
Historical datasets for the first day of each month are available to download without API key.

PythonNode.js$Copy
```
# pip install tardis-dev
# requires Python >=3.6
from tardis_dev import datasets, get_exchange_details
import logging

# comment out to disable debug logs
logging.basicConfig(level=logging.DEBUG)

# function used by default if not provided via options
def default_file_name(exchange, data_type, date, symbol, format):
    return f"{exchange}_{data_type}_{date.strftime('%Y-%m-%d')}_{symbol}.{format}.gz"

# customized get filename function - saves data in nested directory structure
def file_name_nested(exchange, data_type, date, symbol, format):
    return f"{exchange}/{data_type}/{date.strftime('%Y-%m-%d')}_{symbol}.{format}.gz"

# returns data available at https://api.tardis.dev/v1/exchanges/deribit
deribit_details = get_exchange_details("deribit")
# print(deribit_details)

datasets.download(
    # one of https://api.tardis.dev/v1/exchanges with supportsDatasets:true - use 'id' value
    exchange="deribit",
    # accepted data types - 'datasets.symbols[].dataTypes' field in https://api.tardis.dev/v1/exchanges/deribit,
    # or get those values from 'deribit_details["datasets"]["symbols][]["dataTypes"] dict above
    data_types=["incremental_book_L2", "trades", "quotes", "derivative_ticker", "book_snapshot_25", "book_snapshot_5", "liquidations"],
    # change date ranges as needed to fetch full month or year for example
    from_date="2019-11-01",
    # to date is non inclusive
    to_date="2019-11-02",
    # accepted values: 'datasets.symbols[].id' field in https://api.tardis.dev/v1/exchanges/deribit
    symbols=["BTC-PERPETUAL", "ETH-PERPETUAL",],
    # (optional) your API key to get access to non sample data as well
    api_key="YOUR API KEY",
    # (optional) path where data will be downloaded into, default dir is './datasets'
    # download_dir="./datasets",
    # (optional) - one can customize downloaded file name/path (flat dir strucure, or nested etc) - by default function 'default_file_name' is used
    # get_filename=default_file_name,
    # (optional) file_name_nested will download data to nested directory structure (split by exchange and data type)
    # get_filename=file_name_nested,
)
```

/$If you're running into RuntimeError: This event loop is already running  error try solution from https://github.com/ipython/ipython/issues/11338#issuecomment-646539516 (adding nest_asyncio).

Copy
```
// npm install tardis-dev@10.0.20
// requires node version >=12

// remove it to disable debug logs
process.env.DEBUG = 'tardis-dev*'

const { downloadDatasets, getExchangeDetails } = require('tardis-dev')

;(async () => {
  // returns data available at https://api.tardis.dev/v1/exchanges/deribit
  const deribitDetails = await getExchangeDetails('deribit')

  // console.log(deribitDetails.datasets)

  await downloadDatasets({
    exchange: 'deribit', // one of https://api.tardis.dev/v1/exchanges with supportsDatasets:true - use 'id' value
    dataTypes: ['incremental_book_L2', 'trades', 'quotes', 'derivative_ticker', 'book_snapshot_25', 'book_snapshot_5', 'liquidations'], // accepted data types - 'datasets.symbols[].dataTypes' field in https://api.tardis.dev/v1/exchanges/deribit, or get those values from 'deribitDetails.datasets.symbols[].dataTypes' object above
    from: '2019-11-01', // change date ranges as needed to fetch full month or year for example
    to: '2019-11-02', // to date is non inclusive
    symbols: ['BTC-PERPETUAL', 'ETH-PERPETUAL'], // accepted values: 'datasets.symbols[].id' field in https://api.tardis.dev/v1/exchanges/deribit, or `deribitDetails.datasets.symbols[].id` from object above

    apiKey: 'YOUR_API_KEY', // (optional) your API key to get access to non sample data as well
    // downloadDir:'./datasets', // (optional) path where data will be downloaded into, default dir is './datasets'

    // getFilename: getFilenameDefault, // (optional) - one can customize downloaded file name/path (flat dir strucure, or nested etc) - by default function 'getFilenameDefault' is used
    // getFilename: getFilenameCustom // (optional) getFilenameCustom will download data to nested directory structure (split by exchange and data type)
  })
})().catch((e) => {
  console.log('download error', e)
})

// function used by default if not provided via options
function getFilenameDefault({ exchange, dataType, format, date, symbol }) {
  return `${exchange}_${dataType}_${date.toISOString().split('T')[0]}_${symbol}.${format}.gz`
}

// customized get filename function - saves data in nested directory structure
function getFilenameCustom({ exchange, dataType, format, date, symbol }) {
  return `${exchange}/${dataType}/${date.toISOString().split('T')[0]}_${symbol}.${format}.gz`
}
```

## Datasets API reference
GET https://datasets.tardis.dev/v1/:exchange/:dataType/:year/:month/:day/:symbol.csv.gz

Returns gzip compressed CSV dataset for given exchange, data type, date (year, month, day) and symbol.

#### Path Parameters
NameTypeDescriptionexchange

string

one of https://api.tardis.dev/v1/exchanges (field id, only exchanges with "supportsDatasets":true)

dataType

string

one of datasets.symbols[].dataTypes values from https://api.tardis.dev/v1/exchanges/:exchange API response

year

string

year in format YYYY (four-digit year)

month

string

month in format MM (two-digit month of the year)

day

string

day in format DD (two-digit day of the month)

symbol

string

one of datasets.symbols[].id values from https://api.tardis.dev/v1/exchanges/:exchange API response, see details below

#### Headers
NameTypeDescriptionAuthorization

string

For authenticated requests provide Authorization header with value: 'Bearer YOUR_API_KEY'.
Without API key historical datasets for the first day of each month are available to download.

200 gzip compressed CSV dataset$Copy
```

```

/$
• symbols param provided to datasets API in comparison to HTTP API needs to be both always uppercase and  have '/' and ':' characters replaced with '-' so symbol is url safe.
• list of allowed symbols for each exchange can be requested via /exchanges/:exchange API call, e.g., https://api.tardis.dev/v1/exchanges/deribit - datasets.symbols[].id field

#### Sample requests
[https://datasets.tardis.dev/v1/deribit/trades/2019/11/01/BTC-PERPETUAL.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/trades/2019/11/01/BTC-PERPETUAL.csv.gz)[https://datasets.tardis.dev/v1/deribit/trades/2019/11/01/OPTIONS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/trades/2019/11/01/OPTIONS.csv.gz)[https://datasets.tardis.dev/v1/bitmex/incremental_book_L2/2020/04/01/XBTUSD.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/bitmex/incremental_book_L2/2020/04/01/XBTUSD.csv.gz)[https://datasets.tardis.dev/v1/deribit/options_chain/2019/08/01/OPTIONS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/options_chain/2019/08/01/OPTIONS.csv.gz)[https://datasets.tardis.dev/v1/deribit/book_snapshot_25/2020/08/01/BTC-PERPETUAL.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/book_snapshot_25/2020/08/01/BTC-PERPETUAL.csv.gz)[https://datasets.tardis.dev/v1/deribit/quotes/2019/08/01/OPTIONS.csv.gzdatasets.tardis.dev](https://datasets.tardis.dev/v1/deribit/quotes/2019/08/01/OPTIONS.csv.gz)/$[PreviousBilling and Subscriptions](/faq/billing-and-subscriptions)[NextHistorical Data Details](/historical-data-details)Last updated 1 year ago

================================================================================

# Historical Data Details

Source: https://docs.tardis.dev/historical-data-details
Extraction Method: playwright

Copy
# Historical Data Details
Historical market data details for each supported exchange — available symbols, channels, date ranges...

$Historical data details describes data collection specifics for each supported exchange and what's available via Tardis.dev HTTP API. If you'd like to work with normalized market data see official libraries and downloadable CSV files.

You'll find here per-exchange details about:

• historical data availability date ranges — since when the historical data has been collected and is available
• captured real-time market data channels also described as streams, subscription topics, tables etc in exchanges' docs — available historical raw market data is being sourced from WebSocket real-time APIs provided by the exchanges and can be filtered by channels, e.g.: to get historical trades for BitMEX, channel trade needs to be provided alongside requested instruments symbols (via HTTP API or client libs function args).
• symbols of recorded instruments/currency pairs
• incidents - describing periods where due to internal errors data has been missing for given exchange

Some exchanges encode requested symbol in channel name, e.g.: Deribit trades.BTC-PERPETUAL.100ms channel. This is not the case with our API as we always consider channel name and symbol to be separate inputs. In case of Deribit example channel name would be trades and symbol BTC-PERPETUAL. If channel provides option of frequency of updates (e.g.: 100ms vs raw tick by tick) always higher frequency one is being chosen and recorded.

What is the channel field used in the HTTP API and client libs replay functions?

## Market data collection overview

• All market data collection is being performed on one of the highly available Google Cloud Platform Kubernetes Clusters - London, UK (europe-west2 region) or Tokyo, Japan (asia-northeast1 region) - information which data center location is used for particular exchange is described on exchange historical data details page.
• When exchange provides choice of real-time data frequency for specific data types (e.g. order book data ) always most granular, non aggregated data feed is being collected.
• Choice if single or multiple WebSocket connections are being used to record full real-time data feed is made on case by case basis - we take into account exchange API limits and latency which may be higher or lower if single connection is being used - detailed information which strategy is used for particular exchange is described on exchange historical data details page.
• WebSocket connection is dynamically re-subscribed (or restarted for some exchanges) at 00:00 UTC every day in order to receive initial order book snapshots.
• Each received message is timestamped with 100ns precision using synchronized clock at arrival time and stored in ISO 8601 format.
• Messages provided by exchanges' WebSocket feeds are being stored without any modifications.
• Checks if there are new instruments available for given exchange are being performed every minute.
• Market data collection services are being constantly monitored both manually and via automated tools (monitoring, alert notifications) and have built-in self-healing capabilities. We also constantly monitor for upcoming exchanges' API changes and adapt to those beforehand.
• There are multiple built-in checks detecting if connection to exchange is healthy during data collection process, such as:validating subscription responses - if exchange does not confirm subscriptions within 20 seconds, connection is being restartedHeartbeat pingsorder books sequence numbers validation for exchange that provide thosevalidating JSON format as in some unusual circumstances exchanges return data that is invalid JSONstale connection detection - if there are no responses received within certain period (adjusted per exchange) it's most likely stale connection which gets automatically restarteddetection of unusually small messages count being received from exchange in given time period which likely means connection is not healthy, e.g.: receiving only 'pings' without data messagesand many more
• Any incident that is caused by us (bugs, network errors etc.) is being logged and available via API.
• New market data delay is 6 minutes in relation to real-time (T - 6min).

## Collected order book data details
Historical market data available via HTTP API provides order book snapshots at the beginning of each day (00:00 UTC) and every-time WebSocket connection has been closed when recording real-time data feed (connection is restarted and new snapshot provided via fresh connection). It means that  in order to be sure to receive initial order book snapshots one must replay historical data from 00:00 UTC time of the day. It also means that there is a tiny gap in historical data (around 300-3000ms range depending on exchange) during re-subscribing to real-time WebSocket feed (every 24 hours) in order to receive order book snapshots.

Some exchanges do not provide initial order book snapshots when subscribing to WebSocket real-time feeds (like Binance, Bitstamp or Coinbase Pro full order book), hence for those there is a 'generated' snapshot available instead (based on REST API call) - details are specific for each exchange and are described in per-exchange historical details pages.

## Per-exchange historical data details
Click any exchange below to see it's historical data details - available instruments, captured real-time channels, API access details and market data collection specifics.

• BitMEX
• Deribit
• Binance USDT Futures
• Binance COIN Futures
• Binance
• FTX
• OKX Futures
• OKX Swap
• OKX Options
• OKX Spot
• Huobi Futures
• Huobi COIN Swaps
• Huobi USDT Swaps
• Huobi Global
• Bitfinex Derivatives
• Bitfinex
• Coinbase Pro
• Kraken Futures (Crypto Facilities)
• Kraken
• Bitstamp
• Gemini
• Poloniex
• Bybit
• Bybit Spot
• dYdX
• WOO X
• Kucoin Spot
• Blockchain.com
• Upbit
• Phemex
• Delta
• Ascendex (BitMax)
• FTX US
• Binance US
• Gate.io Futures
• Gate.io
• Bitnomial
• Crypto.com
• OKCoin
• bitFlyer
• HitBTC (high caps)
• CoinFLEX
• Binance Jersey
• Binance DEX

/$[PreviousDownloadable CSV files](/downloadable-csv-files)[NextBitMEX](/historical-data-details/bitmex)Last updated 1 year ago

================================================================================

# BitMEX

Source: https://docs.tardis.dev/historical-data-details/bitmex
Extraction Method: playwright
Components: code_block(7)

Copy
1. Historical Data Details

# BitMEX
BitMEX historical market data details - available data, coverage and data collection specifics

$BitMEX historical data for all it's instruments is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/bitmexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bitmex)See BitMEX historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

XBTUSD

2019-07-01

Download sample

incremental_book_L2

XBTUSD

2019-07-01

Download sample

book_snapshot_25

XBTUSD

2019-07-01

Download sample

quotes

XBTUSD

2019-07-01

Download sample

derivative_ticker

XBTUSD

2019-07-01

Download sample

trades

FUTURES

2020-03-01

Download sample

incremental_book_L2

FUTURES

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

book_ticker

XBTUSD

2022-01-01

Download sample

#### How to download all Bitmex datasets for all instruments
See full downloadable CSV files documentation with datasets format spec, data samples and more.

PythonNode.jscURL$Copy
```
# requires Python >=3.6
# pip install tardis-dev

from tardis_dev import datasets, get_exchange_details
import logging

# optionally enable debug logs
# logging.basicConfig(level=logging.DEBUG)

exchange = 'bitmex'
exchange_details = get_exchange_details(exchange)   

# iterate over and download all data for every symbol
for symbol in exchange_details["datasets"]["symbols"]:
    # alternatively specify datatypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    # see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    data_types = symbol["dataTypes"]  
    symbol_id = symbol["id"]
    from_date =  symbol["availableSince"]
    to_date = symbol["availableTo"]

    # skip groupped symbols
    if symbol_id in ['PERPETUALS', 'SPOT', 'FUTURES']:
        continue

    print(f"Downloading {exchange} {data_types} for {symbol_id} from {from_date} to {to_date}")

    # each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    # see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    datasets.download(
        exchange = exchange,
        data_types = data_types,
        from_date =  from_date,
        to_date = to_date,
        symbols = [symbol_id],
        # TODO set your API key here
        api_key = "YOUR_API_KEY",
        # path where CSV data will be downloaded into
        download_dir = "./datasets",
    )
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
// npm install tardis-dev
// requires node version >=12
const { downloadDatasets, getExchangeDetails } = require('tardis-dev')

;(async () => {
  const exchange = 'bitmex'
  const exchangeDetails = await getExchangeDetails(exchange)

  // iterate over and download all data for every symbol
  for (const symbol of exchangeDetails.datasets.symbols) {
    // alternatively specify dataTypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    // see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    const dataTypes = symbol.dataTypes
    const symbolId = symbol.id

    const from = symbol.availableSince
    const to = symbol.availableTo

    // skip groupped symbols
    if (['PERPETUALS', 'SPOT', 'FUTURES'].includes(symbolId)) {
      continue
    }

    console.log(`Downloading ${exchange} ${dataTypes} for ${symbolId} from ${from} to ${to}`)

    // each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    // see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    await downloadDatasets({
      exchange,
      dataTypes,
      from,
      to,
      symbols: [symbolId],
      // TODO: set your API key here
      apiKey: 'YOUR_API_KEY',
      //  path where CSV data will be downloaded into
      downloadDir: './datasets'
    })
  }
})()
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
curl -o bitmex_trades_2019-11-01_XBTUSD.csv.gz https://datasets.tardis.dev/v1/bitmex/trades/2019/11/01/XBTUSD.csv.gz
```

/$See datasets API reference which allows downloading single file at once.

### API Access and data format
Historical data format is the same as provided by real-time BitMEX WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bitmex",
    from_date="2019-07-01",
    to_date="2019-07-02",
    filters=[Channel(name="orderBookL2", symbols=["XBTUSD"])]
  )

  # messages as provided by BitMEX real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bitmex',
      from: '2019-07-01',
      to: '2019-07-02',
      filters: [{ channel: 'orderBookL2', symbols: ['XBTUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by BitMEX real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bitmex?from=2019-07-01&filters=[{"channel":"orderBookL2","symbols":["ETHUSD"]}]&offset=2'
```

/$[https://api.tardis.dev/v1/data-feeds/bitmex?from=2019-07-01&filters=[{%22channel%22:%22orderBookL2%22,%22symbols%22:[%22ETHUSD%22]}]&offset=2api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bitmex?from=2019-07-01&filters=[{%22channel%22:%22orderBookL2%22,%22symbols%22:[%22ETHUSD%22]}]&offset=2)Example API response for BitMEX historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bitmex","filters":[{"channel":"orderBookL2","symbols":["XBTUSD"]}],"from":"2019-07-01","to":"2019-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[BitMEX | Bitcoin Mercantile ExchangeBitMEX](https://www.bitmex.com/app/wsAPI)See BitMEX WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• orderBookL2
• liquidation
• connected
• announcement
• chat
• publicNotifications
• instrument
partial messages returned via HTTP API may contain data for all BitMEX instruments and require filtering client-side if only selected symbols were requested
• settlement
• funding
• insurance
• orderBookL2_25
• quote
• quoteBin1m
• quoteBin5m
• quoteBin1h
• quoteBin1d
• tradeBin1m
• tradeBin5m
• tradeBin1h
• tradeBin1d
• orderBook10 - available since 2021-02-21

### Market data collection details
Market data collection infrastructure for BitMEX is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via single WebSocket connection.

BitMEX servers are located in AWS eu-west-1 region (Dublin, Ireland).

/$[PreviousHistorical Data Details](/historical-data-details)[NextDeribit](/historical-data-details/deribit)Last updated 3 years ago

================================================================================

# Deribit

Source: https://docs.tardis.dev/historical-data-details/deribit
Extraction Method: playwright
Components: code_block(7)

Copy
1. Historical Data Details

# Deribit
Deribit historical market data details - available data, coverage and data collection specifics

$Deribit historical data for all it's instruments (including all options) is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/deribitapi.tardis.dev](https://api.tardis.dev/v1/exchanges/deribit)See Deribit historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-PERPETUAL

2019-07-01

Download sample

incremental_book_L2

BTC-PERPETUAL

2019-07-01

Download sample

quotes

BTC-PERPETUAL

2019-07-01

Download sample

book_snapshot_25

BTC-PERPETUAL

2019-07-01

Download sample

derivative_ticker

BTC-PERPETUAL

2019-07-01

Download sample

trades

OPTIONS

2020-03-01

Download sample

quotes

OPTIONS

2020-03-01

Download sample

options_chain

OPTIONS

2020-03-01

Download sample

book_snapshot_25

OPTIONS

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

#### How to download all Deribit datasets for all instruments
See full downloadable CSV files documentation with datasets format spec, data samples and more.

PythonNode.jscURL$Copy
```
# requires Python >=3.6
# pip install tardis-dev

from tardis_dev import datasets, get_exchange_details
import logging

# optionally enable debug logs
# logging.basicConfig(level=logging.DEBUG)

exchange = 'deribit'
exchange_details = get_exchange_details(exchange)   

# iterate over and download all data for every symbol
for symbol in exchange_details["datasets"]["symbols"]:
    # alternatively specify datatypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    # see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    data_types = symbol["dataTypes"]  
    symbol_id = symbol["id"]
    from_date =  symbol["availableSince"]
    to_date = symbol["availableTo"]

    # skip groupped symbols
    if symbol_id in ['PERPETUALS', 'SPOT', 'FUTURES']:
        continue

    print(f"Downloading {exchange} {data_types} for {symbol_id} from {from_date} to {to_date}")

    # each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    # see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    datasets.download(
        exchange = exchange,
        data_types = data_types,
        from_date =  from_date,
        to_date = to_date,
        symbols = [symbol_id],
        # TODO set your API key here
        api_key = "YOUR_API_KEY",
        # path where CSV data will be downloaded into
        download_dir = "./datasets",
    )
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
// npm install tardis-dev
// requires node version >=12
const { downloadDatasets, getExchangeDetails } = require('tardis-dev')

;(async () => {
  const exchange = 'deribit'
  const exchangeDetails = await getExchangeDetails(exchange)

  // iterate over and download all data for every symbol
  for (const symbol of exchangeDetails.datasets.symbols) {
    // alternatively specify dataTypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    // see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    const dataTypes = symbol.dataTypes
    const symbolId = symbol.id

    const from = symbol.availableSince
    const to = symbol.availableTo

    // skip groupped symbols
    if (['PERPETUALS', 'SPOT', 'FUTURES'].includes(symbolId)) {
      continue
    }

    console.log(`Downloading ${exchange} ${dataTypes} for ${symbolId} from ${from} to ${to}`)

    // each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    // see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    await downloadDatasets({
      exchange,
      dataTypes,
      from,
      to,
      symbols: [symbolId],
      // TODO: set your API key here
      apiKey: 'YOUR_API_KEY',
      //  path where CSV data will be downloaded into
      downloadDir: './datasets'
    })
  }
})()
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
curl -o deribit_trades_2019-11-01_BTC-PERPETUAL.csv.gz https://datasets.tardis.dev/v1/deribit/trades/2019/11/01/BTC-PERPETUAL.csv.gz
```

/$See datasets API reference which allows downloading single file at once.

### API Access and data format
Historical data format is the same as provided by real-time Deribit WebSocket v2 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="deribit",
    from_date="2019-07-01",
    to_date="2019-07-02",
    filters=[Channel(name="book", symbols=["BTC-PERPETUAL"])]
  )

  # messages as provided by Deribit real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'deribit',
      from: '2019-07-01',
      to: '2019-07-02',
      filters: [{ channel: 'book', symbols: ['BTC-PERPETUAL'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Deribit real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/deribit?from=2019-07-01&filters=[{"channel":"book","symbols":["BTC-PERPETUAL"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/deribit?from=2019-07-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTC-PERPETUAL%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/deribit?from=2019-07-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTC-PERPETUAL%22]}]&offset=0)Example API response for Deribit historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"deribit","filters":[{"channel":"book","symbols":["BTC-PERPETUAL"]}],"from":"2019-07-01","to":"2019-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Deribit APIdocs.deribit.com](https://docs.deribit.com/v2/#subscriptions)See Deribit WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• book
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by Deribit's real-time feed (prev_change_id) - in case of detecting missed message WebSocket connection is being restarted.
• trades
• deribit_price_index
• deribit_price_ranking
• estimated_expiration_price
• markprice.options
• perpetual
• ticker
• quote
• platform_state - available since 2019-12-31
• deribit_volatility_index - available since 2021-04-01

book, perpetual, ticker, trades channels data was all collected with raw interval - no aggregation was applied.

### Market data collection details
Market data collection infrastructure for Deribit is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Deribit servers are located in Equinix LD4 (Slough, UK).

/$[PreviousBitMEX](/historical-data-details/bitmex)[NextBinance USDT Futures](/historical-data-details/binance-futures)Last updated 3 years ago

================================================================================

# Binance USDT Futures

Source: https://docs.tardis.dev/historical-data-details/binance-futures
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Binance USDT Futures
Binance USDT Margined Futures historical market data details - instruments, data coverage and data collection specifics

$Binance USDT Futures historical data for all it's instruments is available since 2019-11-17.

[https://api.tardis.dev/v1/exchanges/binance-futuresapi.tardis.dev](https://api.tardis.dev/v1/exchanges/binance-futures)See Binance USDT Futures historical data coverage: available symbols, channels, date ranges and incidentsData collection before 2020-05-14 suffered some issues (missing data, latency spikes) during market volatility periods. It has been circumvent by switching to Tokyo DC and using multiple WS connections for real-time market data collection.

### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

derivative_ticker open interest data is available since 2020-05-13 - date since we've started collecting that info via Binance USDT Futures REST API (open interest channel).

data type

symbol

date

trades

BTCUSDT

2020-02-01

Download sample

incremental_book_L2

BTCUSDT

2020-02-01

Download sample

quotes

BTCUSDT

2020-02-01

Download sample

book_snapshot_25

BTCUSDT

2020-09-01

Download sample

derivative_ticker

BTCUSDT

2020-02-01

Download sample

trades

PERPETUALS

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Binance USDT Futures WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="binance-futures",
    from_date="2020-02-01",
    to_date="2020-02-02",
    filters=[Channel(name="depth", symbols=["btcusdt"])]
  )

  # messages as provided by Binance USDT Futures real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'binance-futures',
      from: '2020-02-01',
      to: '2020-02-02',
      filters: [{ channel: 'depth', symbols: ['btcusdt'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Binance USDT Futures real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/binance-futures?from=2020-02-01&filters=[{"channel":"depth","symbols":["btcusdt"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/binance-futures?from=2020-02-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusdt%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/binance-futures?from=2020-02-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusdt%22]}]&offset=0)Example API response for Binance USDT Futures historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"binance-futures","filters":[{"channel":"depth","symbols":["btcusdt"]}],"from":"2020-02-01","to":"2020-02-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Change Log | Binance Open Platformbinance-docs.github.io](https://binance-docs.github.io/apidocs/futures/en/#websocket-market-streams)See Binance USDT Futures WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• aggTrade
• ticker
• bookTicker
• forceOrder - available since 2019-12-05
• markPrice
 Recorded with @1s speed since 2020-02-13 (new API feature).
• depthBinance USDT Futures depth channel has been recorded with the fastest update speed API allowed at the time. It means until 2020-01-07 it was depth@100ms - book updates pushed every 100ms  and after that date it was depth@0ms - book updates pushed real-time (new API feature).
• depthSnapshot - generated channel with full order book snapshots
Binance USDT Futures real-time WebSocket API does not provide initial order book snapshots. To overcome this issue we fetch initial order book snapshots from REST API and store them together with the rest of the WebSocket messages - top 1000 levels. Such snapshot messages are marked with "stream":"<symbol>@depthSnapshot" and "generated":true  fields. 
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by real-time feed (pu and u fields) - in case of detecting missed message WebSocket connection is being restarted. We also validate if initial book snapshot fetched from REST API overlaps with received depth messages.
• openInterest - generated channel, available since 2020-05-14Since Binance USDT Futures does not offer currently real-time WebSocket open interest channel, we simulate it by fetching that info from REST API (https://binance-docs.github.io/apidocs/futures/en/#open-interest) every 30 seconds for each instrument. Such messages are marked with "stream":"<symbol>@openInterest" and "generated":true  fields and data field has the same format as REST API response.
• compositeIndex - available since 2020-10-13
• topLongShortAccountRatio - generated channel, available since 2020-12-18Top trader long/short ratio (accounts), sourced by querying https://binance-docs.github.io/apidocs/futures/en/#top-trader-long-short-ratio-accounts every minute
• topLongShortPositionRatio - generated channel, available since 2020-12-18Top trader long/short ratio (positions), sourced by querying https://binance-docs.github.io/apidocs/futures/en/#top-trader-long-short-ratio-positions every minute
• globalLongShortAccountRatio - generated channel, available since 2020-12-18Global long/short ratio, sourced by querying https://binance-docs.github.io/apidocs/futures/en/#long-short-ratio every minute
• takerlongshortRatio - generated channel, available since 2021-12-01Taker buy sell volume and ratio, sourced by querying https://binance-docs.github.io/apidocs/futures/en/#taker-buy-sell-volume every minute

### Market data collection details
Market data collection infrastructure for Binance USDT Futures since 2020-05-14 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Binance servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousDeribit](/historical-data-details/deribit)[NextBinance COIN Futures](/historical-data-details/binance-delivery)Last updated 3 years ago

================================================================================

# Binance COIN Futures

Source: https://docs.tardis.dev/historical-data-details/binance-delivery
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Binance COIN Futures
Binance COIN Margined Futures historical market data details - instruments, data coverage and data collection specifics

$Binance COIN Futures historical data for all it's instruments is available since 2020-06-16.

[https://api.tardis.dev/v1/exchanges/binance-deliveryapi.tardis.dev](https://api.tardis.dev/v1/exchanges/binance-delivery)See Binance COIN Futures historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD_200925

2020-07-01

Download sample

incremental_book_L2

BTCUSD_200925

2020-07-01

Download sample

book_snapshot_25

BTCUSD_PERP

2020-11-01

Download sample

quotes

BTCUSD_200925

2020-07-01

Download sample

derivative_ticker

BTCUSD_200925

2020-07-01

Download sample

trades

FUTURES

2020-07-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Binance COIN Futures WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="binance-delivery",
    from_date="2020-07-01",
    to_date="2020-07-02",
    filters=[Channel(name="depth", symbols=["btcusd_200925"])]
  )

  # messages as provided by Binance COIN Futures real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'binance-delivery',
      from: '2020-07-01',
      to: '2020-07-02',
      filters: [{ channel: 'depth', symbols: ['btcusd_200925'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Binance COIN Futures real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/binance-delivery?from=2020-07-01&filters=[{"channel":"depth","symbols":["btcusd_200925"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/binance-delivery?from=2020-07-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusd_200925%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/binance-delivery?from=2020-07-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusd_200925%22]}]&offset=0)Example API response for Binance COIN Futures historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"binance-delivery","filters":[{"channel":"depth","symbols":["btcusd_200925"]}],"from":"2020-07-01","to":"2020-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Change Log | Binance Open Platformbinance-docs.github.io](https://binance-docs.github.io/apidocs/delivery/en/#websocket-market-streams)See Binance COIN Futures WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• aggTrade
• ticker
• bookTicker
• forceOrder
• markPrice @1s
• indexPrice @1s
• depth @0ms
• depthSnapshot - generated channel with full order book snapshots
Binance COIN Futures real-time WebSocket API does not provide initial order book snapshots. To overcome this issue we fetch initial order book snapshots from REST API and store them together with the rest of the WebSocket messages - top 1000 levels. Such snapshot messages are marked with "stream":"<symbol>@depthSnapshot" and "generated":true  fields. 
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by real-time feed (pu and u fields) - in case of detecting missed message WebSocket connection is being restarted. We also validate if initial book snapshot fetched from REST API overlaps with received depth messages.
• openInterest - generated channelSince Binance COIN Futures does not offer currently real-time WebSocket open interest channel, we simulate it by fetching that info from REST API (https://binance-docs.github.io/apidocs/delivery/en/#open-interest) every 30 seconds for each instrument. Such messages are marked with "stream":"<symbol>@openInterest" and "generated":true  fields and data field has the same format as REST API response.

### Market data collection details
Market data collection infrastructure for Binance COIN Futures is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

Binance servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousBinance USDT Futures](/historical-data-details/binance-futures)[NextBinance Spot](/historical-data-details/binance)Last updated 2 years ago

================================================================================

# Binance Spot

Source: https://docs.tardis.dev/historical-data-details/binance
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Binance Spot
Binance historical market data details - currency pairs, data coverage and data collection specifics

$Binance historical data for high caps currency pairs is available since 2019-03-30, data for all currency pairs is available since 2021-03-05.

[https://api.tardis.dev/v1/exchanges/binanceapi.tardis.dev](https://api.tardis.dev/v1/exchanges/binance)See Binance historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSDT

2019-12-01

Download sample

incremental_book_L2

BTCUSDT

2019-12-01

Download sample

book_snapshot_25

BTCUSDT

2019-12-01

Download sample

quotes

BTCUSDT

2019-12-01

Download sample

trades

ETHUSDT

2020-03-01

Download sample

incremental_book_L2

ETHUSDT

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Binance WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="binance",
    from_date="2019-12-01",
    to_date="2019-12-02",
    filters=[Channel(name="depth", symbols=["btcusdt"])]
  )

  # messages as provided by Binance real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'binance',
      from: '2019-12-01',
      to: '2019-12-02',
      filters: [{ channel: 'depth', symbols: ['btcusdt'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Binance real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/binance?from=2019-12-01&filters=[{"channel":"depth","symbols":["btcusdt"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/binance?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusdt%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/binance?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusdt%22]}]&offset=0)Example API response for Binance historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"binance","filters":[{"channel":"depth","symbols":["btcusdt"]}],"from":"2019-12-01","to":"2019-12-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Changelog | Binance Open Platformbinance-docs.github.io](https://binance-docs.github.io/apidocs/spot/en/#websocket-market-streams)See Binance WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• aggTrade - available since 2019-11-19
• ticker
• bookTicker - available since 2019-09-21
• depth
Binance depth channel has been recorded with the fastest update speed API allowed at the time. It means until 2019-08-30 it was depth (without @time suffix) - book updates pushed every 1000ms  and after that date it was depth@100ms - book updates pushed every 100ms (new API feature).
• depthSnapshot  - generated channel with full order book snapshots
Binance real-time WebSocket API does not provide initial order book snapshots. To overcome this issue we fetch initial order book snapshots from REST API and store them together with the  rest of the WebSocket messages - top 1000 levels. Such snapshot messages are marked with "stream":"<symbol>@depthSnapshot" and "generated":true  fields. 
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by real-time feed (U and u fields) - in case of detecting missed message WebSocket connection is being restarted. We also validate if initial book snapshot fetched from REST API overlaps with received depthmessages.

### Market data collection details
Market data collection infrastructure for Binance since 2020-05-18 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Binance servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousBinance COIN Futures](/historical-data-details/binance-delivery)[NextFTX](/historical-data-details/ftx)Last updated 2 years ago

================================================================================

# FTX

Source: https://docs.tardis.dev/historical-data-details/ftx
Extraction Method: playwright
Components: code_block(7)

Copy
1. Historical Data Details

# FTX
FTX historical market data details - available instruments, data coverage and data collection specifics

$Delisted exchange.

FTX historical data for all it's instruments is available since 2019-08-01 until 2022-11-13.

[https://api.tardis.dev/v1/exchanges/ftxapi.tardis.dev](https://api.tardis.dev/v1/exchanges/ftx)See FTX historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

Derivative ticker datasets are available since 2020-05-13 - date since we've started collecting that data via FTX REST API (instrument channel).

data type

symbol

date

trades

BTC-PERP

2020-01-01

Download sample

incremental_book_L2

BTC-PERP

2020-01-01

Download sample

book_snapshot_25

BTC-PERP

2020-01-01

Download sample

quotes

BTC-PERP

2020-01-01

Download sample

derivative_ticker

BTC-PERP

2020-06-01

Download sample

trades

FUTURES

2020-03-01

Download sample

incremental_book_L2

FUTURES

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

#### How to download all FTX datasets for all instruments
See full downloadable CSV files documentation with datasets format spec, data samples and more.

PythonNode.jscURL$Copy
```
# requires Python >=3.6
# pip install tardis-dev

from tardis_dev import datasets, get_exchange_details
import logging

# optionally enable debug logs
# logging.basicConfig(level=logging.DEBUG)

exchange = 'ftx'
exchange_details = get_exchange_details(exchange)   

# iterate over and download all data for every symbol
for symbol in exchange_details["datasets"]["symbols"]:
    # alternatively specify datatypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    # see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    data_types = symbol["dataTypes"]  
    symbol_id = symbol["id"]
    from_date =  symbol["availableSince"]
    to_date = symbol["availableTo"]

    # skip groupped symbols
    if symbol_id in ['PERPETUALS', 'SPOT', 'FUTURES']:
        continue

    print(f"Downloading {exchange} {data_types} for {symbol_id} from {from_date} to {to_date}")

    # each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    # see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    datasets.download(
        exchange = exchange,
        data_types = data_types,
        from_date =  from_date,
        to_date = to_date,
        symbols = [symbol_id],
        # TODO set your API key here
        api_key = "YOUR_API_KEY",
        # path where CSV data will be downloaded into
        download_dir = "./datasets",
    )
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
// npm install tardis-dev
// requires node version >=12
const { downloadDatasets, getExchangeDetails } = require('tardis-dev')

;(async () => {
  const exchange = 'ftx'
  const exchangeDetails = await getExchangeDetails(exchange)

  // iterate over and download all data for every symbol
  for (const symbol of exchangeDetails.datasets.symbols) {
    // alternatively specify dataTypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    // see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    const dataTypes = symbol.dataTypes
    const symbolId = symbol.id

    const from = symbol.availableSince
    const to = symbol.availableTo

    // skip groupped symbols
    if (['PERPETUALS', 'SPOT', 'FUTURES'].includes(symbolId)) {
      continue
    }

    console.log(`Downloading ${exchange} ${dataTypes} for ${symbolId} from ${from} to ${to}`)

    // each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    // see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    await downloadDatasets({
      exchange,
      dataTypes,
      from,
      to,
      symbols: [symbolId],
      // TODO: set your API key here
      apiKey: 'YOUR_API_KEY',
      //  path where CSV data will be downloaded into
      downloadDir: './datasets'
    })
  }
})()
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
curl -o ftx_trades_2019-11-01_BTC-PERP.csv.gz https://datasets.tardis.dev/v1/ftx/trades/2019/11/01/BTC-PERP.csv.gz
```

/$See datasets API reference which allows downloading single file at once.

### API Access and data format
Historical data format is the same as provided by real-time FTX WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="ftx",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="orderbook", symbols=["BTC-PERP"])]
  )

  # messages as provided by FTX real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'ftx',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'orderbook', symbols: ['BTC-PERP'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by FTX real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/ftx?from=2020-01-01&filters=[{"channel":"orderbook","symbols":["BTC-PERP"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/ftx?from=2020-01-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22BTC-PERP%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/ftx?from=2020-01-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22BTC-PERP%22]}]&offset=0)Example API response for FTX historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"ftx","filters":[{"channel":"orderbook","symbols":["BTC-PERP"]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[FTXFTX](https://docs.ftx.com/#websocket-api)See FTX WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• orderbook
• trades
• markets - available since 2020-05-22
• orderbookGrouped - available since 2020-07-21
Asorderbook channel provides data only about the orderbook's best 100 orders on either side, grouped orderbooks channel supplies orderbook data with grouped (collapsed) prices allowing retrieving lower-granularity, higher-depth information about the orderbook. 
We set grouping param to instruments' priceIncrement value multiplied by 10.
• instrument - generated channel, available since 2020-05-13
Since FTX does not offer currently real-time WebSocket instrument info channel with next funding rate, open interest or mark price data, we simulate it by fetching that info from FTX REST API (https://docs.ftx.com/#get-future and https://docs.ftx.com/#get-future-stats) every 3-5 seconds for each derivative instrument. Such messages are marked with "channel":"instrument" and "generated":true  fields and data field has the same format as REST API responses.

### Market data collection details
Market data collection infrastructure for FTX since 2020-05-14 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).

Real-time market data is captured via multiple WebSocket connections.

FTX servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousBinance Spot](/historical-data-details/binance)[NextOKX Futures](/historical-data-details/okex-futures)Last updated 2 years ago

================================================================================

# OKX Futures

Source: https://docs.tardis.dev/historical-data-details/okex-futures
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# OKX Futures
OKX Futures historical market data details - instruments, data coverage and data collection specifics

$OKX historical data for all it's futures instruments is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/okex-futuresapi.tardis.dev](https://api.tardis.dev/v1/exchanges/okex-futures)See OKX Futures historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

Liquidations datasets are available since 2020-12-18.

data type

symbol

date

trades

BTC-USD-200103

2020-01-01

Download sample

incremental_book_L2

BTC-USD-200103

2020-01-01

Download sample

book_snapshot_25

BTC-USD-200103

2020-01-01

Download sample

quotes

BTC-USD-200103

2020-01-01

Download sample

derivative_ticker

BTC-USD-200103

2020-01-01

Download sample

trades

FUTURES

2020-03-01

Download sample

liquidations

FUTURES

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time OKX WebSocket v5 API with addition of local timestamps (before 2021-12-23 it was v3 API version). If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="okex-futures",
    from_date="2023-01-01",
    to_date="2023-01-02",
    filters=[Channel(name="books-l2-tbt", symbols=[])]
  )

  # messages as provided by OKX real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'okex-futures',
      from: '2023-01-01',
      to: '2023-01-02',
      filters: [{ channel: 'books-l2-tbt', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by OKX real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/okex-futures?from=2023-01-01&filters=[{"channel":"books-l2-tbt","symbols":[]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/okex-futures?from=2023-01-01&filters=[{%22channel%22:%22books-l2-tbt%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/okex-futures?from=2023-01-01&filters=[{%22channel%22:%22books-l2-tbt%22,%22symbols%22:[]}]&offset=0)Example API response for OKEx Futures historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"okex-futures","filters":[{"channel":"books-l2-tbt","symbols":[]}],"from":"2023-01-01","to":"2023-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[OKX API guide | OKX technical support | OKXwww.okx.com](https://www.okx.com/docs-v5/en/)See OKX Futures WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

V3 API channels (recorded until 2021-12-23):

• futures/trade
• futures/depth - available until 2020-01-29
• futures/depth_l2_tbt - available since 2019-12-05
• futures/mark_price
• futures/ticker
• index/ticker - available since 2019-09-21
• system/status - available since 2020-07-05

V5 API channels (recorded since 2021-12-23):

• trades
• trades-all
• books-l2-tbt
• bbo-tbt
• tickers
• open-interest
• mark-price
• price-limit
• status
• instruments
• index-tickers
• long-short-account-ratio
• taker-volume
• estimated-price
• public-block-trades
• public-struc-block-trades
• liquidation-orders
• taker-volume-contract
• long-short-account-ratio-contract-top-trader
• long-short-position-ratio-contract-top-trader
• long-short-account-ratio-contract

### Market data collection details
Market data collection infrastructure for OKX Futures since 2022-05-04T16:45 is located in AWS HK region (Hong Kong, China, VPC colo setup), before that, starting since 2020-05-15 it was located in GCP asia-northeast1 (Tokyo, Japan) and initially it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

OKEx servers are located in Alibaba Cloud cn-hongkong region (Hong Kong, China).

/$[PreviousFTX](/historical-data-details/ftx)[NextOKX Swap](/historical-data-details/okex-swap)Last updated 1 year ago

================================================================================

# OKX Swap

Source: https://docs.tardis.dev/historical-data-details/okex-swap
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# OKX Swap
OKX Swap historical market data details - instruments, data coverage and data collection specifics

$OKX historical data for all it's perpetual swap instruments is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/okex-swapapi.tardis.dev](https://api.tardis.dev/v1/exchanges/okex-swap)See OKX Swap historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

Liquidations datasets are available since 2020-12-18.

data type

symbol

date

trades

BTC-USD-SWAP

2020-01-01

Download sample

incremental_book_L2

BTC-USD-SWAP

2020-01-01

Download sample

book_snapshot_25

BTC-USD-SWAP

2020-01-01

Download sample

quotes

BTC-USD-SWAP

2020-01-01

Download sample

derivative_ticker

BTC-USD-SWAP

2020-01-01

Download sample

trades

PERPETUALS

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time OKX WebSocket v3 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="okex-swap",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="swap/trade", symbols=[])]
  )

  # messages as provided by OKEx real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'okex-swap',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'swap/trade', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by OKEx real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/okex-swap?from=2020-01-01&filters=[{"channel":"swap/trade","symbols":[]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/okex-swap?from=2020-01-01&filters=[{%22channel%22:%22swap/trade%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/okex-swap?from=2020-01-01&filters=[{%22channel%22:%22swap/trade%22,%22symbols%22:[]}]&offset=0)Example API response for OKEx Swap historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"okex-swap","filters":[{"channel":"swap/trade","symbols":[]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://www.okex.com/docs/en/#ws_swap-allwww.okex.com](https://www.okex.com/docs/en/#ws_swap-all)See OKEx Swap WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• swap/trade
• swap/depth - available until 2020-02-12
• swap/depth_l2_tbt - available since 2020-02-08
• swap/funding_rate
• swap/mark_price
• swap/ticker
• index/ticker - available since 2019-09-2
• system/status - available since 2020-07-05

### Market data collection details
Market data collection infrastructure for OKX Swap since 2022-05-04T16:45 is located in AWS HK region (Hong Kong, China, VPC colo setup), before that, starting since 2020-05-15 it was located in GCP asia-northeast1 (Tokyo, Japan) and initially it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

OKEx servers are located in Alibaba Cloud cn-hongkong region (Hong Kong, China).

/$[PreviousOKX Futures](/historical-data-details/okex-futures)[NextOKX Options](/historical-data-details/okex-options)Last updated 1 year ago

================================================================================

# OKX Options

Source: https://docs.tardis.dev/historical-data-details/okex-options
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# OKX Options
OKX Options historical market data details - instruments, data coverage and data collection specifics

$OKX historical data for all it's options instruments is available since 2020-02-01.

[https://api.tardis.dev/v1/exchanges/okex-optionsapi.tardis.dev](https://api.tardis.dev/v1/exchanges/okex-options)See OKX Options historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USD-200327-8500-P

2020-03-01

Download sample

incremental_book_L2

BTC-USD-200327-8500-P

2020-03-01

Download sample

quotes

BTC-USD-200327-8500-P

2020-03-01

Download sample

trades

OPTIONS

2020-03-01

Download sample

options_chain

OPTIONS

2020-03-01

Download sample

quotes

OPTIONS

2020-03-01

Download sample

book_snapshot_25

OPTIONS

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time OKX WebSocket v3 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="okex-options",
    from_date="2020-02-01",
    to_date="2020-02-02",
    filters=[Channel(name="option/trade", symbols=[])]
  )

  # messages as provided by OKEx real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'okex-options',
      from: '2020-02-01',
      to: '2020-02-02',
      filters: [{ channel: 'option/trade', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by OKEx real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/okex-options?from=2020-02-01&filters=[{"channel":"option/trade","symbols":[]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/okex-options?from=2020-02-01&filters=[{%22channel%22:%22option/trade%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/okex-options?from=2020-02-01&filters=[{%22channel%22:%22option/trade%22,%22symbols%22:[]}]&offset=0)Example API response for OKEx Options historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"okex-options","filters":[{"channel":"option/trade","symbols":[]}],"from":"2020-02-01","to":"2020-02-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://www.okex.com/docs/en/#option_ws-allwww.okex.com](https://www.okex.com/docs/en/#option_ws-all)See OKEx Options WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• option/trade
• option/depth - available until 2020-02-12
• option/depth_l2_tbt - available since 2020-02-08
• option/ticker
• option/summary
• option/instruments
• index/ticker - available since 2020-06-09
• system/status - available since 2020-07-05
• option/trades - available since 2020-07-31

### Market data collection details
Market data collection infrastructure for OKX Options since 2022-05-04T16:45 is located in AWS HK region (Hong Kong, China, VPC colo setup), before that, starting since 2020-05-15 it was located in GCP asia-northeast1 (Tokyo, Japan) and initially it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

OKEx servers are located in Alibaba Cloud cn-hongkong region (Hong Kong, China).

/$[PreviousOKX Swap](/historical-data-details/okex-swap)[NextOKX Spot](/historical-data-details/okex)Last updated 1 year ago

================================================================================

# OKX Spot

Source: https://docs.tardis.dev/historical-data-details/okex
Extraction Method: playwright
Components: code_block(7)

Copy
1. Historical Data Details

# OKX Spot
OKX Spot historical market data details - currency pairs, data coverage and data collection specifics

$OKEx historical data for spot high caps currency pairs is available since 2019-03-30, data for all spot currency pairs is available since 2021-03-11.

[https://api.tardis.dev/v1/exchanges/okexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/okex)See OKX Spot historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USDT

2020-01-01

Download sample

incremental_book_L2

BTC-USDT

2020-01-01

Download sample

book_snapshot_25

BTC-USDT

2020-01-01

Download sample

quotes

BTC-USDT

2020-01-01

Download sample

trades

ETH-USDT

2020-03-01

Download sample

incremental_book_L2

ETH-USDT

2020-03-01

Download sample

#### How to download all OKEx datasets for all instruments
See full downloadable CSV files documentation with datasets format spec, data samples and more.

PythonNode.jscURL$Copy
```
# requires Python >=3.6
# pip install tardis-dev

from tardis_dev import datasets, get_exchange_details
import logging

# optionally enable debug logs
# logging.basicConfig(level=logging.DEBUG)

exchange = 'okex'
exchange_details = get_exchange_details(exchange)   

# iterate over and download all data for every symbol
for symbol in exchange_details["datasets"]["symbols"]:
    # alternatively specify datatypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    # see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    data_types = symbol["dataTypes"]  
    symbol_id = symbol["id"]
    from_date =  symbol["availableSince"]
    to_date = symbol["availableTo"]

    # skip groupped symbols
    if symbol_id in ['PERPETUALS', 'SPOT', 'FUTURES']:
        continue

    print(f"Downloading {exchange} {data_types} for {symbol_id} from {from_date} to {to_date}")

    # each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    # see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    datasets.download(
        exchange = exchange,
        data_types = data_types,
        from_date =  from_date,
        to_date = to_date,
        symbols = [symbol_id],
        # TODO set your API key here
        api_key = "YOUR_API_KEY",
        # path where CSV data will be downloaded into
        download_dir = "./datasets",
    )
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
// npm install tardis-dev
// requires node version >=12
const { downloadDatasets, getExchangeDetails } = require('tardis-dev')

;(async () => {
  const exchange = 'okex'
  const exchangeDetails = await getExchangeDetails(exchange)

  // iterate over and download all data for every symbol
  for (const symbol of exchangeDetails.datasets.symbols) {
    // alternatively specify dataTypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    // see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    const dataTypes = symbol.dataTypes
    const symbolId = symbol.id

    const from = symbol.availableSince
    const to = symbol.availableTo

    // skip groupped symbols
    if (['PERPETUALS', 'SPOT', 'FUTURES'].includes(symbolId)) {
      continue
    }

    console.log(`Downloading ${exchange} ${dataTypes} for ${symbolId} from ${from} to ${to}`)

    // each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    // see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    await downloadDatasets({
      exchange,
      dataTypes,
      from,
      to,
      symbols: [symbolId],
      // TODO: set your API key here
      apiKey: 'YOUR_API_KEY',
      //  path where CSV data will be downloaded into
      downloadDir: './datasets'
    })
  }
})()
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
curl -o okex_trades_2019-11-01_BTC-USD.csv.gz https://datasets.tardis.dev/v1/okex/trades/2019/11/01/BTC-USD.csv.gz
```

/$See datasets API reference which allows downloading single file at once.

### API Access and data format
Historical data format is the same as provided by real-time OKX WebSocket v3 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="okex",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="spot/trade", symbols=[])]
  )

  # messages as provided by OKEx real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'okex',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'spot/trade', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by OKEx real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/okex?from=2020-01-01&filters=[{"channel":"spot/trade","symbols":[]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/okex?from=2020-01-01&filters=[{%22channel%22:%22spot/trade%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/okex?from=2020-01-01&filters=[{%22channel%22:%22spot/trade%22,%22symbols%22:[]}]&offset=0)Example API response for OKEx Spot historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"okex","filters":[{"channel":"spot/trade","symbols":[]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://www.okex.com/docs/en/#spot_ws-allwww.okex.com](https://www.okex.com/docs/en/#spot_ws-all)See OKEx Spot WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• spot/trade
• spot/ticker
• spot/depth - available until 2020-04-10
• spot/depth_l2_tbt - available since 2020-04-10
• system/status - available since 2020-07-05

### Market data collection details
Market data collection infrastructure for OKX Spot since 2022-05-04T16:45 is located in AWS HK region (Hong Kong, China, VPC colo setup), before that, starting since 2020-05-15 it was located in GCP asia-northeast1 (Tokyo, Japan) and initially it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

OKEx servers are located in Alibaba Cloud cn-hongkong region (Hong Kong, China).

/$[PreviousOKX Options](/historical-data-details/okex-options)[NextHuobi Futures](/historical-data-details/huobi-dm)Last updated 1 year ago

================================================================================

# Huobi Futures

Source: https://docs.tardis.dev/historical-data-details/huobi-dm
Extraction Method: playwright
Components: code_block(7)

Copy
1. Historical Data Details

# Huobi Futures
Huobi Futures historical market data details - instruments, data coverage and data collection specifics

$Huobi Futures historical data for all it's instruments is available since 2019-11-19.

[https://api.tardis.dev/v1/exchanges/huobi-dmapi.tardis.dev](https://api.tardis.dev/v1/exchanges/huobi-dm)See Huobi Futures historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

Derivative ticker datasets are available since 2020-06-24.

data type

symbol

date

trades

BTC_CQ

2020-02-01

Download sample

incremental_book_L2

BTC_CQ

2020-02-01

Download sample

book_snapshot_25

BTC_CQ

2020-02-01

Download sample

quotes

BTC_CQ

2020-02-01

Download sample

derivative_ticker

BTC_CQ

2020-07-01

Download sample

trades

FUTURES

2020-03-01

Download sample

liquidations

FUTURES

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Huobi Futures WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="huobi-dm",
    from_date="2020-02-01",
    to_date="2020-02-02",
    filters=[Channel(name="depth", symbols=["BTC_CW"])]
  )

  # messages as provided by Huobi Futures real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'huobi-dm',
      from: '2020-02-01',
      to: '2020-02-02',
      filters: [{ channel: 'depth', symbols: ['BTC_CW'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Huobi Futures real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/huobi-dm?from=2020-02-01&filters=[{"channel":"depth","symbols":["BTC_CW"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/huobi-dm?from=2020-02-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC_CW%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/huobi-dm?from=2020-02-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC_CW%22]}]&offset=0)Example API response for Huobi Futures historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"huobi-dm","filters":[{"channel":"depth","symbols":["BTC_CW"]}],"from":"2020-02-01","to":"2020-02-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Huobi API Reference v1.0huobiapi.github.io](https://huobiapi.github.io/docs/dm/v1/en/#websocket-market-interface)See Huobi Futures WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• depth
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by Huobi Futures real-time feed (version field) - in case of detecting missed message WebSocket connection is being restarted.
See also details below regarding depth channel data collection details.
• trade
• detail
• bbo - available since 2020-06-24
• open_interest - generated channel, available since 2020-06-24
Since Huobi Futures does not offer currently real-time WebSocket open interest channel, we simulate it by fetching that info from REST API (https://huobiapi.github.io/docs/dm/v1/en/#get-contract-open-interest-information) every 4-6 seconds for each instrument. Such messages are marked with "ch":"market.<symbol>.open_interest" and "generated":true  fields and data field has the same format as REST API response data.
• basis (index price updates) - available since 2020-06-24
• liquidation_orders - available since 2020-06-24
• contract_info - available since 2020-06-24

Up until 2020-01-31 depth channel was collected with step0 aggregation level (no aggregation) which produces full order book snapshots for each book change which is very inefficient to store. To circumvent this issue we stored only initial book snapshots and then incremental updates instead - incremental updates were calculated by diffing two subsequent book snapshots and provided in the same format as other depth messages, except having additional update: true flag set as in snippet below. Update with amount (second value in array) set to 0 means such level should be deleted, otherwise price level should be updated with new amount value.

$Copy
```
{
  "ch": "market.ETC_CW.depth.step0",
  "ts": 1572652860024,
  "update": true,
  "tick": {
    "mrid": 24660973159,
    "id": 1572652860,
    "bids": [
      [
        4.869,
        1175
      ]
    ],
    "asks": [],
    "ts": 1572652860013,
    "version": 1572652860,
    "ch": "market.ETC_CW.depth.step0"
  }
}
```

/$On 2020-01-31 we've switched to depth.size_150.high_freq channel instead when collecting data and which natively provides incremental order book updates without workarounds described above.

Unfortunately it means that when requesting data for depth channel it may return slightly different format depending for which time period request was made.  It's only slightly different and boils down to the way order book update messages are marked vs order book snapshots. In depth.size_150.high_freq order book message has event field always present with value update or snapshot, for example:

$Copy
```
{
  "ch": "market.LTC_CW.depth.size_150.high_freq",
  "tick": {
   ...
    "event": "update",
   ...
  }
}
```

/$For messages before 2020-01-31 we've used depth.step0 channel for collecting order book data which means order book update message has flag update set to true, if it's a snapshot it doesn't have that flag at all, for example:

$Copy
```
{
  "ch": "market.ETC_CW.depth.step0",
  "update": true,
  "tick": {
   ...
  }
}
```

/$All other fields are are the same (tick.bids and tick.asks etc).

Please feel free to contact us if it's confusing in any way.

We also provide normalization layer that handles those differences transparently via our client libs.

### Market data collection details
Market data collection infrastructure for Huobi Futures since 2020-06-19 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

Huobi servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousOKX Spot](/historical-data-details/okex)[NextHuobi COIN Swaps](/historical-data-details/huobi-dm-swap)Last updated 2 years ago

================================================================================

# Huobi COIN Swaps

Source: https://docs.tardis.dev/historical-data-details/huobi-dm-swap
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Huobi COIN Swaps
Huobi COIN Swaps historical market data details - instruments, data coverage and data collection specifics

$Huobi COIN Swaps historical data for all it's instruments is available since 2020-03-28.

[https://api.tardis.dev/v1/exchanges/huobi-dm-swapapi.tardis.dev](https://api.tardis.dev/v1/exchanges/huobi-dm-swap)See Huobi COIN Swaps historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

Derivative ticker datasets are available since 2020-06-24.

data type

symbol

date

trades

BTC-USD

2020-04-01

Download sample

incremental_book_L2

BTC-USD

2020-04-01

Download sample

book_snapshot_25

BTC-USD

2020-04-01

Download sample

quotes

BTC-USD

2020-04-01

Download sample

book_snapshot_25

BTC-USD

2020-04-01

Download sample

derivative_ticker

BTC-USD

2020-07-01

Download sample

trades

PERPETUALS

2020-05-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Huobi COIN Swaps WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="huobi-dm-swap",
    from_date="2020-04-01",
    to_date="2020-04-02",
    filters=[Channel(name="depth", symbols=["BTC-USD"])]
  )

  # messages as provided by Huobi COIN Swaps real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'huobi-dm-swap',
      from: '2020-04-01',
      to: '2020-04-02',
      filters: [{ channel: 'depth', symbols: ['BTC-USD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Huobi COIN Swaps real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/huobi-dm-swap?from=2020-04-01&filters=[{"channel":"depth","symbols":["BTC-USD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/huobi-dm-swap?from=2020-04-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/huobi-dm-swap?from=2020-04-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0)Example API response for Huobi COIN Swaps historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"huobi-dm-swap","filters":[{"channel":"depth","symbols":["BTC-USD"]}],"from":"2020-04-01","to":"2020-04-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Huobi Coin Margined Swap API Referencehuobiapi.github.io](https://huobiapi.github.io/docs/coin_margined_swap/v1/en/)See Huobi COIN Swaps WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• depth (depth.size_150.high_freq)
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by Huobi Swap real-time feed (version field) - in case of detecting missed message WebSocket connection is being restarted.
• trade
• detail
• bbo - available since 2020-09-18
• open_interest - generated channel, available since 2020-06-24
Since Huobi does not offer currently real-time WebSocket open interest channel, we simulate it by fetching that info from REST API (https://huobiapi.github.io/docs/coin_margined_swap/v1/en/#get-swap-open-interest-information) every 4-6 seconds for each instrument. Such messages are marked with "ch":"market.<symbol>.open_interest" and "generated":true  fields and data field has the same format as REST API response data.
• basis (index price updates) - available since 2020-06-24
• liquidation_orders - available since 2020-06-24
• contract_info - available since 2020-06-24
• funding_rate - available since 2020-06-24

### Market data collection details
Market data collection infrastructure for Huobi COIN Swaps since 2020-06-19 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

Huobi servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousHuobi Futures](/historical-data-details/huobi-dm)[NextHuobi USDT Swaps](/historical-data-details/huobi-dm-linear-swap)Last updated 2 years ago

================================================================================

# Huobi USDT Swaps

Source: https://docs.tardis.dev/historical-data-details/huobi-dm-linear-swap
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Huobi USDT Swaps
Huobi USDT Swaps historical market data details - instruments, data coverage and data collection specifics

$Huobi USDT Swaps historical data for all it's instruments is available since 2020-10-30.

[https://api.tardis.dev/v1/exchanges/huobi-dm-linear-swapapi.tardis.dev](https://api.tardis.dev/v1/exchanges/huobi-dm-linear-swap)See Huobi USDT Swaps historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USDT

2023-03-01

Download sample

incremental_book_L2

BTC-USDT

2023-03-01

Download sample

book_snapshot_25

BTC-USDT

2023-03-01

Download sample

quotes

BTC-USDT

2023-03-01

Download sample

book_ticker

BTC-USDT

2023-03-01

Download sample

derivative_ticker

BTC-USDT

2023-03-01

Download sample

trades

FUTURES

2023-03-01

Download sample

liquidations

PERPETUALS

2023-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Huobi USDT Swaps WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="huobi-dm-linear-swap",
    from_date="2023-03-01",
    to_date="2023-03-02",
    filters=[Channel(name="depth", symbols=["BTC-USDT"])]
  )

  # messages as provided by Huobi USDT Swaps real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'huobi-dm-linear-swap',
      from: '2020-04-01',
      to: '2020-04-02',
      filters: [{ channel: 'depth', symbols: ['BTC-USDT'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Huobi USDT Swaps real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/huobi-dm-linear-swap?from=2023-03-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC-USDT%22]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/huobi-dm-linear-swap?from=2023-03-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC-USDT%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/huobi-dm-linear-swap?from=2023-03-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC-USDT%22]}]&offset=0)Example API response for Huobi USDT Swaps historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"huobi-dm-linear-swap","filters":[{"channel":"depth","symbols":["BTC-USDT"]}],"from":"2023-03-01","to":"2023-03-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Huobi USDT Margined Contracts API Referencehuobiapi.github.io](https://huobiapi.github.io/docs/usdt_swap/v1/en/)See Huobi USDT Swaps WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• depth (depth.size_150.high_freq)
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by Huobi Swap real-time feed (version field) - in case of detecting missed message WebSocket connection is being restarted.
• detail
• trade
• bbo
• basis
• funding_rate
• liquidation_orders
• contract_info
• open_interest - generated channel
Since Huobi does not offer currently real-time WebSocket open interest channel, we simulate it by fetching that info from REST API (https://huobiapi.github.io/docs/usdt_swap/v1/en/#general-get-swap-open-interest-information) every 4-6 seconds for each instrument. Such messages are marked with "ch":"market.<symbol>.open_interest" and "generated":true  fields and data field has the same format as REST API response data.
• elite_account_ratio
• elite_position_ratio

### Market data collection details
Market data collection infrastructure for Huobi USDT Swap is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

Huobi servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousHuobi COIN Swaps](/historical-data-details/huobi-dm-swap)[NextHuobi Global](/historical-data-details/huobi)Last updated 2 years ago

================================================================================

# Huobi Global

Source: https://docs.tardis.dev/historical-data-details/huobi
Extraction Method: playwright
Components: code_block(5)

Copy
1. Historical Data Details

# Huobi Global
Huobi Global historical market data details - currency pairs, data coverage and data collection specifics

$Huobi Global historical data for high caps currency pairs is available since 2019-11-19, data for all currency pairs is available since 2022-06-09.

[https://api.tardis.dev/v1/exchanges/huobiapi.tardis.dev](https://api.tardis.dev/v1/exchanges/huobi)See Huobi Global historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSDT

2019-12-01

Download sample

incremental_book_L2

BTCUSDT

2019-12-01

Download sample

book_snapshot_25

BTCUSDT

2020-11-01

Download sample

quotes

BTCUSDT

2019-12-01

Download sample

trades

ETHUSDT

2020-03-01

Download sample

incremental_book_L2

ETHUSDT

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Huobi Global WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="huobi",
    from_date="2019-12-01",
    to_date="2019-12-02",
    filters=[Channel(name="depth", symbols=["btcusdt"])]
  )

  # messages as provided by Huobi real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'huobi',
      from: '2019-12-01',
      to: '2019-12-02',
      filters: [{ channel: 'depth', symbols: ['btcusdt'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Huobi real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/huobi?from=2019-12-01&filters=[{"channel":"depth","symbols":["btcusdt"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/huobi?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusdt%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/huobi?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcusdt%22]}]&offset=0)Example API response for Huobi Global historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"huobi","filters":[{"channel":"depth","symbols":["btcusdt"]}],"from":"2019-12-01","to":"2019-12-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Huobi API Reference v1.0huobiapi.github.io](https://huobiapi.github.io/docs/spot/v1/en/#websocket-market-data)See Huobi Global WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• mbp (mbp.150, 100ms interval) - market by price incremental updates,  available since 2020-07-03
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by Huobi real-time feed (seqNum and prevSeqNum fields) - in case of detecting missed message (sequence gap) we  fetch new snapshot via "req" request - it means that for brief moment of time between requesting a new snapshot and receiving it due to updates containing a gap reconstructed order book based on those updates may not be 100% valid.
Initial order book snapshot is provided in this channel by requesting it via "req" request.
• trade
• detail
• bbo
• etp - available since 2020-08-18
• depth - available until 2020-12-09, see mbp channel that provides more granular order book dataCollected with step0 aggregation level and provides data in 1-second intervalsHuobi Globaldepth real-time WebSocket channel always publishes full order book snapshots which are inefficient to store. To circumvent this issue we stored only initial book snapshots and then incremental updates instead - incremental updates are calculated by diffing two subsequent book snapshots and provided in the same format as other depth messages, except having additional update: true flag set as in snippet below. Update with amount (second value in array) set to 0 means such level should be deleted, otherwise price level should be updated with new amount value.

$Copy
```
{
   "ch":"market.zileth.depth.step0",
   "ts":1573527600013,
   "update":true,
   "tick":{
      "bids":[ [3.056E-05, 0] ],
      "asks":[],
      "ts":1573527600005,
      "version":100132779130
   }
}
```

/$
### Market data collection details
Market data collection infrastructure for Huobi Global since 2020-06-19 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

Huobi Global servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousHuobi USDT Swaps](/historical-data-details/huobi-dm-linear-swap)[NextBitfinex Derivatives](/historical-data-details/bitfinex-derivatives)Last updated 2 years ago

================================================================================

# Bitfinex Derivatives

Source: https://docs.tardis.dev/historical-data-details/bitfinex-derivatives
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Bitfinex Derivatives
Bitfinex Derivatives historical market data details - available instruments, data coverage and data collection specifics

$Bitfinex exchange historical data for all it's derivative instruments is available since 2019-09-14.

[https://api.tardis.dev/v1/exchanges/bitfinex-derivativesapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bitfinex-derivatives)See Bitfinex Derivatives historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCF0-USTF0

2019-12-01

Download sample

incremental_book_L2

BTCF0-USTF0

2019-12-01

Download sample

quotes

BTCF0-USTF0

2019-12-01

Download sample

book_snapshot_25

BTCF0-USTF0

2019-12-01

Download sample

derivative_ticker

BTCF0-USTF0

2019-12-01

Download sample

trades

ETHF0-USTF0

2020-03-01

Download sample

incremental_book_L2

ETHF0-USTF0

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Bitfinex WebSocket v2 API with addition of local timestamps and since 2020-05-27 also with addition of channel and symbol at the end of each message which allows us providing filtering for the data server-side. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bitfinex-derivatives",
    from_date="2020-06-01",
    to_date="2020-06-02",
    filters=[Channel(name="book", symbols=["BTCF0:USTF0"])]
  )

  # messages as provided by Bitfinex real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bitfinex-derivatives',
      from: '2020-06-01',
      to: '2020-06-02',
      filters: [{ channel: 'book', symbols: ['BTCF0:USTF0'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Bitfinex real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bitfinex-derivatives?from=2020-06-1&filters=[{"channel":"book","symbols":["BTCF0:USTF0"]}]&offset=3'
```

/$[https://api.tardis.dev/v1/data-feeds/bitfinex-derivatives?from=2020-06-1&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTCF0:USTF0%22]}]&offset=3api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bitfinex-derivatives?from=2020-06-1&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTCF0:USTF0%22]}]&offset=3)Example API response for Bitfinex Derivatives historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bitfinex-derivatives","filters":[],"from":"2019-12-01","to":"2019-12-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[GeneralBitfinex](https://docs.bitfinex.com/v2/docs/ws-general)See Bitfinex WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• book (prec=P0, freq=F0, len=100)
During data collection integrity of order book incremental updates is being validated using sequence numbers (SEQ_ALL option) provided by real-time feed - in case of detecting missed message WebSocket connection is being restarted.
• raw_book (prec=R0, freq=F0, len=100)
• status
• liquidations

All data collection is performed  with TIMESTAMP and  SEQ_ALL config flags set.

Since 2020-05-27 each collected Bitfinex real-time data message has appended channel and symbol at the end of array - this allows us providing data filtering via API. Before that date if filters are provided with API request, always all recorded, unfiltered data feed is being returned.

### Market data collection details
Market data collection infrastructure for Bitfinex is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Bitfinex servers are located in Market Synergy DC (Switzerland).
All it's public APIs are proxied through Cloudflare.

/$[PreviousHuobi Global](/historical-data-details/huobi)[NextBitfinex](/historical-data-details/bitfinex)Last updated 2 years ago

================================================================================

# Bitfinex

Source: https://docs.tardis.dev/historical-data-details/bitfinex
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Bitfinex
Bitfinex historical market data details - currency pairs, data coverage and data collection specifics

$Bitfinex exchange historical data for: BTCUSD, BTCUST, ETHUSD, ETHUST, LTCUSD, TRXUSD, EOSUSD, XRPUSD, LEOUSD, BABUSD currency pairs is available since 2019-05-23, data for other high caps is available since 2020-05-28, data for all currency pairs is available since 2021-10-29.

[https://api.tardis.dev/v1/exchanges/bitfinexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bitfinex)See Bitfinex historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2019-08-01

Download sample

incremental_book_L2

BTCUSD

2019-08-01

Download sample

quotes

BTCUSD

2019-08-01

Download sample

trades

ETHUSD

2020-03-01

Download sample

incremental_book_L2

ETHUSD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Bitfinex WebSocket v2 API with addition of local timestamps and since 2020-05-27 also with addition of channel and symbol at the end of each message which allows us providing filtering for the data server-side. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bitfinex",
    from_date="2020-06-01",
    to_date="2020-06-02",
    filters=[Channel(name="book", symbols=["BTCUSD"])]
  )

  # messages as provided by Bitfinex real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bitfinex',
      from: '2020-06-01',
      to: '2020-06-02',
      filters: [{ channel: 'book', symbols: ['BTCUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Bitfinex real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bitfinex?from=2020-06-1&filters=[{"channel":"book","symbols":["BTCUSD"]}]&offset=3'
```

/$[https://api.tardis.dev/v1/data-feeds/bitfinex?from=2020-06-1&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTCUSD%22]}]&offset=3api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bitfinex?from=2020-06-1&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTCUSD%22]}]&offset=3)Example API response for Bitfinex  historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bitfinex","filters":[],"from":"2019-08-01","to":"2019-08-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[GeneralBitfinex](https://docs.bitfinex.com/v2/docs/ws-general)See Bitfinex WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• book (prec=P0, freq=F0, len=100)
During data collection integrity of order book incremental updates is being validated using sequence numbers (SEQ_ALL option) provided by real-time feed - in case of detecting missed message WebSocket connection is being restarted.
• raw_book (prec=R0, freq=F0, len=100)

All data collection is performed  with TIMESTAMP and  SEQ_ALL config flags set.

Since 2020-05-27 each collected Bitfinex real-time data message has appended channel and symbol at the end of array - this allows us providing data filtering via API. Before that date if filters are provided with API request, always all recorded, unfiltered data feed is being returned.

### Market data collection details
Market data collection infrastructure for Bitfinex is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Bitfinex servers are located in Market Synergy DC (Switzerland). 
All it's public APIs are proxied through Cloudflare.

/$[PreviousBitfinex Derivatives](/historical-data-details/bitfinex-derivatives)[NextCoinbase Pro](/historical-data-details/coinbase)Last updated 2 years ago

================================================================================

# Coinbase Pro

Source: https://docs.tardis.dev/historical-data-details/coinbase
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Coinbase Pro
Coinbase Pro historical market data details - currency pairs, data coverage and data collection specifics

$The market data is the property of Coinbase, Inc as applicable. All rights reserved, or otherwise licensed by Coinbase, Inc.

See Coinbase market data license restrictions that apply.

Coinbase Pro historical data for all it's currency pairs is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/coinbaseapi.tardis.dev](https://api.tardis.dev/v1/exchanges/coinbase)See Coinbase Pro historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2019-07-01

Download sample

incremental_book_L2

BTCUSD

2019-07-01

Download sample

quotes

BTCUSD

2019-07-01

Download sample

trades

ETHUSD

2020-03-01

Download sample

incremental_book_L2

ETHUSD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Coinbase Pro WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="coinbase",
    from_date="2019-07-01",
    to_date="2019-07-02",
    filters=[Channel(name="l2update", symbols=["BTC-USD"])]
  )

  # messages as provided by Coinbase Pro real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'coinbase',
      from: '2019-07-01',
      to: '2019-07-02',
      filters: [{ channel: 'l2update', symbols: ['BTC-USD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Coinbase Pro real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/coinbase?from=2019-07-01&filters=[{"channel":"l2update","symbols":["BTC-USD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/coinbase?from=2019-07-01&filters=[{%22channel%22:%22l2update%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/coinbase?from=2019-07-01&filters=[{%22channel%22:%22l2update%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0)Example API response for Coinbase Pro historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"coinbase","filters":[{"channel":"l2update","symbols":["BTC-USD"]}],"from":"2019-07-01","to":"2019-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Welcome to Exchange APIs - Coinbase Developer DocumentationCoinbase Developer Documentation](https://docs.pro.coinbase.com/#websocket-feed)See Coinbase Pro WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• received
• open
• done
• match
• change
• l2update
• ticker
• snapshot
• last_match
• full_snapshot  - generated channel with full order book L3 snapshots
Coinbase Pro (formerly GDAX) real-time WebSocket API provides initial full order book snapshots for level2, but not for full channel. To overcome this issue we fetch initial order book snapshots from REST API and store them together with rest of the WebSocket messages. Such snapshot messages are marked with  "type":"full_snapshot" and "generated":true fields. This effectively allows reconstructing historical full order book for full (L3) channel. Validation based on sequence numbers if full_snapshot overlap with WS L3 updates has been added  2020-06-11.

### Market data collection details
Market data collection infrastructure for Coinbase is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Coinbase Pro servers are located in AWS us-east-1 region (N. Virginia, USA).
It's WebSocket APIs are proxied through Cloudflare.

/$[PreviousBitfinex](/historical-data-details/bitfinex)[NextKraken Futures](/historical-data-details/cryptofacilities)Last updated 10 months ago

================================================================================

# Kraken Futures

Source: https://docs.tardis.dev/historical-data-details/cryptofacilities
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Kraken Futures
Kraken Futures (Crypto Facilities) historical market data details - available instruments, data coverage and data collection specifics

$Exchange status: not available for individual order

Crypto Facilities (aka Kraken Futures) historical data for all it's instruments is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/cryptofacilitiesapi.tardis.dev](https://api.tardis.dev/v1/exchanges/cryptofacilities)See Kraken Futures historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

PI_XBTUSD

2019-07-01

Download sample

incremental_book_L2

PI_XBTUSD

2019-07-01

Download sample

quotes

PI_XBTUSD

2019-07-01

Download sample

derivative_ticker

PI_XBTUSD

2019-07-01

Download sample

trades

FUTURES

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Crypto Facilities WebSocket v1 with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="cryptofacilities",
    from_date="2019-07-01",
    to_date="2019-07-02",
    filters=[Channel(name="book", symbols=["PI_XBTUSD"])]
  )

  # messages as provided by Kraken Futures real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'cryptofacilities',
      from: '2019-07-01',
      to: '2019-07-02',
      filters: [{ channel: 'book', symbols: ['PI_XBTUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Kraken Futures real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/cryptofacilities?from=2019-07-01&filters=[{"channel":"book","symbols":["PI_XBTUSD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/cryptofacilities?from=2019-07-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22PI_XBTUSD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/cryptofacilities?from=2019-07-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22PI_XBTUSD%22]}]&offset=0)Example API response for Kraken Futures historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"cryptofacilities","filters":[{"channel":"book","symbols":["PI_XBTUSD"]}],"from":"2019-07-01","to":"2019-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://www.cryptofacilities.com/resources/hc/en-us/sections/360000120914-Websocket-API-Publicwww.cryptofacilities.com](https://www.cryptofacilities.com/resources/hc/en-us/sections/360000120914-Websocket-API-Public)See Kraken Futures WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• trade_snapshot
• book
During recording, data integrity of order book incremental updates messages is being validated using sequence numbers provided by Kraken Futures real-time message feed - in case of detecting missed message WebSocket connection is being restarted.
• book_snapshot
• ticker

### Market data collection details
Market data collection infrastructure for Kraken Futures is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections. Recording of data is being done via direct API access - without Cloudflare in between - https://www.cryptofacilities.com/resources/hc/en-us/articles/360022531713-IP-whitelisting-for-direct-access.

Kraken Futures (Crypto Facilities) servers are located in AWS eu-west-1 region (Dublin, Ireland).

/$[PreviousCoinbase Pro](/historical-data-details/coinbase)[NextKraken](/historical-data-details/kraken)Last updated 2 years ago

================================================================================

# Kraken

Source: https://docs.tardis.dev/historical-data-details/kraken
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Kraken
Kraken historical market data details - currency pairs, data coverage and data collection specifics

$Exchange status: not available for individual order

Kraken historical data for all it's currency pairs is available since 2019-06-04.

[https://api.tardis.dev/v1/exchanges/krakenapi.tardis.dev](https://api.tardis.dev/v1/exchanges/kraken)See Kraken historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

XBT-USD

2019-07-01

Download sample

incremental_book_L2

XBT-USD

2019-07-01

Download sample

quotes

XBT-USD

2019-07-01

Download sample

trades

ETH-USD

2020-03-01

Download sample

incremental_book_L2

ETH-USD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Kraken WebSocket v1 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="kraken",
    from_date="2019-07-01",
    to_date="2019-07-02",
    filters=[Channel(name="book", symbols=["XBT/USD"])]
  )

  # messages as provided by Kraken real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'kraken',
      from: '2019-07-01',
      to: '2019-07-02',
      filters: [{ channel: 'book', symbols: ['XBT/USD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Kraken real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/kraken?from=2019-07-01&filters=[{"channel":"book","symbols":["XBT/USD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/kraken?from=2019-07-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22XBT/USD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/kraken?from=2019-07-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22XBT/USD%22]}]&offset=0)Example API response for Kraken historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"kraken","filters":[{"channel":"book","symbols":["XBT/USD"]}],"from":"2019-07-01","to":"2019-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Kraken API Centerwww.kraken.com](https://www.kraken.com/en-us/features/websocket-api)See Kraken WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• ticker
• trade
• book
recorded with depth=1000
• spread

### Market data collection details
Market data collection infrastructure for Kraken is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousKraken Futures](/historical-data-details/cryptofacilities)[NextBitstamp](/historical-data-details/bitstamp)Last updated 2 years ago

================================================================================

# Bitstamp

Source: https://docs.tardis.dev/historical-data-details/bitstamp
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Bitstamp
Bitstamp historical market data details - currency pairs, data coverage and data collection specifics

$Exchange status: not available for individual order

Bitstamp historical data for all it's currency pairs is available since 2019-03-30.

[https://api.tardis.dev/v1/exchanges/bitstampapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bitstamp)See Bitstamp historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2019-07-01

Download sample

incremental_book_L2

BTCUSD

2019-07-01

Download sample

quotes

BTCUSD

2019-07-01

Download sample

trades

ETHUSD

2020-03-01

Download sample

incremental_book_L2

ETHUSD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Bitstamp WebSocket v2 with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bitstamp",
    from_date="2019-07-01",
    to_date="2019-07-02",
    filters=[Channel(name="diff_order_book", symbols=["btcusd"])]
  )

  # messages as provided by Bitstamp real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bitstamp',
      from: '2019-07-01',
      to: '2019-07-02',
      filters: [{ channel: 'diff_order_book', symbols: ['btcusd'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Bitstamp real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bitstamp?from=2019-07-01&filters=[{"channel":"diff_order_book","symbols":["btcusd"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/bitstamp?from=2019-07-01&filters=[{%22channel%22:%22diff_order_book%22,%22symbols%22:[%22btcusd%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bitstamp?from=2019-07-01&filters=[{%22channel%22:%22diff_order_book%22,%22symbols%22:[%22btcusd%22]}]&offset=0)Example API response for Bitstamp historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bitstamp","filters":[{"channel":"diff_order_book","symbols":["btcusd"]}],"from":"2019-07-01","to":"2019-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://www.bitstamp.net/websocket/v2/www.bitstamp.net](https://www.bitstamp.net/websocket/v2/)See Bitstamp WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• live_trades
• live_orders
• diff_order_book

Bitstamp real-time WebSocket API does not provide initial full order book snapshots for live_orders and diff_order_book channels subscriptions. To overcome this issue we fetch initial order book snapshots from REST API and store them together with the rest of the WebSocket messages. Such snapshot messages are marked with "event": "snapshot" and "generated": true fields for respective channels.

### Market data collection details
Market data collection infrastructure for Bitstamp is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Bitstamp servers are located in AWS eu-central-1 region (Frankfurt, Germany).

/$[PreviousKraken](/historical-data-details/kraken)[NextGemini](/historical-data-details/gemini)Last updated 2 years ago

================================================================================

# Gemini

Source: https://docs.tardis.dev/historical-data-details/gemini
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Gemini
Gemini historical market data details - currency pairs, data coverage and data collection specifics

$Gemini exchange historical data for all it's currency pairs is available since 2019-08-30.

[https://api.tardis.dev/v1/exchanges/geminiapi.tardis.dev](https://api.tardis.dev/v1/exchanges/gemini)See Gemini historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2020-01-01

Download sample

incremental_book_L2

BTCUSD

2020-01-01

Download sample

quotes

BTCUSD

2020-01-01

Download sample

trades

ETHUSD

2020-03-01

Download sample

incremental_book_L2

ETHUSD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Gemini WebSocket Market Data Version 2 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="gemini",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="l2_updates", symbols=["BTCUSD"])]
  )

  # messages as provided by Gemini real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'gemini',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'l2_updates', symbols: ['BTCUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Gemini real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/gemini?from=2020-01-01&filters=[{%22channel%22:%22l2_updates%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/gemini?from=2020-01-01&filters=[{%22channel%22:%22l2_updates%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/gemini?from=2020-01-01&filters=[{%22channel%22:%22l2_updates%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0)Example API response for Gemini historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"gemini","filters":[{"channel":"l2_updates","symbols":["BTCUSD"]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Introduction - Gemini Crypto ExchangeGemini Crypto Exchange API Documentation](https://docs.gemini.com/websocket-api/#market-data-version-2)See Gemini WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• l2_updates
• auction_open
• auction_indicative
• auction_result

### Market data collection details
Market data collection infrastructure for Gemini is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via single WebSocket connection.

Gemini exchange servers are located in Equinix NY5 data center (Secaucus, New Jersey, USA).

/$[PreviousBitstamp](/historical-data-details/bitstamp)[NextBybit Derivatives](/historical-data-details/bybit)Last updated 2 years ago

================================================================================

# Bybit Derivatives

Source: https://docs.tardis.dev/historical-data-details/bybit
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Bybit Derivatives
Bybit historical market data details - available instruments, data coverage and data collection specifics

$Bybit historical data for all it's inverse contracts is available since 2019-11-07 (for linear contracts since 2020-05-28).

[https://api.tardis.dev/v1/exchanges/bybitapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bybit)See Bybit historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

Liquidations datasets are available since 2020-12-18.

data type

symbol

date

trades

BTCUSD

2020-01-01

Download sample

incremental_book_L2

BTCUSD

2020-01-01

Download sample

quotes

BTCUSD

2019-01-01

Download sample

derivative_ticker

BTCUSD

2019-01-01

Download sample

trades

ETHUSD

2020-03-01

Download sample

incremental_book_L2

ETHUSD

2020-03-01

Download sample

liquidations

PERPETUALS

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Bybit WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bybit",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="orderBook_200", symbols=["BTCUSD"])]
  )

  # messages as provided by Bybit real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bybit',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'orderBook_200', symbols: ['BTCUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Bybit real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bybit?from=2020-01-01&filters=[{"channel":"orderBook_200","symbols":["BTCUSD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/bybit?from=2020-01-01&filters=[{%22channel%22:%22orderBook_200%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bybit?from=2020-01-01&filters=[{%22channel%22:%22orderBook_200%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0)Example API response for Bybit historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bybit","filters":[{"channel":"orderBook_200","symbols":["BTCUSD"]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://bybit-exchange.github.io/docs/inverse/#t-introductionbybit-exchange.github.io](https://bybit-exchange.github.io/docs/inverse/#t-introduction)See Bybit WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• instrument_info
• orderBookL2_25
• insurance
• orderBook_200 - available since 2019-12-24

### Market data collection details
Market data collection infrastructure for Bybit since 2020-05-28 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

Bybit servers are located in AWS ap-southeast-1 region (Singapore, Asia Pacific).

/$[PreviousGemini](/historical-data-details/gemini)[NextBybit Spot](/historical-data-details/bybit-spot)Last updated 2 years ago

================================================================================

# Bybit Spot

Source: https://docs.tardis.dev/historical-data-details/bybit-spot
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Bybit Spot
Bybit Spot historical market data details - available instruments, data coverage and data collection specifics

$Bybit Spot historical data for all it's currency pairs is available since 2021-12-04.

[https://api.tardis.dev/v1/exchanges/bybit-spotapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bybit-spot)See Bybit Spot historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSDT

2023-03-01

Download sample

incremental_book_L2

BTCUSDT

2023-03-01

Download sample

quotes

BTCUSDT

2023-03-01

Download sample

trades

SPOT

2023-03-01

Download sample

book_snapshot_25

BTCUSDT

2023-03-01

Download sample

book_ticker

BTCUSDT

2023-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Bybit Spot WebSocket v2 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bybit-spot",
    from_date="2023-03-01",
    to_date="2023-03-02",
    filters=[Channel(name="trade", symbols=["BTCUSDT"])]
  )

  # messages as provided by Bybit Spot real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bybit',
      from: '2023-03-01',
      to: '2023-03-02',
      filters: [{ channel: 'trade', symbols: ['BTCUSDT'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Bybit Spot real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bybit-spot?from=2023-01-01&filters=[{%22channel%22:%22trade%22,%22symbols%22:[%22BTCUSDT%22]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/bybit-spot?from=2023-01-01&filters=[{%22channel%22:%22trade%22,%22symbols%22:[%22BTCUSDT%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bybit-spot?from=2023-01-01&filters=[{%22channel%22:%22trade%22,%22symbols%22:[%22BTCUSDT%22]}]&offset=0)Example API response for Bybit Spot historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bybit-spot","filters":[{"channel":"trade","symbols":["BTCUSDT"]}],"from":"2023-03-01","to":"2023-03-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
Click any channel below to see HTTP API response with historical data recorded for it.

• trade
• bookTicker
• depth

### Market data collection details
Market data collection infrastructure for Bybit Spot is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

Bybit servers are located in AWS ap-southeast-1 region (Singapore, Asia Pacific).

/$[PreviousBybit Derivatives](/historical-data-details/bybit)[NextdYdX](/historical-data-details/dydx)Last updated 2 years ago

================================================================================

# dYdX

Source: https://docs.tardis.dev/historical-data-details/dydx
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# dYdX
dYdX historical market data details - currency pairs, data coverage and data collection specifics

$dYdX exchange historical data for all it's instruments is available since 2021-04-06.

[https://api.tardis.dev/v1/exchanges/dydxapi.tardis.dev](https://api.tardis.dev/v1/exchanges/dydx)See dYdX historical data coverage: available symbols, channels, date ranges and incidents
• Currently there's a problem with occasional order book crossed state (best bid>=best ask) when reconstructing the book from dYdX WS updates, it's something dYdX team is aware of and working on a fix.
• nextFundingRate published via v3_markets channel does not exactly matching up with the funding rates that dydx end up paying for open positions, it's also something dYdX team is aware of and working on a fix.

### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USD

2021-09-01

Download sample

incremental_book_L2

BTC-USD

2021-09-01

Download sample

quotes

SOL-USD

2021-09-01

Download sample

book_snapshot 25

SOL-USD

2021-09-01

Download sample

trades

PERPETUALS

2021-09-01

Download sample

derivative_ticker

BTC-USD

2021-09-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time dYdX WebSocket Market Data API v3 (wss://api.dydx.exchange/v3/ws) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="dydx",
    from_date="2021-09-01",
    to_date="2021-09-02",
    filters=[Channel(name="v3_orderbook", symbols=["BTC-USD"])]
  )

  # messages as provided by dYdX real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'dydx',
      from: '2021-09-01',
      to: '2021-09-02',
      filters: [{ channel: 'v3_orderbook', symbols: ['BTC-USD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by dYdX real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/dydx?from=2021-09-01&filters=[{%22channel%22:%22v3_orderbook%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/dydx?from=2021-09-01&filters=[{%22channel%22:%22v3_orderbook%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/dydx?from=2021-09-01&filters=[{%22channel%22:%22v3_orderbook%22,%22symbols%22:[%22BTC-USD%22]}]&offset=0)Example API response for dYdX historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"dydx","filters":[{"channel":"v3_orderbook","symbols":["BTC-USD"]}],"from":"2021-09-01","to":"2021-09-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[dYdX DocumentationdYdX](https://docs.dydx.exchange/#v3-websocket-api)See dYdX WebSocket v3 API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• v3_trades
• v3_orderbook
• v3_markets

### Market data collection details
Market data collection infrastructure for dYdX is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

dYdX servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousBybit Spot](/historical-data-details/bybit-spot)[NextWOO X](/historical-data-details/woo-x)Last updated 2 years ago

================================================================================

# WOO X

Source: https://docs.tardis.dev/historical-data-details/woo-x
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# WOO X
WOO X historical market data details - instruments, data coverage and data collection specifics

$WOO X exchange historical data for all it's instruments is available since 2023-01-20.

[https://api.tardis.dev/v1/exchanges/woo-xapi.tardis.dev](https://api.tardis.dev/v1/exchanges/woo-x)See WOO X historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

SPOT_BTC_USDT

2023-02-01

Download sample

incremental_book_L2

SPOT_BTC_USDT

2023-02-01

Download sample

quotes

PERP_BTC_USDT

2023-02-01

Download sample

book_snapshot_25

PERP_BTC_USDT

2023-02-01

Download sample

trades

PERPETUALS

2023-02-01

Download sample

book_ticker

PERP_BTC_USDT

2023-02-01

Download sample

derivative_ticker

PERP_BTC_USDT

2023-02-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time WOO X WebSocket Market Data API v2 (wss://wss.woo.org/ws/stream) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="woo-x",
    from_date="2023-02-01",
    to_date="2023-02-02",
    filters=[Channel(name="trade", symbols=[])]
  )

  # messages as provided by WOO X real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'woo-x',
      from: '2023-02-01',
      to: '2023-02-02',
      filters: [{ channel: 'trade', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by WOO X real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g https://api.tardis.dev/v1/data-feeds/woo-x?from=2023-02-01&filters=[{%22channel%22:%22trade%22,%22symbols%22:[]}]&offset=23
```

/$[https://api.tardis.dev/v1/data-feeds/woo-x?from=2023-02-01&filters=[{%22channel%22:%22trade%22,%22symbols%22:[]}]&offset=23api.tardis.dev](https://api.tardis.dev/v1/data-feeds/woo-x?from=2023-02-01&filters=[{%22channel%22:%22trade%22,%22symbols%22:[]}]&offset=23)Example API response for Woo X historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"woo-x","filters":[{"channel":"trade","symbols":[]}],"from":"2023-02-01","to":"2023-02-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[WOO X API Referencedocs.woo.org](https://docs.woo.org/#websocket-api-v2)See WOO X WebSocket v3 API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• orderbook - channel with initial order book snapshot, uses request order book API to get it https://docs.woo.org/#request-orderbook
• orderbookupdate
• ticker
• bbo
• indexprice
• markprice
• openinterest
• estfundingrate

### Market data collection details
Market data collection infrastructure for WOO X is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

WOO X servers are located in GCP asia-northeast1 (Tokyo, Japan).

/$[PreviousdYdX](/historical-data-details/dydx)[NextKucoin Spot](/historical-data-details/kucoin)Last updated 2 years ago

================================================================================

# Kucoin Spot

Source: https://docs.tardis.dev/historical-data-details/kucoin
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Kucoin Spot
Kucoin Spot historical market data details - instruments, data coverage and data collection specifics

$Kucoin Spot exchange historical data for all it's currency pairs is available since 2022-08-16.

[https://api.tardis.dev/v1/exchanges/kucoinapi.tardis.dev](https://api.tardis.dev/v1/exchanges/kucoin)See Kucoin Spot historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USDT

2023-02-01

Download sample

incremental_book_L2

BTC-USDT

2023-02-01

Download sample

quotes

BTC-USDT

2023-02-01

Download sample

book_snapshot_25

BTC-USDT

2023-02-01

Download sample

trades

SPOT

2023-02-01

Download sample

book_ticker

BTC-USDT

2023-02-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Kucoin Spot WebSocket Market Data API v1 (https://docs.kucoin.com/#websocket-feed) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="kucoin",
    from_date="2023-02-01",
    to_date="2023-02-02",
    filters=[Channel(name="market/match", symbols=[])]
  )

  # messages as provided by Kucoin Spot real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'kucoin',
      from: '2023-02-01',
      to: '2023-02-02',
      filters: [{ channel: 'market/match', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Kucoin Spot real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g https://api.tardis.dev/v1/data-feeds/kucoin?from=2023-02-01&filters=[{%22channel%22:%22market/match%22,%22symbols%22:[]}]&offset=23
```

/$[https://api.tardis.dev/v1/data-feeds/kucoin?from=2023-02-01&filters=[{%22channel%22:%22market/match%22,%22symbols%22:[]}]&offset=23api.tardis.dev](https://api.tardis.dev/v1/data-feeds/kucoin?from=2023-02-01&filters=[{%22channel%22:%22market/match%22,%22symbols%22:[]}]&offset=23)Example API response for Kucoin historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"kucoin","filters":[{"channel":"market/match","symbols":[]}],"from":"2023-02-01","to":"2023-02-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Introduction - KUCOIN APIdocs.kucoin.com](https://docs.kucoin.com/#websocket-feed)See Kucoin SpotAPI docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• market/ticker
• market/snapshot
• market/level2
• market/match
• market/level2Snapshot - channel with initial order book snapshot, uses request order book API to get it as described at https://docs.kucoin.com/#level-2-market-data

### Market data collection details
Market data collection infrastructure for Kucoin Spot is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

Kucoin Spot servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousWOO X](/historical-data-details/woo-x)[NextBlockchain.com](/historical-data-details/blockchain-com)Last updated 2 years ago

================================================================================

# Blockchain.com

Source: https://docs.tardis.dev/historical-data-details/blockchain-com
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Blockchain.com
Blockchain.com Exchange historical market data details - instruments, data coverage and data collection specifics

$Blockchain.com exchange historical data for all it's currency pairs is available since 2023-02-23.

[https://api.tardis.dev/v1/exchanges/blockchain-comapi.tardis.dev](https://api.tardis.dev/v1/exchanges/blockchain-com)See Blockchain.com exchange historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USD

2023-03-01

Download sample

incremental_book_L2

BTC-USD

2023-03-01

Download sample

quotes

BTC-USD

2023-03-01

Download sample

book_snapshot_25

BTC-USD

2023-03-01

Download sample

trades

SPOT

2023-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Blockchain.com Exchange WebSocket Market Data API v1 (https://exchange.blockchain.com/api/#websocket-api) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="blockchain-com",
    from_date="2023-03-01",
    to_date="2023-03-02",
    filters=[Channel(name="l2", symbols=[])]
  )

  # messages as provided by Blockchain.com exchange real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'blockchain-com',
      from: '2023-03-01',
      to: '2023-03-02',
      filters: [{ channel: 'l2', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Blockchain.com exchange real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g https://api.tardis.dev/v1/data-feeds/blockchain-com?from=2023-03-01&filters=[{%22channel%22:%22l2%22,%22symbols%22:[]}]&offset=23
```

/$[https://api.tardis.dev/v1/data-feeds/blockchain-com?from=2023-03-01&filters=[{%22channel%22:%22l2%22,%22symbols%22:[]}]&offset=23api.tardis.dev](https://api.tardis.dev/v1/data-feeds/blockchain-com?from=2023-03-01&filters=[{%22channel%22:%22l2%22,%22symbols%22:[]}]&offset=23)Example API response for Blockchain.com exchange historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"blockchain-com","filters":[{"channel":"l2","symbols":[]}],"from":"2023-03-01","to":"2023-03-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Blockchain.com Exchange | APIexchange.blockchain.com](https://exchange.blockchain.com/api/#websocket-api)See Blockchain.com exchange docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• l2
• l3
• ticker

### Market data collection details
Market data collection infrastructure for Blockchain.com exchange is located in GCP europe-west2 region (London, UK).

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousKucoin Spot](/historical-data-details/kucoin)[NextUpbit](/historical-data-details/upbit)Last updated 2 years ago

================================================================================

# Upbit

Source: https://docs.tardis.dev/historical-data-details/upbit
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Upbit
Upbit historical market data details - currency pairs, data coverage and data collection specifics

$Upbit exchange historical data for all it's currency pairs is available since 2021-03-03.

[https://api.tardis.dev/v1/exchanges/upbitapi.tardis.dev](https://api.tardis.dev/v1/exchanges/upbit)See Upbit historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

KRW-BTC

2021-09-01

Download sample

incremental_book_L2

KRW-BTC

2021-09-01

Download sample

quotes

KRW-BTC

2021-09-01

Download sample

book_snapshot 25

KRW-BTC

2021-09-01

Download sample

trades

SPOT

2021-08-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Upbit WebSocket Market Data API v1 (wss://api.upbit.com/websocket/v1) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="upbit",
    from_date="2021-09-01",
    to_date="2021-09-02",
    filters=[Channel(name="orderbook", symbols=["KRW-BTC"])]
  )

  # messages as provided by Upbit real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'upbit',
      from: '2021-09-01',
      to: '2021-09-02',
      filters: [{ channel: 'orderbook', symbols: ['KRW-BTC'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Upbit real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/upbit?from=2021-09-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22KRW-BTC%22]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/upbit?from=2021-09-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22KRW-BTC%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/upbit?from=2021-09-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22KRW-BTC%22]}]&offset=0)Example API response for Upbit historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"upbit","filters":[{"channel":"orderbook","symbols":["KRW-BTC"]}],"from":"2021-09-01","to":"2021-09-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[업비트 개발자 센터업비트 개발자 센터](https://docs.upbit.com/docs/upbit-quotation-websocket)See Upbit WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• orderbook
• ticker

### Market data collection details
Market data collection infrastructure for Upbit is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousBlockchain.com](/historical-data-details/blockchain-com)[NextPhemex](/historical-data-details/phemex)Last updated 2 years ago

================================================================================

# Phemex

Source: https://docs.tardis.dev/historical-data-details/phemex
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Phemex
Phemex historical market data details - available instruments, data coverage and data collection specifics

$Phemex historical data for all it's derivative instruments is available since 2020-03-17 (for spot markets since 2020-06-04).

[https://api.tardis.dev/v1/exchanges/phemexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/phemex)See Phemex historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2020-04-01

Download sample

incremental_book_L2

BTCUSD

2020-04-01

Download sample

quotes

BTCUSD

2019-04-01

Download sample

derivative_ticker

BTCUSD

2019-04-01

Download sample

trades

ETHUSD

2020-04-01

Download sample

incremental_book_L2

ETHUSD

2020-04-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Phemex WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="phemex",
    from_date="2020-04-01",
    to_date="2020-04-02",
    filters=[Channel(name="book", symbols=["BTCUSD"])]
  )

  # messages as provided by Phemex real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'phemex',
      from: '2020-04-01',
      to: '2020-04-02',
      filters: [{ channel: 'book', symbols: ['BTCUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Phemex real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/phemex?from=2020-04-01&filters=[{"channel":"book","symbols":["BTCUSD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/phemex?from=2020-04-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/phemex?from=2020-04-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0)Example API response for Phemex historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"phemex","filters":[{"channel":"book","symbols":["BTCUSD"]}],"from":"2020-04-01","to":"2020-04-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[GitHub - phemex/phemex-api-docs: Phemex Exchange Public API Reference DocumentGitHub](https://github.com/phemex/phemex-api-docs)See Phemex WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• book
• market24h
• spot_market24h - available since 2020-06-05

### Market data collection details
Market data collection infrastructure for Phemex since 2020-06-04 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

Phemex servers are located in AWS ap-southeast-1 region (Singapore, Asia Pacific).

/$[PreviousUpbit](/historical-data-details/upbit)[NextDelta](/historical-data-details/delta)Last updated 2 years ago

================================================================================

# Delta

Source: https://docs.tardis.dev/historical-data-details/delta
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Delta
Delta historical market data details - available instruments, data coverage and data collection specifics

$Delta exchange historical data for all it's instruments is available since 2020-03-30.

[https://api.tardis.dev/v1/exchanges/deltaapi.tardis.dev](https://api.tardis.dev/v1/exchanges/delta)See Delta historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2020-06-01

Download sample

incremental_book_L2

BTCUSD

2020-06-01

Download sample

quotes

BTCUSD

2020-06-01

Download sample

book_snapshot_25

BTCUSD

2020-06-01

Download sample

derivative_ticker

BTCUSD

2020-06-01

Download sample

trades

PERPETUALS

2020-06-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Delta Exchange WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="delta",
    from_date="2020-06-01",
    to_date="2020-06-02",
    filters=[Channel(name="l2_orderbook", symbols=["BTCUSD"])]
  )

  # messages as provided by Delta Exchange real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'delta',
      from: '2020-06-01',
      to: '2020-06-02',
      filters: [{ channel: 'l2_orderbook', symbols: ['BTCUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Delta Exchange real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/delta?from=2020-06-01&filters=[{"channel":"l2_orderbook","symbols":["BTCUSD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/delta?from=2020-06-01&filters=[{%22channel%22:%22l2_orderbook%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/delta?from=2020-06-01&filters=[{%22channel%22:%22l2_orderbook%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0)Example API response for Delta Exchange historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"delta","filters":[{"channel":"l2_orderbook","symbols":["BTCUSD"]}],"from":"2020-06-01","to":"2020-06-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Delta Exchange Apidocs.delta.exchange](https://docs.delta.exchange/#websocket-feed)See Delta Exchange WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• l2_orderbook
• recent_trade - available until 2020-10-14, after that trades are available via all_trades channel, this is due to change in Delta exchange API which discontinued recent_trade channel support, see https://docs.delta.exchange/#new-socket-channels
• recent_trade_snapshot - available until 2020-10-14
• all_trades - available from 2020-10-14
• mark_price
• spot_price
• funding_rate
• funding_rate_8h
• product_updates
• announcements
• v2/ticker - available from 2020-10-14

### Market data collection details
Market data collection infrastructure for Delta Exchange is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connection.

Delta exchange servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousPhemex](/historical-data-details/phemex)[NextAscendEX (BitMax)](/historical-data-details/ascendex)Last updated 2 years ago

================================================================================

# AscendEX (BitMax)

Source: https://docs.tardis.dev/historical-data-details/ascendex
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# AscendEX (BitMax)
AscendEX historical market data details - available instruments, data coverage and data collection specifics

$AscendEX exchange historical data for all it's instruments is available since 2021-03-28.

[https://api.tardis.dev/v1/exchanges/ascendexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/ascendex)See AscendEX historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-PERP

2023-03-01

Download sample

incremental_book_L2

BTC-PERP

2023-03-01

Download sample

quotes

BTC-USDT

2023-03-01

Download sample

book_snapshot_25

BTC-USDT

2023-03-01

Download sample

derivative_ticker

BTC-PERP

2023-03-01

Download sample

trades

PERPETUALS

2023-03-01

Download sample

book_ticker

BTC-PERP

2023-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time AscendEX Exchange WebSocket API v2 (https://ascendex.github.io/ascendex-futures-pro-api-v2/#websocket) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="ascendex",
    from_date="2023-03-01",
    to_date="2023-03-02",
    filters=[Channel(name="trades", symbols=["BTC-PERP"])]
  )

  # messages as provided by Ascendex real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'ascendex',
      from: '2023-03-01',
      to: '2023-03-02',
      filters: [{ channel: 'trades', symbols: ['BTC-PERP'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Ascendex real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/ascendex?from=2023-03-01&filters=[{%22channel%22:%22trades%22,%22symbols%22:[%22BTC-PERP%22]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/ascendex?from=2023-03-01&filters=[{%22channel%22:%22trades%22,%22symbols%22:[%22BTC-PERP%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/ascendex?from=2023-03-01&filters=[{%22channel%22:%22trades%22,%22symbols%22:[%22BTC-PERP%22]}]&offset=0)Example API response for Ascendex exchange historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"ascendex","filters":[{"channel":"trades","symbols":["BTC-PERP"]}],"from":"2023-03-01","to":"2023-03-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[AscendEX Futures API Referenceascendex.github.io](https://ascendex.github.io/ascendex-futures-pro-api-v2/#websocket)See AscendEX Exchange WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• depth-realtime
• depth-snapshot-realtime
• bbo
• futures-pricing-data

### Market data collection details
Market data collection infrastructure for AscendEX is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connection.

AscendEX servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousDelta](/historical-data-details/delta)[NextFTX US](/historical-data-details/ftx-us)Last updated 2 years ago

================================================================================

# FTX US

Source: https://docs.tardis.dev/historical-data-details/ftx-us
Extraction Method: playwright
Components: code_block(7)

Copy
1. Historical Data Details

# FTX US
FTX US historical market data details - available currency pairs, data coverage and data collection specifics

$Delisted exchange.

FTX US historical data for all it's currency pairs is available since 2020-05-22 until 2022-11-13.

[https://api.tardis.dev/v1/exchanges/ftx-usapi.tardis.dev](https://api.tardis.dev/v1/exchanges/ftx-us)See FTX US historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USD

2020-06-01

Download sample

incremental_book_L2

BTC-USD

2020-06-01

Download sample

quotes

BTC-USD

2020-06-01

Download sample

trades

SPOT

2020-06-01

Download sample

#### How to download all FTX US datasets for all instruments
See full downloadable CSV files documentation with datasets format spec, data samples and more.

PythonNode.jscURL$Copy
```
# requires Python >=3.6
# pip install tardis-dev

from tardis_dev import datasets, get_exchange_details
import logging

# optionally enable debug logs
# logging.basicConfig(level=logging.DEBUG)

exchange = 'ftx-us'
exchange_details = get_exchange_details(exchange)   

# iterate over and download all data for every symbol
for symbol in exchange_details["datasets"]["symbols"]:
    # alternatively specify datatypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    # see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    data_types = symbol["dataTypes"]  
    symbol_id = symbol["id"]
    from_date =  symbol["availableSince"]
    to_date = symbol["availableTo"]

    # skip groupped symbols
    if symbol_id in ['PERPETUALS', 'SPOT', 'FUTURES']:
        continue

    print(f"Downloading {exchange} {data_types} for {symbol_id} from {from_date} to {to_date}")

    # each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    # see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    datasets.download(
        exchange = exchange,
        data_types = data_types,
        from_date =  from_date,
        to_date = to_date,
        symbols = [symbol_id],
        # TODO set your API key here
        api_key = "YOUR_API_KEY",
        # path where CSV data will be downloaded into
        download_dir = "./datasets",
    )
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
// npm install tardis-dev
// requires node version >=12
const { downloadDatasets, getExchangeDetails } = require('tardis-dev')

;(async () => {
  const exchange = 'ftx-us'
  const exchangeDetails = await getExchangeDetails(exchange)

  // iterate over and download all data for every symbol
  for (const symbol of exchangeDetails.datasets.symbols) {
    // alternatively specify dataTypes explicitly ['trades', 'incremental_book_L2', 'quotes'] etc
    // see available options https://docs.tardis.dev/downloadable-csv-files#data-types
    const dataTypes = symbol.dataTypes
    const symbolId = symbol.id

    const from = symbol.availableSince
    const to = symbol.availableTo

    // skip groupped symbols
    if (['PERPETUALS', 'SPOT', 'FUTURES'].includes(symbolId)) {
      continue
    }

    console.log(`Downloading ${exchange} ${dataTypes} for ${symbolId} from ${from} to ${to}`)

    // each CSV dataset format is documented at https://docs.tardis.dev/downloadable-csv-files#data-types
    // see https://docs.tardis.dev/downloadable-csv-files#download-via-client-libraries for full options docs
    await downloadDatasets({
      exchange,
      dataTypes,
      from,
      to,
      symbols: [symbolId],
      // TODO: set your API key here
      apiKey: 'YOUR_API_KEY',
      //  path where CSV data will be downloaded into
      downloadDir: './datasets'
    })
  }
})()
```

/$See docs that shows all available download options (download path customization, filenames conventions and more).

$Copy
```
curl -o ftx_us_trades_2021-11-01_BTC-USD.csv.gz https://datasets.tardis.dev/v1/ftx-us/trades/2021/11/01/BTC-USD.csv.gz
```

/$See datasets API reference which allows downloading single file at once.

### API Access and data format
Historical data format is the same as provided by real-time FTX US WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="ftx-us",
    from_date="2020-06-01",
    to_date="2020-06-02",
    filters=[Channel(name="orderbook", symbols=["BTC/USD"])]
  )

  # messages as provided by FTX US real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'ftx-us',
      from: '2020-06-01',
      to: '2020-06-02',
      filters: [{ channel: 'orderbook', symbols: ['BTC/USD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by FTX US real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/ftx-us?from=2020-06-01&filters=[{"channel":"orderbook","symbols":["BTC/USD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/ftx-us?from=2020-06-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22BTC/USD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/ftx-us?from=2020-06-01&filters=[{%22channel%22:%22orderbook%22,%22symbols%22:[%22BTC/USD%22]}]&offset=0)Example API response for FTX US historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"ftx-us","filters":[{"channel":"orderbook","symbols":["BTC/USD"]}],"from":"2020-06-01","to":"2020-06-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[FTXFTX](https://docs.ftx.us/#websocket-api)See FTX US WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• orderbook
• trades
• markets
• orderbookGrouped - available since 2020-07-21
Asorderbook channel provides data only about the orderbook's best 100 orders on either side, grouped orderbooks channel supplies orderbook data with grouped (collapsed) prices allowing retrieving lower-granularity, higher-depth information about the orderbook. 
We set grouping param to currency pairs' priceIncrement value multiplied by 10.

### Market data collection details
Market data collection infrastructure for FTX US is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousAscendEX (BitMax)](/historical-data-details/ascendex)[NextBinance US](/historical-data-details/binance-us)Last updated 2 years ago

================================================================================

# Binance US

Source: https://docs.tardis.dev/historical-data-details/binance-us
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Binance US
Binance US  historical market data details - currency pairs, data coverage and data collection specifics

$Binance US exchange historical data for all it's currency pairs is available since 2019-09-25.

[https://api.tardis.dev/v1/exchanges/binance-usapi.tardis.dev](https://api.tardis.dev/v1/exchanges/binance-us)See Binance US historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD

2019-12-01

Download sample

incremental_book_L2

BTCUSD

2019-12-01

Download sample

quotes

BTCUSD

2019-12-01

Download sample

trades

ETHUSD

2020-03-01

Download sample

incremental_book_L2

ETHUSD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Binance US WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="binance-us",
    from_date="2019-12-01",
    to_date="2019-12-02",
    filters=[Channel(name="depth", symbols=["bnbusd"])]
  )

  # messages as provided by Binance US real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'binance-us',
      from: '2019-12-01',
      to: '2019-12-02',
      filters: [{ channel: 'depth', symbols: ['bnbusd'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Binance US real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/binance-us?from=2019-12-01&filters=[{"channel":"depth","symbols":["bnbusd"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/binance-us?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22bnbusd%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/binance-us?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22bnbusd%22]}]&offset=0)Example API response for Binance US historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"binance-us","filters":[{"channel":"depth","symbols":["bnbusd"]}],"from":"2019-12-01","to":"2019-12-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[GitHub - binance-us/binance-us-api-docs: Official Documentation for the Binance US APIs and StreamsGitHub](https://github.com/binance-us/binance-official-api-docs)See Binance US WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• aggTrade - available since 2019-11-19
• ticker
• bookTicker
• depth
• depthSnapshot - generated channel with full order book snapshots
Binance US real-time WebSocket API does not provide initial order book snapshots . To overcome this issue we fetch initial order book snapshots from REST API and store them together with the  rest of the WebSocket messages - top 1000 levels. Such snapshot messages are marked with "stream":"<symbol>@depthSnapshot" and "generated":true  fields. 
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by real-time feed (U and u fields) - in case of detecting missed message WebSocket connection is being restarted. We also validate if initial book snapshot fetched from REST API overlaps with received depth messages.

### Market data collection details
Market data collection infrastructure for Binance US is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousFTX US](/historical-data-details/ftx-us)[NextGate.io Futures](/historical-data-details/gate-io-futures)Last updated 2 years ago

================================================================================

# Gate.io Futures

Source: https://docs.tardis.dev/historical-data-details/gate-io-futures
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Gate.io Futures
Gate.io Futures historical market data details - available instruments, data coverage and data collection specifics

$Gate.io Futures historical data for all it's instruments is available since 2020-07-01.

[https://api.tardis.dev/v1/exchanges/gate-io-futuresapi.tardis.dev](https://api.tardis.dev/v1/exchanges/gate-io-futures)See Gate.io Futures historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC_USDT

2020-07-01

Download sample

incremental_book_L2

BTC_USDT

2020-07-01

Download sample

quotes

BTC_USDT

2020-07-01

Download sample

derivative_ticker

BTC_USDT

2020-07-01

Download sample

trades

PERPETUALS

2020-07-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Gate.io Futures WebSocket v4 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="gate-io-futures",
    from_date="2020-07-01",
    to_date="2020-07-02",
    filters=[Channel(name="order_book", symbols=["BTC_USDT"])]
  )

  # messages as provided by Gate.io Futures real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'gate-io-futures',
      from: '2020-07-01',
      to: '2020-07-02',
      filters: [{ channel: 'order_book', symbols: ['BTC_USDT'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Gate.io Futures real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/gate-io-futures?from=2020-07-01&filters=[{"channel":"order_book","symbols":["BTC_USDT"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/gate-io-futures?from=2020-07-01&filters=[{%22channel%22:%22order_book%22,%22symbols%22:[%22BTC_USDT%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/gate-io-futures?from=2020-07-01&filters=[{%22channel%22:%22order_book%22,%22symbols%22:[%22BTC_USDT%22]}]&offset=0)Example API response for Gate.io Futures historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"gate-io-futures","filters":[{"channel":"order_book","symbols":["BTC_USDT"]}],"from":"2020-07-01","to":"2020-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Gate.io Futures WebSocket v4 | Gate API v4www.gate.io](https://www.gate.io/docs/futures/ws/index.html#changelog)See Gate.io Futures WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• order_book (limit=20, interval="0")
• tickers

### Market data collection details
Market data collection infrastructure for Gate.io Futures is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

Gate.io Futures servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousBinance US](/historical-data-details/binance-us)[NextGate.io](/historical-data-details/gate-io)Last updated 2 years ago

================================================================================

# Gate.io

Source: https://docs.tardis.dev/historical-data-details/gate-io
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Gate.io
Gate.io historical market data details - currency pairs, data coverage and data collection specifics

$Gate.io historical data for high caps currency pairs is available since 2020-07-01, data for all currency pairs is available since 2022-06-09.

[https://api.tardis.dev/v1/exchanges/gate-ioapi.tardis.dev](https://api.tardis.dev/v1/exchanges/gate-io)See Gate.io historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC_USDT

2020-07-01

Download sample

incremental_book_L2

BTC_USDT

2020-07-01

Download sample

quotes

BTC_USDT

2020-07-01

Download sample

book_snapshot_25

BTC_USDT

2020-07-01

Download sample

trades

SPOT

2020-07-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Gate.io WebSocket v3 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="gate-io",
    from_date="2020-07-01",
    to_date="2020-07-02",
    filters=[Channel(name="depth", symbols=["BTC_USDT"])]
  )

  # messages as provided by Gate.io real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'gate-io',
      from: '2020-07-01',
      to: '2020-07-02',
      filters: [{ channel: 'depth', symbols: ['BTC_USDT'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Gate.io real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/gate-io?from=2020-07-01&filters=[{"channel":"depth","symbols":["BTC_USDT"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/gate-io?from=2020-07-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC_USDT%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/gate-io?from=2020-07-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22BTC_USDT%22]}]&offset=0)Example API response for Gate.io historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"gate-io","filters":[{"channel":"depth","symbols":["BTC_USDT"]}],"from":"2020-07-01","to":"2020-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Gate WebSocketAPI Referencewww.gate.io](https://www.gate.io/docs/websocket/index.html)See Gate.io WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• depth (limit=30, interval="0")
• ticker

### Market data collection details
Market data collection infrastructure for Gate.io is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

Gate.io servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousGate.io Futures](/historical-data-details/gate-io-futures)[NextBitnomial](/historical-data-details/bitnomial)Last updated 2 years ago

================================================================================

# Bitnomial

Source: https://docs.tardis.dev/historical-data-details/bitnomial
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Bitnomial
Bitnomial historical market data details - instruments, data coverage and data collection specifics

$Bitnomial exchange historical data for all it's instruments is available since 2023-01-13.

[https://api.tardis.dev/v1/exchanges/bitnomialapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bitnomial)See Bitnomial exchange historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BUIH23

2023-03-01

Download sample

incremental_book_L2

BUIH23

2023-03-01

Download sample

quotes

BUIH23

2023-03-01

Download sample

book_snapshot_25

BUIH23

2023-03-01

Download sample

trades

FUTURES

2023-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Bitnomial WebSocket Market Data API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bitnomial",
    from_date="2023-03-01",
    to_date="2023-03-02",
    filters=[Channel(name="trade", symbols=[])]
  )

  # messages as provided by Bitnomial exchange real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bitnomial',
      from: '2023-03-01',
      to: '2023-03-02',
      filters: [{ channel: 'trade', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Bitnomial exchange real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g https://api.tardis.dev/v1/data-feeds/bitnomial?from=2023-03-01&filters=[{%22channel%22:%22level%22,%22symbols%22:[]}]&offset=1000
```

/$[https://api.tardis.dev/v1/data-feeds/bitnomial?from=2023-03-01&filters=[{%22channel%22:%22level%22,%22symbols%22:[]}]&offset=1000api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bitnomial?from=2023-03-01&filters=[{%22channel%22:%22level%22,%22symbols%22:[]}]&offset=1000)Example API response for Bitnomial exchange historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bitnomial","filters":[{"channel":"level","symbols":[]}],"from":"2023-03-01","to":"2023-03-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
Click any channel below to see HTTP API response with historical data recorded for it.

• trade
• level
• book
• block
• status

### Market data collection details
Market data collection infrastructure for Bitnomial exchange is located in GCP europe-west2 region (London, UK).

Real-time market data is captured via multiple WebSocket connections.

Bitnomial servers are located in AWS us-east-2 region (US East, Ohio, USA).

/$[PreviousGate.io](/historical-data-details/gate-io)[NextCrypto.com](/historical-data-details/crypto-com)Last updated 2 years ago

================================================================================

# Crypto.com

Source: https://docs.tardis.dev/historical-data-details/crypto-com
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Crypto.com
Crypto.com exchange historical market data details - instruments, data coverage and data collection specifics

$Crypto.com exchange historical data for all it's instruments is available since 2022-06-01.

[https://api.tardis.dev/v1/exchanges/crypto-comapi.tardis.dev](https://api.tardis.dev/v1/exchanges/crypto-com)See Crypto.com exchange historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCUSD-PERP

2023-03-01

Download sample

incremental_book_L2

BTCUSD-PERP

2023-03-01

Download sample

quotes

BTCUSD-PERP

2023-03-01

Download sample

book_ticker

BTCUSD-PERP

2023-03-01

Download sample

book_snapshot_25

BTCUSD-PERP

2023-03-01

Download sample

derivative_ticker

BTCUSD-PERP

2023-03-01

Download sample

trades

PERPETUALS

2023-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Crypto.com Exchange WebSocket Market Data API v2 (https://exchange-docs.crypto.com/spot/index.html#websocket-subscriptions) with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="crypto-com",
    from_date="2023-03-01",
    to_date="2023-03-02",
    filters=[Channel(name="book", symbols=[])]
  )

  # messages as provided by Crypto.com exchange real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'crypto-com',
      from: '2023-03-01',
      to: '2023-03-02',
      filters: [{ channel: 'book', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Crypto.com exchange real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g https://api.tardis.dev/v1/data-feeds/crypto-com?from=2023-03-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[]}]&offset=0
```

/$[https://api.tardis.dev/v1/data-feeds/crypto-com?from=2023-03-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/crypto-com?from=2023-03-01&filters=[{%22channel%22:%22book%22,%22symbols%22:[]}]&offset=0)Example API response for Crypto.com exchange historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"crypto-com","filters":[{"channel":"book","symbols":[]}],"from":"2023-03-01","to":"2023-03-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://exchange-docs.crypto.com/spot/index.html#websocket-subscriptionsexchange-docs.crypto.com](https://exchange-docs.crypto.com/spot/index.html#websocket-subscriptions)See Crypto.com exchange docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• book
• ticker
• settlement
• index
• mark
• funding

### Market data collection details
Market data collection infrastructure for Crypto.com exchange is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousBitnomial](/historical-data-details/bitnomial)[NextOKCoin](/historical-data-details/okcoin)Last updated 2 years ago

================================================================================

# OKCoin

Source: https://docs.tardis.dev/historical-data-details/okcoin
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# OKCoin
OKCoin historical market data details - available instruments, data coverage and data collection specifics

$OKCoin historical data for all it's currency pairs is available since 2019-11-19.

[https://api.tardis.dev/v1/exchanges/okcoinapi.tardis.dev](https://api.tardis.dev/v1/exchanges/okcoin)See OKCoin historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTC-USD

2020-01-01

Download sample

incremental_book_L2

BTC-USD

2020-01-01

Download sample

quotes

BTC-USD

2020-01-01

Download sample

trades

ETH-USD

2020-03-01

Download sample

incremental_book_L2

ETH-USD

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time OKCoin WebSocket v3 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="okcoin",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="spot/trade", symbols=["BTC-USD"])]
  )

  # messages as provided by OKCoin real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'okcoin',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'spot/trade', symbols: ['BTC-USD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by OKCoin real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/okcoin?from=2020-01-01&filters=[{"channel":"spot/trade","symbols":[]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/okcoin?from=2020-01-01&filters=[{%22channel%22:%22spot/trade%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/okcoin?from=2020-01-01&filters=[{%22channel%22:%22spot/trade%22,%22symbols%22:[]}]&offset=0)Example API response for OKCoin historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"okcoin","filters":[{"channel":"spot/trade","symbols":["BTC-USD"]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Okcoin Developer Documentation | Okcoin Official Website | Okcoinwww.okcoin.com](https://www.okcoin.com/docs/en/#spot_ws-general)See OKCoin WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• spot/trade
• spot/ticker
• spot/depth  - available until 2020-02-17
• spot/depth_l2_tbt - available since 2020-02-13

### Market data collection details
Market data collection infrastructure for OKCoin since 2020-05-15 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via multiple WebSocket connections.

OKCoin servers are located in Alibaba Cloud cn-hongkong region (Hong Kong, China).

/$[PreviousCrypto.com](/historical-data-details/crypto-com)[NextbitFlyer](/historical-data-details/bitflyer)Last updated 2 years ago

================================================================================

# bitFlyer

Source: https://docs.tardis.dev/historical-data-details/bitflyer
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# bitFlyer
bitFlyer historical market data details - available instruments, data coverage and data collection specifics

$BitFlyer historical data for all it's instruments is available since 2019-08-30.

[https://api.tardis.dev/v1/exchanges/bitflyerapi.tardis.dev](https://api.tardis.dev/v1/exchanges/bitflyer)See bitFlyer historical data coverage: available symbols, channels, date ranges and incidentsReal-time market data provided by bitFlyer exchange isn't always the most reliable and clean, especially during market volatility periods (crossed order books, delayed trade data).

### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

FX_BTC_JPY

2020-01-01

Download sample

incremental_book_L2

FX_BTC_JPY

2020-01-01

Download sample

quotes

FX_BTC_JPY

2020-01-01

Download sample

trades

FUTURES

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time bitFlyer lightning JSON-RPC 2.0 over WebSocket  API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="bitflyer",
    from_date="2020-01-01",
    to_date="2020-02-02",
    filters=[Channel(name="lightning_executions", symbols=["FX_BTC_JPY"])]
  )

  # messages as provided by bitFlyer real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'bitflyer',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'lightning_executions', symbols: ['FX_BTC_JPY'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by bitFlyer real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/bitflyer?from=2020-01-01&filters=[{"channel":"lightning_executions","symbols":["FX_BTC_JPY"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/bitflyer?from=2020-01-01&filters=[{%22channel%22:%22lightning_executions%22,%22symbols%22:[%22FX_BTC_JPY%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/bitflyer?from=2020-01-01&filters=[{%22channel%22:%22lightning_executions%22,%22symbols%22:[%22FX_BTC_JPY%22]}]&offset=0)Example API response for bitFlyer historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"bitflyer","filters":[{"channel":"lightning_executions","symbols":["FX_BTC_JPY"]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Bitcoin Exchange - bitFlyer Lightninglightning.bitflyer.com](https://lightning.bitflyer.com/docs?lang=en#json-rpc-2.0-over-websocket)See bitFlyer WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• lightning_executions
• lightning_ticker
• lightning_board
• lightning_board_snapshot
lightning_board_snapshot channel is subscribed only in order to get initial order book snapshot, after that it's automatically unsubscribed as all order book update are being provided via lightning_board channel.

### Market data collection details
Market data collection infrastructure for bitFlyer since 2020-05-28 is located in GCP asia-northeast1 (Tokyo, Japan), before that it was located in GCP europe-west2 region (London, UK).  

Real-time market data is captured via single WebSocket connection.

Bitflyer servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousOKCoin](/historical-data-details/okcoin)[NextHitBTC (high caps)](/historical-data-details/hitbtc)Last updated 2 years ago

================================================================================

# HitBTC (high caps)

Source: https://docs.tardis.dev/historical-data-details/hitbtc
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# HitBTC (high caps)
HitBTC historical market data details - currency pairs, data coverage and data collection specifics

$HitBTC historical data for high caps currency pairs is available since 2019-11-19.

[https://api.tardis.dev/v1/exchanges/hitbtcapi.tardis.dev](https://api.tardis.dev/v1/exchanges/hitbtc)See HitBTC historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Not available.

### API Access and data format
Historical data format is the same as provided by real-time HitBTC WebSocket v2 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that can perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="hitbtc",
    from_date="2020-01-01",
    to_date="2020-01-02",
    filters=[Channel(name="updateOrderbook", symbols=["BTCUSD"])]
  )

  # messages as provided by HitBTC real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'hitbtc',
      from: '2020-01-01',
      to: '2020-01-02',
      filters: [{ channel: 'updateOrderbook', symbols: ['BTCUSD'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by HitBTC real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/hitbtc?from=2020-01-01&filters=[{"channel":"updateOrderbook","symbols":["BTCUSD"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/hitbtc?from=2020-01-01&filters=[{%22channel%22:%22updateOrderbook%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/hitbtc?from=2020-01-01&filters=[{%22channel%22:%22updateOrderbook%22,%22symbols%22:[%22BTCUSD%22]}]&offset=0)Example API response for HitBTC historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"hitbtc","filters":[{"channel":"updateOrderbook","symbols":["BTCUSD"]}],"from":"2020-01-01","to":"2020-01-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[API Documentationapi.hitbtc.com](https://api.hitbtc.com/#socket-market-data)See HitBTC WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• snapshotTrades
• updateTrades
• snapshotOrderbook
• updateOrderbook

### Market data collection details
Market data collection infrastructure for HitBTC is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via single WebSocket connection.

/$[PreviousbitFlyer](/historical-data-details/bitflyer)[NextCoinFLEX (2.0)](/historical-data-details/coinflex)Last updated 5 years ago

================================================================================

# CoinFLEX (2.0)

Source: https://docs.tardis.dev/historical-data-details/coinflex
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# CoinFLEX (2.0)
CoinFLEX 2.0 historical market data details - instruments, data coverage and data collection specifics

$CoinFLEX historical data for all it's instruments is available since 2020-07-14.

[https://api.tardis.dev/v1/exchanges/coinflexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/coinflex)See CoinFLEX historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
data type

symbol

date

trades

BTC-USD-SWAP-LIN

2020-08-01

Download sample

incremental_book_L2

BTC-USD-SWAP-LIN

2020-08-01

Download sample

quotes

BTC-USD-SWAP-LIN

2020-08-01

Download sample

derivative_ticker

BTC-USD-SWAP-LIN

2020-08-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time CoinFLEX WebSocket v2 API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="coinflex",
    from_date="2020-08-01",
    to_date="2020-08-02",
    filters=[Channel(name="futures/depth", symbols=["BTC-USD-SWAP-LIN"])]
  )

  # messages as provided by CoinFLEX 2.0 real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'coinflex',
      from: '2020-08-01',
      to: '2020-08-02',
      filters: [{ channel: 'futures/depth', symbols: ['BTC-USD-SWAP-LIN'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by CoinFLEX 2.0 real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/coinflex?from=2020-08-01&filters=[{"channel":"futures/depth","symbols":["BTC-USD-SWAP-LIN"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/coinflex?from=2020-08-01&filters=[{%22channel%22:%22futures/depth%22,%22symbols%22:[%22BTC-USD-SWAP-LIN%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/coinflex?from=2020-08-01&filters=[{%22channel%22:%22futures/depth%22,%22symbols%22:[%22BTC-USD-SWAP-LIN%22]}]&offset=0)Example API response for CoinFLEX historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"coinflex","filters":[{"channel":"futures/depth","symbols":["BTC-USD-SWAP-LIN"]}],"from":"2020-08-01","to":"2020-08-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[https://docs.coinflex.com/v2/#websocket-apidocs.coinflex.com](https://docs.coinflex.com/v2/#websocket-api)See CoinFLEX 2.0 WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• futures/depth
• ticker

### Market data collection details
Market data collection infrastructure for CoinFlex 2.0 is located in GCP asia-northeast1 (Tokyo, Japan).

Real-time market data is captured via single WebSocket connection.

CoinFLEX 2.0 servers are located in AWS ap-northeast-1 region (Tokyo, Japan).

/$[PreviousHitBTC (high caps)](/historical-data-details/hitbtc)[NextBinance Jersey](/historical-data-details/binance-jersey)Last updated 2 years ago

================================================================================

# Binance Jersey

Source: https://docs.tardis.dev/historical-data-details/binance-jersey
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Binance Jersey
Binance Jersey historical market data details - currency pairs, data coverage and data collection specifics

$Delisted exchange.

Binance Jersey exchange historical data for all it's currency pairs is available since 2019-10-30 until 2020-11-10.

[https://api.tardis.dev/v1/exchanges/binance-jerseyapi.tardis.dev](https://api.tardis.dev/v1/exchanges/binance-jersey)See Binance Jersey historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

BTCEUR

2019-12-01

Download sample

incremental_book_L2

BTCEUR

2019-12-01

Download sample

quotes

BTCEUR

2019-12-01

Download sample

trades

ETHEUR

2020-03-01

Download sample

incremental_book_L2

ETHEUR

2020-03-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Binance Jersey WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="binance-jersey",
    from_date="2019-12-01",
    to_date="2019-12-02",
    filters=[Channel(name="depth", symbols=["btcgbp"])]
  )

  # messages as provided by Binance Jersey real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'binance-jersey',
      from: '2019-12-01',
      to: '2019-12-02',
      filters: [{ channel: 'depth', symbols: ['btcgbp'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Binance Jersey real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/binance-jersey?from=2019-12-01&filters=[{"channel":"depth","symbols":["btcgbp"]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/binance-jersey?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcgbp%22]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/binance-jersey?from=2019-12-01&filters=[{%22channel%22:%22depth%22,%22symbols%22:[%22btcgbp%22]}]&offset=0)Example API response for Binance Jersey historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"binance-jersey","filters":[{"channel":"depth","symbols":["btcgbp"]}],"from":"2019-12-01","to":"2019-12-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[GitHub - binance-jersey/binance-official-api-docs: Official Documentation for the Binance APIs and StreamsGitHub](https://github.com/binance-jersey/binance-official-api-docs)See Binance Jersey WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trade
• aggTrade - available since 2019-11-19
• ticker
• bookTicker
• depth
• depthSnapshot  - generated channel with full order book snapshots
Binance Jersey real-time WebSocket API does not provide initial order book snapshots . To overcome this issue we fetch initial order book snapshots from REST API and store them together with the  rest of the WebSocket messages - top 1000 levels. Such snapshot messages are marked with "stream":"<symbol>@depthSnapshot" and "generated":true  fields. 
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by real-time feed (U and u fields) - in case of detecting missed message WebSocket connection is being restarted. We also validate if initial book snapshot fetched from REST API overlaps with received depth messages.
• recentTrades - generated channel, available since 2020-05-19
After establishing successful real-time WebSocket connection we fetch last 1000 trades from REST API and store that info together with other captured WebSocket messages. Such messages are marked with "stream":"<symbol>@recentTrades" and "generated":true  fields and data field has the same format as REST API response.

### Market data collection details
Market data collection infrastructure for Binance Jersey is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via single WebSocket connection.

/$[PreviousCoinFLEX (2.0)](/historical-data-details/coinflex)[NextBinance DEX](/historical-data-details/binance-dex)Last updated 2 years ago

================================================================================

# Binance DEX

Source: https://docs.tardis.dev/historical-data-details/binance-dex
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Binance DEX
Binance DEX  historical market data details - currency pairs, data coverage and data collection specifics

$Delisted exchange.

Binance DEX exchange historical data for all it's currency pairs is available since 2019-06-04 until 2022-10-04.

[https://api.tardis.dev/v1/exchanges/binance-dexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/binance-dex)See Binance DEX historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Not available.

### API Access and data format
Historical data format is the same as provided by real-time Binance DEX WebSocket API with addition of local timestamps. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="binance-dex",
    from_date="2019-12-01",
    to_date="2019-12-02",
    filters=[Channel(name="marketDiff", symbols=[])]
  )

  # messages as provided by Binance DEX real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'binance-dex',
      from: '2019-12-01',
      to: '2019-12-02',
      filters: [{ channel: 'marketDiff', symbols: [] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Binance DEX real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/binance-dex?from=2019-12-01&filters=[{"channel":"marketDiff","symbols":[]}]&offset=0'
```

/$[https://api.tardis.dev/v1/data-feeds/binance-dex?from=2019-12-01&filters=[{%22channel%22:%22marketDiff%22,%22symbols%22:[]}]&offset=0api.tardis.dev](https://api.tardis.dev/v1/data-feeds/binance-dex?from=2019-12-01&filters=[{%22channel%22:%22marketDiff%22,%22symbols%22:[]}]&offset=0)Example API response for Binance DEX historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"binance-dex","filters":[{"channel":"marketDiff","symbols":[]}],"from":"2019-12-01","to":"2019-12-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[BNB Chaindocs.binance.org](https://docs.binance.org/api-reference/dex-api/ws-streams.html)See Binance DEX WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• trades
• marketDiff
• depthSnapshot - generated channel with full order book snapshots

Binance DEX real-time WebSocket API does not provide initial order book snapshots . To overcome this issue we fetch initial order book snapshots from REST API and store them together with the  rest of the WebSocket messages - top 1000 levels. Such snapshot messages are marked with "stream":"<symbol>@depthSnapshot" and "generated":true  fields.

### Market data collection details
Market data collection infrastructure for Binance DEX is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

/$[PreviousBinance Jersey](/historical-data-details/binance-jersey)[NextPoloniex](/historical-data-details/poloniex)Last updated 2 years ago

================================================================================

# Poloniex

Source: https://docs.tardis.dev/historical-data-details/poloniex
Extraction Method: playwright
Components: code_block(4)

Copy
1. Historical Data Details

# Poloniex
Poloniex historical market data details - currency pairs, data coverage and data collection specifics

$Poloniex exchange historical data for all it's currency pairs is available since 2020-07-01.

[https://api.tardis.dev/v1/exchanges/poloniexapi.tardis.dev](https://api.tardis.dev/v1/exchanges/poloniex)See Poloniex historical data coverage: available symbols, channels, date ranges and incidents
### Downloadable CSV files
Historical CSV datasets for the first day of each month are available to download without API key. 
See downloadable CSV files documentation.

data type

symbol

date

trades

USDT_BTC

2020-07-01

Download sample

incremental_book_L2

USDT_BTC

2020-07-01

Download sample

quotes

USDT_BTC

2020-07-01

Download sample

trades

SPOT

2020-07-01

Download sample

### API Access and data format
Historical data format is the same as provided by real-time Poloniex WebSocket v2 API with addition of local timestamps and also with addition of symbol at the end of each message which allows us providing filtering for the data server-side. If you'd like to work with normalized data format instead (same format for each exchange) see downloadable CSV files or official client libs that perform data normalization client-side.

PythonNode.jscURL & HTTP APIcURL & tardis-machine$Copy
```
# pip install tardis-client
import asyncio
from tardis_client import TardisClient, Channel
tardis_client = TardisClient(api_key="YOUR_API_KEY")

async def replay():
  # replay method returns Async Generator
  messages = tardis_client.replay(
    exchange="poloniex",
    from_date="2020-07-01",
    to_date="2020-07-02",
    filters=[Channel(name="price_aggregated_book", symbols=["USDT_BTC"])]
  )

  # messages as provided by Poloniex real-time stream
  async for local_timestamp, message in messages:
    print(message)

asyncio.run(replay())
```

/$See Python client docs.

$Copy
```
// npm install tardis-dev
const { replay } = require('tardis-dev');

async function run() {
  try {
    const messages = replay({
      exchange: 'poloniex',
      from: '2020-07-01',
      to: '2020-07-02',
      filters: [{ channel: 'price_aggregated_book', symbols: ['USDT_BTC'] }],
      apiKey: 'YOUR_API_KEY'
    });

    // messages as provided by Poloniex real-time stream
    for await (const { localTimestamp, message } of messages) {
      console.log(localTimestamp, message);
    }
  } catch (e) {
    console.error(e);
  }
}

run();
```

/$See Node.js client docs.

$Copy
```
curl -g 'https://api.tardis.dev/v1/data-feeds/poloniex?from=2020-07-01&filters=[{"channel":"price_aggregated_book","symbols":["USDT_BTC"]}]'
```

/$[https://api.tardis.dev/v1/data-feeds/poloniex?from=2020-07-01&filters=[{%22channel%22:%22price_aggregated_book%22,%22symbols%22:[%22USDT_BTC%22]}]api.tardis.dev](https://api.tardis.dev/v1/data-feeds/poloniex?from=2020-07-01&filters=[{%22channel%22:%22price_aggregated_book%22,%22symbols%22:[%22USDT_BTC%22]}])Example API response for Poloniex historical market data requestSee HTTP API docs.

$Copy
```
curl -g 'localhost:8000/replay?options={"exchange":"poloniex","filters":[],"from":"2020-07-01","to":"2020-07-02"}'
```

/$Tardis-machine is a locally runnable server that exposes API allowing efficiently requesting historical market data for whole time periods in contrast to HTTP API that provides data only in minute by minute slices.

See tardis-machine docs.

### Captured real-time channels
[Poloniex APIdocs.poloniex.com](https://docs.poloniex.com/#websocket-api)See Poloniex WebSocket API docs providing documentation for each captured channel's formatClick any channel below to see HTTP API response with historical data recorded for it.

• price_aggregated_book - initial book snapshot, book modifications, and trades
During data collection integrity of order book incremental updates is being validated using sequence numbers provided by real-time feed - in case of detecting missed message WebSocket connection is being restarted.

Each collected Poloniex real-time data message has appended symbol at the end of array - this allows us providing data filtering via API.

### Market data collection details
Market data collection infrastructure for Poloniex is located in GCP europe-west2 region (London, UK). 

Real-time market data is captured via multiple WebSocket connections.

Poloniex servers are located in AWS eu-west-1 region (Dublin, Ireland).
All it's public APIs are proxied through Cloudflare.

/$[PreviousBinance DEX](/historical-data-details/binance-dex)[NextGetting Started](/api/getting-started)Last updated 2 years ago

================================================================================

# Privacy Policy

Source: https://docs.tardis.dev/legal/privacy-policy
Extraction Method: playwright

Copy
1. Legal

# Privacy Policy
Tardis.dev privacy policy — what data we collect, how we collect it and what we do with this data

$This Privacy Policy explains how Personal Information about our (potential) customers and other individuals using our services is collected, used and disclosed by Tardis.dev and its respective affiliates ("us", "we", "our" or "Tardis.dev"). This Privacy Policy describes our privacy practices in relation to the use of our websites (including any customer portal or interactive customer website) (https://tardis.dev and https://docs.tardis.dev), services, solutions, tools, and related applications, services, and programs, including research and marketing activities, offered by us (the "Services"), as well as your choices regarding use, access, storage and correction of Personal Information. It also describes how we collect, use, disclose and otherwise process Personal Information collected in relation to our Services and otherwise in the course of our business activities. This Privacy Policy does not apply to Personal Information collected about our employees, applicants or other personnel.

By using our Services or by agreeing to our Terms of Service required to use our Services, you agree to the collection, usage, storage and disclosure of information described in this Privacy Policy.

Our Services may contain links to other websites or services; and information practices and/or the content of such other websites or services shall be governed by the privacy statements of such other websites or services.

### What information do we collect?
Here we describe what information we collect, what we use it for, which third parties we use to help us and give links to the privacy policies of those third parties for you to read:

• To manage payments, we use Paddle Ltd (https://paddle.com) who will store your payment details such as your payment card number, expiration date or security code. Please refer to their Privacy Statements https://paddle.com/gdpr and https://paddle.com/privacy/
• we track and store usage behavior such as which links are clicked on and API endpoints usage statistics so we can optimize the services we provide to you. We use Google Analytics with anonymized IP feature enabled for this purpose. Please refer to their Privacy Statement https://www.google.com/policies/privacy/
• We use Crisp to provide livechat support functionality. Please refer to their Privacy Statement https://crisp.chat/en/privacy/
• When you contact us for support or other customer service requests, we can maintain records related to such requests, including any information provided by you related to such support or service requests and contact you back about our services with relevant information. We may also obtain Personal Information about you from third parties, such as LinkedIn, Facebook, Twitter and other publicly accessible sources.
• We may use your Personal Information to contact you with marketing or promotional materials and other information communications related to Tardis.dev. If you no longer wish to receive marketing or promotional communications related to us, you can at any moment in time by using the unsubscribe button in the email or emailing privacy@tardis.dev to request us to stop sending you such communications. Such a request will be processed immediately by us, but in any event within two (2) business days.
• We use RunKit to provide interactive code playgrounds. Please refer to their Privacy Statement https://runkit.com/s/privacy
• To keep track of which users should have access to paid versions of our services and to handle API authentication and authorization, we store user details such as email address, name, subscription details and IP address in Cloudflare data store (encrypted at rest). Please refer to their Privacy Statement https://www.cloudflare.com/privacypolicy

Unless specified otherwise, all data requested by Tardis.dev is mandatory and failure to provide this data may make it impossible for us to provide our services. In cases where Tardis.dev website specifically states that some data is not mandatory, users are free not to communicate this data without consequences to the availability or the functioning of the service. Users who are uncertain about which personal data is mandatory are welcome  to contact us at privacy@tardis.dev.

We may publicly display aggregated anonymous data to help communicate what we know about how our services are typically used.

### How do you get my consent?
When you provide us with personal information to make a purchase or return a purchase, we imply that you consent to us collecting this information and using it for that specific reason only.

If we ask for your personal information so that we can send you communications in the future, we will either ask you directly for your expressed consent or provide you with an opportunity to say no afterwards.

### How do I withdraw my consent?
If you wish to withdraw the consent you have given to us to collect, store or use your information, please contact us at privacy@tardis.dev.

### Disclosure
We may disclose your personal information if we are required by law to do so or if you violate our Terms of Service.

### Third-party services
Third-party providers will collect, use and disclose your information to the extent necessary to allow them to perform the services they provide to us. Third-party service providers have their own privacy policies in respect to the information we are required to provide to them. For these providers, we recommend that you read their privacy policies so you can understand the manner in which your personal information will be handled by these providers.

In particular, remember that certain providers may be located in or have facilities that are located in a different jurisdiction than either you or us. Your information may become subject to the laws of the jurisdiction(s) in which a third party service provider or its facilities are located.

### Links
When you click on links that appear in any of the content we provide to you, those links may direct you to third party sites. We are not responsible for the privacy practices of other sites and encourage you to read their privacy statements.

### Security
To protect your personal information, we take reasonable precautions to make sure it is not inappropriately lost, misused, accessed, disclosed, altered or destroyed.

### Cookies
Our website uses cookies to track anonymized usage behavior and to personalize content.

### Retention of Personal Information
We retain personal information that you provide us as long as we consider it potentially useful in contacting you about our services, or as needed to comply with our legal obligations, resolve disputes and enforce our agreements.

### Age of consent
By using Tardis.dev website and services, you represent that you are at least the age of majority in your state or province of residence, or that you are the age of majority in your state or province of residence and you have given us your consent to allow any of your minor dependents to use this site.

### Changes to this privacy policy
We reserve the right to modify this privacy policy at any time, so please review it frequently. Changes and clarifications will take effect immediately upon their posting on the website. If we make material changes to this policy, we will notify you here that it has been updated, so that you are aware of what information we collect, how we use it, and under what circumstances, if any, we use and/or disclose it.

If we are acquired or merged with another company, your information may be transferred to the new owners.

### Questions and contact information
If you would like to access, correct, amend or delete any personal information we have about you, register a complaint, or simply want more information you should email us at privacy@tardis.dev.

/$[PreviousHTTP API Reference](/api/http)[NextTerms of Service](/legal/terms-of-service)Last updated 5 years ago

================================================================================

# Terms of Service

Source: https://docs.tardis.dev/legal/terms-of-service
Extraction Method: playwright

Copy
1. Legal

# Terms of Service
Terms you are agreeing to when you use Tardis.dev website and it's services

$Last modification date: 2023-09-12

## General conditions
Throughout the page, the terms “we”, “us” and “our” refer to Tardis.dev.

Please read these Terms of Service carefully before using our Service. By using our websites (including any customer portal or interactive customer website) (https://tardis.dev and https://docs.tardis.dev), services, solutions, tools, and related applications, services, and programs, including research and marketing activities, offered by us (the "Services"), you agree to be bound by these Terms of Service.

By visiting our site, purchasing something from us, accessing material we make available or using any software we provide such as API service, you engage in our “Service” and agree to be bound by the following terms and conditions (“Terms of Service”, “Terms”), including those additional terms and conditions and policies referenced herein and/or available by hyperlink. These Terms of Service apply to all users of the site, including without limitation users who are browsers, vendors, customers, merchants, and/or contributors of content.

Any new features or tools we offer are subject to the Terms of Service. You can review the most current version of the Terms of Service at any time on this page. We reserve the right to update, change or replace any part of these Terms of Service by posting updates and/or changes to our website. It is your responsibility to check this page periodically for changes. Your continued use of our Service following the posting of any changes constitutes acceptance of those changes.

By agreeing to these Terms of Service, you represent that you are at least the age of majority in your state or province of residence, or that you are the age of majority in your state or province of residence and you have given us your consent to allow any of your minor dependents to use this site.

A breach or violation of any of the Terms will result in an immediate termination of your Services.

We reserve the right to refuse service to anyone for any reason at any time.

We reserve the right at any time to modify or discontinue the Service (or any part or content thereof) without notice at any time.

We shall not be liable to you or to any third-party for any modification, price change, suspension or discontinuance of the Service.

You agree to indemnify, defend and hold harmless Tardis.dev and our affiliates, officers, directors, contractors and employees, harmless from any claim or demand, including reasonable attorneys’ fees, made by any third-party due to or arising out of your breach of these Terms of Service or the documents they incorporate by reference, or your violation of any law or the rights of a third-party.

In the event that any provision of these Terms of Service is determined to be unlawful, void or unenforceable, such provision shall nonetheless be enforceable to the fullest extent permitted by applicable law, and the unenforceable portion shall be deemed to be severed from these Terms of Service, such determination shall not affect the validity and enforceability of any other remaining provisions.

In addition to other prohibitions as set forth in the Terms of Service, you are prohibited from using our service: (a) for any unlawful purpose; (b) to solicit others to perform or participate in any unlawful acts; (c) to violate any international, federal, provincial or state regulations, rules, laws, or local ordinances; (d) to infringe upon or violate our intellectual property rights or the intellectual property rights of others; (e) to harass, abuse, insult, harm, defame, slander, disparage, intimidate, or discriminate based on gender, sexual orientation, religion, ethnicity, race, age, national origin, or disability; (f) to submit false or misleading information; (g) to upload or transmit viruses or any other type of malicious code that will or may be used in any way that will affect the functionality or operation of the Service or of any related website, other websites, or the Internet; (h) to collect or track the personal information of others; (i) to spam, phish, pharm or pretext; (j) for any obscene or immoral purpose; or (k) to interfere with or circumvent the security features of the Service or any related website, other websites, or the Internet. We reserve the right to terminate your use of the Service or any related website for violating any of the prohibited uses.

The failure of us to exercise or enforce any right or provision of these Terms of Service shall not constitute a waiver of such right or provision.

These Terms of Service and any policies or operating rules posted by us on this site or in respect to The Service constitutes the entire agreement and understanding between you and us and govern your use of the Service, superseding any prior or contemporaneous agreements, communications and proposals, whether oral or written, between you and us (including, but not limited to, any prior versions of the Terms of Service).

Any ambiguities in the interpretation of these Terms of Service shall not be construed against the drafting party.

## Payments
Our order process is conducted by our online reseller Paddle.com. Paddle.com is the Merchant of Record and authorized reseller for all the Services provided by us which means that you acquire our Services from Paddle.com.

By agreeing to these Terms of Service you also agree to Paddle's Buyer Terms and Conditions (https://paddle.com/legal-buyers/). 

Paddle.com handles returns and provides all customer service inquiries.

## Licence Agreement
By purchasing the Services provided by Tardis.dev (“the Supplier”), you (the “Customer”) are agreeing to this Licence Agreement (“Agreement”). This Agreement (as well as the documents referred to in it, including the Supplier’s Privacy Policy and any additional terms or policies that the Supplier tells the Customer about) sets out the agreement between the Customer and the Supplier - please read them carefully.

### 1. Interpretation
1.1  The definitions and rules of interpretation in this clause apply in this Agreement and in any other agreement between the parties.

Authorised Person: means in relation to either party: (i) any director, officer, employee or professional advisor of that party to whom the disclosure of Confidential Information is necessary in order to enable that party to perform obligations or exercise rights pursuant to this Agreement; (ii) any body which regulates that party in any jurisdiction, if disclosure to that body is mandated by applicable law or relevant regulation; (iii) the insurers, brokers and auditors of that party; and (v) any service providers providing administrative and similar support services to that party in the ordinary course of business in connection with the performance of obligations under this Agreement and to whom disclosure of Confidential Information is necessary to enable that party to perform obligations or exercise rights pursuant to this Agreement.

Confidential Information: all financial, business and technical and all other information (regardless of its form or the medium in which it is stored) concerning the business and affairs of a party or of a confidential nature that the other party obtains, receives or has access to, before or after the date of this Agreement, in connection with, or in the performance of, the Agreement.

Customer System: any information technology system or systems owned or operated by the Customer to which Data is delivered or within which Data is Distributed in accordance with this Agreement.

Customer User: any employee of the Customer authorized by the Customer to access and use the Services (wholly or in part), including employees of Customer’s Affiliates.

Customer Affiliate: an entity that owns or controls, is owned or controlled by or is or under common control or ownership with Customer, where control is defined as the possession, directly or indirectly, of the power to direct or cause the direction of the management and policies of an entity, whether through ownership of voting securities, by contract or otherwise;

Customer User Restrictions: the obligations set out in Schedule 1.

Data: the data or information, in whatever form including images, still and moving, and including financial and market research information, the provision of which comprises the Services (wholly or in part).

Derived Data: any Data (wholly or in part):

1. Manipulated to such a degree that it: (i) cannot be identified as originating or deriving directly from the Data or the Services and cannot be reverse-engineered such that it can be so identified; (ii) is not capable of use substantially as a substitute for the Data or the Services;
2. that is not separately marketed by the Customer; and
3. that has no independent commercial value.

Distribute: to make Data accessible (including the provision of access through a database or other application populated with the Data, transferring or disclosing the Data) by any means, including any electronic means, to any Customer User.

Effective Date: date of acceptance of the Agreement by the Customer.

Fees: fees specified on the Website and in the purchase invoice.

Force Majeure Event: means an event beyond a Party's reasonable control (but in each case only to the extent actually beyond the control of the Party seeking to rely on that event as a Force Majeure Event), including: (i) extreme abnormal weather conditions; (ii) nuclear, chemical or biological contamination; (iii) war, civil commotion or terrorist attack; (iv) interruption or failure of a utility service including electric power, gas or water; (v) acts of God, floods or earthquakes; (vi) pandemic (excluding COVID-19); or (vii) the imposition of a sanction, embargo or breaking off of diplomatic relations, but excluding in each case strikes or other forms of industrial action by the employees, agents or subcontractors of that Party, or any change in applicable law or relevant regulation.

Initial Period: the period commencing on the Effective Date that is specified in the purchase invoice.

Insolvency Event: (i) any procedure commenced with a view to the winding-up or re-organisation of such party; (ii) any step taken or any procedure is commenced with a view to the appointment of an administrator, receiver, administrative receiver or trustee in bankruptcy in relation to such party or all or substantially all of its assets; (iii) the holder of any security over all or substantially all of the assets of such party takes any step to enforce that security; (iv) all or substantially all of the assets of such party is subject to attachment, sequestration, execution or any similar process; (v) such party is unable to pay its debts as they fall due; (vi) such party enters into, or any step is taken, whether by the board of directors of such party or otherwise, towards entering into a composition or arrangement with its creditors or any class of them, including a company voluntary arrangement or a deed of arrangement; or (vii) such party enters into, or any step is taken, whether by the board of directors of such party or otherwise, towards any analogous procedure under the laws of any jurisdiction to the procedures set out in (i) to (vi) above.

Intellectual Property Rights: means: (i) rights in, and in relation to, any patents, registered designs, design rights, trade marks, trade and business names (including goodwill associated with any trade marks or trade and business names), copyright and related rights, moral rights, databases, domain names, semi-conductor and other topography rights and utility models, and including registrations and applications for, and renewals or extensions of, such rights, and similar or equivalent rights or forms of protection in any part of the world; (ii) rights in the nature of unfair competition rights and to sue for passing off and for past infringement; and (iii) trade secrets, confidentiality and other proprietary rights, including rights to know how and other technical information.

Licence: the licence granted in Clause 9.

Manipulate: to combine or aggregate the Data (wholly or in part) with other data or information or to adapt the Data (wholly or in part).

Manipulated Data: any Data which has been Manipulated. Manipulated Data includes any Derived Data.

Mark:means the trade marks, trade names, product or service names, logos, slogans, typefaces, brand or other proprietary words or symbols used by the Supplier from time to time.

Materials: any documents or software supplied by the Supplier under this Agreement.

Permitted Use: internal business use (which shall not include the use of the Data or the Materials by, or for the benefit of, any person other than an employee of the Customer).

Release: generally available upgrades and enhancements to the Data.

Services: the services to be supplied by the Supplier under this Agreement, including the supply of any Data, Materials, or Support.

Software:  any software provided by the Supplier to enable the Services to be used including any Releases.

Support: the support to be supplied by the Supplier including reasonable efforts to assist the Customer to access the Data.

Term: the Initial Period and any Renewal Periods.

Website: means any webpage of the Supplier, including but not limited to Tardis.dev.

1.2 The headings in this Agreement are inserted for convenience only and shall not affect its construction.

1.3 A person includes a natural person, corporate or unincorporated body (whether or not having separate legal personality).

1.4 The schedules form part of this Agreement and shall have effect as if set out in full in the body of this Agreement. Any reference to this Agreement includes the schedules.

1.5 A reference to a company shall include any company, corporation or other body corporate, wherever and however incorporated or established.

1.6 Unless the context otherwise requires, words in the singular shall include the plural and in the plural shall include the singular.

1.7 A reference to a particular law is a reference to it as it is in force for the time being taking account of any amendment, extension, or re-enactment and includes any subordinate legislation for the time being in force made under it.

1.8 References to clauses and schedules are to the clauses and schedules of this Agreement and references to paragraphs are to paragraphs of the relevant schedule.

1.9 Any words following the terms including, include, in particular or for example or any similar phrase shall be construed as illustrative and shall not limit the generality of the related general words.

1.10 If there is any uncertainty between any provision contained in the body of this Agreement and any provision contained in the Schedules or appendices, the provision in the body of this Agreement shall prevail.

### 2. Scope
During the Term the Supplier shall supply the Services to the Customer and the Customer shall pay the Fees and use the Services.

### 3. Connection
3.1 The Supplier shall use reasonable efforts to make connection to the Services available on the Effective Date.

3.2 The Customer shall ensure that it promptly complies with any minimum hardware configuration requirements specified by the Supplier to establish connectivity between the Customer System and the Services.

3.3 Each party shall bear its own costs of establishing that connectivity.

### 4. Services
4.1 During the Term the Supplier shall supply the Services to the Customer.

4.2 The Supplier may change at any time, with as much prior notice to the Customer as is reasonably practicable:

1. the content, format or nature of the Data or the Services; and
2. the means of access to the Data or the Services.

### 5. Fees
5.1 Customer will pay to Supplier, without offset or deduction, all fees due under this Agreement. Unless otherwise specified, all fees shall be due 14 days from the date of invoice and all fees are non-cancelable and non-refundable.

5.2 Supplier order process is conducted by Supplier online reseller Paddle.com. Paddle.com is the Merchant of Record for all Supplier orders.

5.3 All Fees are exclusive of VAT or any other applicable sales tax, which shall be paid by the Customer at the rate and in the manner for the time being prescribed by law.

### 6. Confidentiality
6.1 The parties shall each, as a receiving party: (i) keep confidential all Confidential Information disclosed by the disclosing party; (ii) shall not use the Confidential Information disclosed by the disclosing party in any way contrary to this Agreement, including Schedule I and not otherwise for the benefit of any third party; and (iii) not disclose the Confidential Information disclosed by the disclosing party to any person save to an Authorised Person.

6.2 The parties shall each, as a receiving party, ensure that each Authorised Person complies with confidentiality provisions no less onerous than those contained in this Clause 6 and will remain liable for any disclosure of Confidential Information by each Authorised Person as if it had made such disclosure.

6.3 The parties shall each, on the other party’s request destroy, erase or deliver to the other party all the requesting party’s Confidential Information, save where the retention of such Confidential Information is necessary to comply with applicable law or relevant regulation or otherwise for the other party to exercise its rights or receive benefits due under the Agreement.

6.4 The parties agree that the provisions of Clauses 6.1, 6.2, and 6.3 shall not apply to any information which the receiving party can prove: (i) is or becomes public knowledge other than by breach of this Clause; (ii) was in the possession of the receiving party without restriction in relation to disclosure before the date of receipt from the disclosing party; (iii) is received from a third party who lawfully acquired it and who was under no obligation restricting its disclosure; or (iv) was independently developed without access to any Confidential Information disclosed by the disclosing party.

6.5 The parties agree that these provisions in this Clause 6 shall not apply so as to prevent disclosure of Confidential Information by the receiving party to the extent that such disclosure is required to be made by any authority of competent jurisdiction or by any applicable law or relevant regulation or for the purposes of defending itself in relation to actual or threatened proceedings, regardless of whether brought or threatened by the other party or any other person, provided in each case that where permissible the receiving party: (i) gives the disclosing party reasonable formal written notice (provided that this is not in contravention of applicable law or relevant regulation) prior to such disclosure to allow the disclosing party a reasonable opportunity to seek a protective order; and (ii) uses reasonable endeavours to obtain prior to the disclosures written assurance from the applicable entity that it will keep the Confidential Information confidential.

6.6 Each party reserves all rights in its Confidential Information. No rights or obligations in respect of a party’s Confidential Information, other than those expressly stated in this Agreement, are granted to the other party, or are to be implied from this Agreement.

6.7 The provisions of this Clause 6 shall survive any expiry or termination of the Agreement.

### 7. Announcements
No party shall make, or permit any person to make, any public announcement concerning this Agreement without the prior written consent of the other party (such consent not to be unreasonably withheld or delayed), except as required by law, any governmental or regulatory authority (including any relevant securities exchange), any court or other authority of competent jurisdiction

### 8. Security
The Customer shall ensure that the Data and Materials are kept secure, and shall use security practices and systems consistent with standard industry practices and which will be applicable to the use of the Data and Materials to prevent, and take prompt and proper remedial action against, unauthorised access, copying, modification, storage, reproduction, display or distribution of the Data and the Materials.

### 9. Licence
9.1 The Supplier grants to the Customer a non-exclusive, non-transferable, licence for the Permitted Use only, subject to the Customer User Restrictions, to:

1. access, view and Manipulate Data and create Derived Data;
2. store the Data and Manipulated Data on the Customer System;
3. Distribute Derived Data to Customer Users on the Customer System; and
4. use (but not modify) the Materials in support of the activities referred to in this Clause 9.1.

9.2 Except as expressly provided in this Agreement, the Customer shall not:

1. use the Services (wholly or in part) in its products or services; or
2. redistribute or resell the Data or the Services (wholly or in part) with exception of reselling or redistributing aggregated and calculated data (lowest resolution being 10 minutes)

9.3 The Customer shall comply with the Customer User Restrictions.

### 10. Intellectual property rights ownership
10.1 The Customer acknowledges that:

1. all Intellectual Property Rights in the Data and the Materials are the property of the Supplier or its licensors, as the case may be;
2. it shall have no rights in or to the Data or the Materials other than the right to use them in accordance with the express terms of this Agreement;
3. the Supplier or its licensors has or have made and will continue to make substantial investment in the obtaining, verification, selection, coordination, development, presentation and supply of the Data;
4. it shall use the Supplier’s Mark strictly in accordance with the Supplier’s written instructions; and
5. any goodwill generated though the Customer’s use of the Supplier’s Mark shall belong only to the Supplier.

10.2 The Customer acknowledges that reference in any element of the Materials to trade names or proprietary products where no specific acknowledgement of such names or products is made does not imply that such names or products may be regarded by the Customer as free for general use, outside the scope of the use of the Materials authorised by this agreement.

10.3 If any third-party claim is made, or in the Supplier’s reasonable opinion is likely to be made, in relation to the use of the Data, the Supplier may at its sole option and expense:

1. procure for the Customer the right to continue using, developing, modifying or retaining the Data or the Materials (wholly or in part) in accordance with this Agreement;
2. modify the Data or the Materials (wholly or in part) so that they cease to be infringing;
3. replace the Data or the Materials (wholly or in part) with non-infringing items; or
4. terminate this Agreement immediately by notice in writing to the Customer. In respect of ongoing Subscriptions purchased by the Customer, the Supplier shall refund any Fees for the Initial Period or Renewal Period (as relevant) paid in advance by the Customer as at the date of termination (less a reasonable sum in respect of the Customer’s use of the Data or Materials to the date of termination) on return of the Data or the Materials and all copies of each of them.

10.4 Supplier shall indemnify and hold Customer harmless for any claims arising from third-party claims of any infringement of Intellectual Property Rights.

### 11. Warranties
11.1 Except as expressly stated in this Agreement, all warranties, conditions and terms, whether express or implied by statute, common law or otherwise (including any implied warranties of satisfactory quality or fitness for a particular purpose or non-infringement) are hereby excluded to the extent permitted by law.

11.2 Without limiting the effect of Clause 11.1, the Supplier does not warrant or make any representations:

1. that the supply of the Data will be error-free, free from interruption,or operate without loss or corruption of data or technical malfunction;
2. that the Data is accurate, complete, reliable, secure, useful, fit for purpose or timely; or
3. that the Data has been tested for use by the Customer or any third party or that the Data will be suitable for or be capable of being used by the Customer or any third party; or
4. regarding the benefit the Customer or any third party will obtain from the Data.

### 12. Limitation of liability
12.1 The Customer acknowledges that:

1. the use and interpretation of the Data requires specialist skill and knowledge of financial markets;
2. the Customer has that skill and knowledge and undertakes that it will exercise that skill and knowledge and appropriate judgment when using the Data;
3. the Customer shall be solely responsible, as against the Supplier, for any opinions, recommendations, forecasts or other conclusions made or actions taken by the Customer, any client of the Customer or any other third party based (wholly or in part) on the Data unless otherwise set out in this Clause 12; and
4. it is in the best position to ascertain any likely loss it may suffer in connection with this Agreement, that it is therefore responsible for making appropriate insurance arrangements to address the risk of any such loss and that the provisions of this Clause 12 are reasonable in these circumstances.

12.2 Neither party excludes or limits liability to the other party for:

1. fraud or fraudulent misrepresentation;
2. any matter which cannot be excluded by law.

12.3 Subject to Clause 12.2, each party shall not in any circumstances be liable whether in contract, tort (including for negligence and breach of statutory duty howsoever arising), misrepresentation (whether innocent or negligent), restitution or otherwise, for:

1. any loss (whether direct or indirect) of profits, business, business opportunities, revenue, turnover, reputation or goodwill;
2. any loss or corruption (whether direct or indirect) of data or information;
3. loss (whether direct or indirect) of anticipated savings or wasted expenditure (including management time); or
4. any loss or liability (whether direct or indirect) under or in relation to any other contract.

12.4 Subject to Clause 12.2 and excluding Clause 10.4, each party's total aggregate liability in contract, tort (including negligence and breach of statutory duty howsoever arising), misrepresentation (whether innocent or negligent), restitution or otherwise, arising in connection with the performance or contemplated performance of this Agreement or any collateral contract shall in all circumstances be limited to the total Fees paid by the Customer to the Supplier during the 12-month period immediately before the date on which the cause of action first arose or, if the cause of actions arose during the Initial Period, in respect of the Initial Period.

12.5 The Supplier shall not be liable for any delay in delivery of the Services that is caused by an event within the scope of Clause 14 or the Customer’s failure to provide the Supplier with adequate delivery instructions or any other instructions that are relevant to the supply of the Services or the Customer’s failure to comply with Clause 3.2.

### 13. Term and termination
13.1 This Agreement shall commence on the Effective Date. Unless terminated earlier in accordance with this Clause 13 or Clause 10.3, this Agreement shall continue for the Initial Period.

13.2 The Supplier may terminate this Agreement in respect of the Services (wholly or in part):

1. with immediate effect by giving written notice to the Customer if the Customer fails to pay any amount due under this Agreement on the due date for payment and remains in default not less than 30 days after being notified in writing to make that payment;
2. on written notice to the Customer at any time if the Supplier discontinues or withdraws, in whole or in part, its provision of the Services in question to all subscribers of such Services. The Supplier will use reasonable endeavours to give the Customer as much notice of the same as reasonably practicable, but any such termination will be without liability to the Supplier.

13.3 Without prejudice to any rights that have accrued under this Agreement or any of its rights or remedies, either party may terminate this Agreement (or any part thereof) with immediate effect by giving written notice to the other party if:

1. the other party: (i) commits a material breach of this Agreement and (if that breach is remediable) fails to remedy that breach within a period of 30 days after being notified in writing to do so; or (ii) commits a series of breaches of this Agreement which when taken together have the impact or effect of or otherwise amount to a material breach;
2. a Force Majeure Event continues for a period exceeding two (2) months;
3. the other party becomes subject to an Insolvency Event; or
4. the party reasonably determines that it has become unlawful to perform its obligations under the Agreement.

13.4 Any provision of this Agreement that expressly or by implication is intended to come into or continue in force on or after termination of this Agreement shall remain in full force and effect.

13.5 Termination or expiry of this agreement shall not affect any rights, remedies, obligations or liabilities of the parties that have accrued up to the date of termination or expiry, including the right to claim damages in respect of any breach of the agreement which existed at or before the date of termination or expiry.

13.6 On any termination of this Agreement for any reason or expiry of the Term, the Customer shall:

1. immediately pay any outstanding amounts owed to the Supplier under this Agreement; and
2. within a reasonable period of termination or expiry ensure that there is no further use of the Services in any of the Customer's products, applications or services, provided that the Customer shall not be obliged to remove from its products, applications and services any Data or Derived Data incorporated into them in accordance with this Agreement before termination or expiry.

13.7 On termination of this Agreement for any reason (save for termination for material breach by the Customer under Clause 13.3(a) or for failure to pay amounts due under Clause 13.2(a)), the Supplier shall refund any Fees for the Initial Period or Renewal Period (as relevant) paid in advance by the Customer as at the date of termination or expiry (less a reasonable sum taking into account the remaining length of the Initial Period or Renewal Period and the Customer's use of the Data or the Materials to the date of termination). If the Supplier terminates this Agreement under Clause 13.3(a) due to the Customer’s material breach, or under Clause 13.2(a) for the Customer’s failure to pay amounts due, the Customer shall not be entitled to any refund.

### 14. Force Majeure
Neither party shall be responsible for any failure to fulfill any obligation for so long as, and to the extent to which, the fulfillment of such obligation is impeded by a Force Majeure Event, and the affected party:

1. has promptly notified the other party of any circumstances which may result in failure to perform its obligations;
2. uses its best endeavours to minimize the adverse consequences that any failure in performance of its obligations might have, and to return the performance of such obligations to normal as soon as possible.

### 15. Assignment
15.1 This Agreement is personal to the Customer and it shall not assign, transfer, mortgage, charge, sub-contract, or otherwise transfer any of its rights and obligations under this Agreement without the prior written consent of the Supplier (which is not to be unreasonably withheld or delayed). Notwithstanding the preceding, Customer may assign any right or obligations to any of its Affiliates. For the purposes of this Agreement, the term “Affiliate” shall mean in respect of a party, any other entity that directly or indirectly controls, is controlled by or is under common control with, that party.

15.2 The Supplier may at any time assign, transfer, mortgage, charge, sub-contract, or otherwise transfer any of its rights and obligations under this Agreement without the consent of the Customer.

### 16. Waiver
No failure or delay by a party to exercise any right or remedy provided under the Agreement or by law, or a single or partial exercise of such right or remedy, shall constitute a waiver of that or any other right or remedy, nor shall it preclude or restrict the further exercise of that or any other right or remedy.

### 17. Remedies
Except as expressly provided in this Agreement, the rights and remedies provided under this Agreement are in addition to, and not exclusive of, any rights or remedies provided by law.

### 18. Notice
All notices, demands and other communications provided for or permitted under this Agreement will be made in writing to the parties at the addresses on the Cover Page and will be sent by email and will be deemed received upon receipt of a delivery receipt.

### 19. Entire Agreement
19.1 This Agreement represents the entire agreement between the parties and supersedes all previous discussions, correspondence, negotiations, arrangements, understandings and agreements between them, whether written or oral, relating to its subject matter.

19.2 Each party acknowledges that in entering into this Agreement it does not rely on, and shall have no remedies in respect of, any representation or warranty (whether made innocently or negligently) that is not set out in this Agreement.

19.3 Each party agrees that it shall have no claim for innocent or negligent misrepresentation based on any statement in this agreement.

### 20. Variation
The Supplier reserves the right to change the Agreement at any time and the Customer should revisit the terms and conditions at Tardis.dev before making purchase to ensure that it is fully aware of the current terms and conditions.

### 21. No partnership or agency
Nothing in this agreement is intended to, or shall be deemed to, establish any partnership or joint venture between any of the parties, constitute any party the agent of another party, or authorise any party to make or enter into any commitments for or on behalf of any other party.

### 22. Third-party rights
Except as expressly provided in this Agreement, a person who is not a party to this Agreement shall not have any rights under the Contracts (Rights of Third Parties) Act 1999 or otherwise to enforce any term of this Agreement.

### 23. Coinbase market data license restrictions
In relation to licensing Coinbase market data additional restrictions apply.

23.1 Customer is prohibited from further disseminating Coinbase Data and/or Derivative Data, and  using or permitting the use of Coinbase Data, Derivative Data and/or any part thereof for any Prohibited Use that  means any of:

1. use of Coinbase Data or Derivative Data that violates any applicable laws or the terms and conditions of this Agreement,
2. use of Coinbase Data to create Financial Products,
3. display or redistribution of any Coinbase Data or Derivative Datato any third party who is not a Customer, or by any Customer to any third party,
4. authorization of any Person to do any of the foregoing,
5. any other use not expressly permitted under this Agreement, and
6. any other use of the Data not expressly permitted under the Coinbase Market Data Policy.

23.2 Customer agrees that Coinbase may inspect Customer’s use of Coinbase Data and/or Derivative Data by Licensee and its agents upon ten (10) days advance notice to Customer; and Supplier or Coinbase has the ability to modify the agreement (or any other agreements related to the use of Coinbase Data or Derivative Data) with any Customer as Coinbase may from time to time specify, except that Supplier may continue to provide Coinbase Data and/or Derivative Data to a Customer without affecting the modification for ninety (90) days from that receipt; Supplier and Coinbase shall discontinue its provision of Coinbase Data and/or Derivative Data to a Customer thereafter if the Customer has not agreed to the modifications after this ninety (90) day period.

23.3 Customer agrees that for reporting purposes some of the customer specific information (such as customer name or address for example) may be be required by and reported to Coinbase.

### SCHEDULE 1 - CUSTOMER USER RESTRICTIONS

1. The Customer shall:

(a)  limit access to the Services to the Customer Users, which shall include Customer’s Affiliates;

(b)  only make copies of the Data and the Materials to the extent reasonably necessary for the following purposes: back-up, mirroring (and similar availability enhancement techniques), security, disaster recovery and testing;

(c)  comply with all applicable law and relevant regulations, and not use the Services for any purpose contrary to any applicable law or relevant regulation, or any regulatory code, guidance or request;

(d)  not extract, reutilise, use, exploit, redistribute, resell, redisseminate, copy or store the Data or the Materials for any purpose not expressly permitted by this Agreement;

(e)  not copy, modify, decompile, reverse engineer or create derivative works from the Software, except to the extent permitted by any applicable law; and

(f) not do anything which may damage the reputation of the Supplier, the Data or the Services, including by way of using the Data (wholly or in part) in any manner which is pornographic, racist or that incites religious hatred or violence.

/$[PreviousPrivacy Policy](/legal/privacy-policy)Last updated 2 years ago

================================================================================

## Failed Pages

- https://docs.tardis.dev/faq/data#what-is-a-difference-between-exchange-native-and-normalized-data-format: Duplicate content
- https://docs.tardis.dev/faq/general#do-you-support-consolidated-real-time-market-data-streaming: Duplicate content
- https://docs.tardis.dev/historical-data-details#per-exchange-historical-data-details: Duplicate content
